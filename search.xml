<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>demo驱动学习：Image_Caption</title>
      <link href="/2018/08/26/Image-Caption-demo-by-tensorflow/"/>
      <url>/2018/08/26/Image-Caption-demo-by-tensorflow/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Introduction-to-demo"><a href="#Introduction-to-demo" class="headerlink" title="Introduction to demo"></a>Introduction to demo</h2><p>Source Code:<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb" target="_blank" rel="noopener">image_captioning_with_attention</a></p><h3 id="Related-Papers"><a href="#Related-Papers" class="headerlink" title="Related Papers"></a>Related Papers</h3><p><a href="https://arxiv.org/pdf/1502.03044.pdf" target="_blank" rel="noopener">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.</a></p><h3 id="Goal-of-this-end2end-model"><a href="#Goal-of-this-end2end-model" class="headerlink" title="Goal of this end2end model"></a>Goal of this end2end model</h3><ol><li>Generate a caption, such as “a surfer riding on a wave”, according to an image.<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fun2xxvjt8j20hs0buamq.jpg" alt=""></li><li>Use an attention based model that enables us to see which parts of the image the model focuses on as it generates a caption.<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fun2yatwwhj20zz0ehk1c.jpg" alt=""></li></ol><h3 id="Dateset"><a href="#Dateset" class="headerlink" title="Dateset"></a>Dateset</h3><p><strong>MS-COCO</strong>:This dataset contains &gt;82,000 images, each of which has been annotated with at least 5 different captions.</p><h2 id="Frame-work-of-demo"><a href="#Frame-work-of-demo" class="headerlink" title="Frame work of demo:"></a>Frame work of demo:</h2><ol><li>Download and prepare the MS-COCO dataset</li><li>Limit the size of the training set for faster training</li><li><p>Preprocess the images using InceptionV3: extract features from the last convolutional layer.</p><ol><li>Initialize InceptionV3 and load the pretrained Imagenet weights</li><li>Caching the features extracted from InceptionV3</li></ol></li><li><p>Preprocess and tokenize the captions</p><ol><li>First, tokenize the captions will give us a vocabulary of all the unique words in the data (e.g., “surfing”, “football”, etc).</li><li>Next, limit the vocabulary size to the top 5,000 words to save memory. We’ll replace all other words with the token “UNK” (for unknown).</li><li>Finally, we create a word –&gt; index mapping and vice-versa.</li><li>We will then pad all sequences to the be same length as the longest one.</li></ol></li><li><p>create a tf.data dataset to use for training our model.</p></li></ol><ol start="6"><li><p>Model</p><ol><li>extract the features from the lower convolutional layer of InceptionV3 giving us a vector of shape (8, 8, 2048).</li><li>This vector is then passed through the CNN Encoder(which consists of a single Fully connected layer).</li><li>The RNN(here GRU) attends over the image to predict the next word.</li></ol></li><li><p>Training</p><ol><li>We extract the features stored in the respective .npy files and then pass those features through the encoder.</li><li>The encoder output, hidden state(initialized to 0) and the decoder input (which is the start token) is passed to the decoder.</li><li>The decoder returns the predictions and the decoder hidden state.</li><li>The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.</li><li>Use teacher forcing to decide the next input to the decoder.</li><li>Teacher forcing is the technique where the target word is passed as the next input to the decoder.</li><li>The final step is to calculate the gradients and apply it to the optimizer and backpropagate.</li></ol></li><li><p>Caption</p><ol><li>The evaluate function is similar to the training loop, except we don’t use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.</li><li>Stop predicting when the model predicts the end token.</li><li>And store the attention weights for every time step.</li></ol></li></ol><h2 id="Problems-undesirable"><a href="#Problems-undesirable" class="headerlink" title="Problems undesirable"></a>Problems undesirable</h2><h3 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h3><ul><li>The code requires TensorFlow version <strong>&gt;=1.9</strong>. 1.10.0 is better.</li><li><code>cudatoolkit</code></li></ul><h3 id="GPU-lose-connect"><a href="#GPU-lose-connect" class="headerlink" title="GPU lose connect"></a>GPU lose connect</h3><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb</a></li></ol>]]></content>
      
      <categories>
          
          <category> Demo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> imageCaption </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Visual-Question-Learning</title>
      <link href="/2018/08/23/Visual-Question-Learning/"/>
      <url>/2018/08/23/Visual-Question-Learning/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote><p>Visual Question Answering(VQA): A VQS system takes as input an image and free-form, open-ended, natural-language question about the image and produces a</p></blockquote>]]></content>
      
      
    </entry>
    
    <entry>
      <title>深度学习模块文档备忘录</title>
      <link href="/2018/08/23/colab-tensorflow-usage/"/>
      <url>/2018/08/23/colab-tensorflow-usage/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Colab-study-notes"><a href="#Colab-study-notes" class="headerlink" title="Colab study notes"></a>Colab study notes</h2><h3 id="Install-commonly-used-packages"><a href="#Install-commonly-used-packages" class="headerlink" title="Install commonly used packages"></a>Install commonly used packages</h3><p>Although Colab has already installed some packages such as Tensorflow Matplotlib .etc, there are lots of commonly ised packages:</p><ul><li>Keras:<code>pip install keras</code></li><li>OpenCV:<code>!apt-get -qq install -y libsm6 libxext6 &amp;&amp; pip install -q -U opencv-python</code></li><li>Pytorch:<code>!pip install -q http://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp27-cp27mu-manylinux1_x86_64.whl torchvision</code></li><li>tqdm:<code>!pip install tqdm</code><h3 id="Authorized-to-log-in"><a href="#Authorized-to-log-in" class="headerlink" title="Authorized to log in"></a>Authorized to log in</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 PyDrive 操作库，该操作每个 notebook 只需要执行一次</span></span><br><span class="line">!pip install -U -q PyDrive</span><br><span class="line"><span class="keyword">from</span> pydrive.auth <span class="keyword">import</span> GoogleAuth</span><br><span class="line"><span class="keyword">from</span> pydrive.drive <span class="keyword">import</span> GoogleDrive</span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> auth</span><br><span class="line"><span class="keyword">from</span> oauth2client.client <span class="keyword">import</span> GoogleCredentials</span><br><span class="line"></span><br><span class="line"><span class="comment"># 授权登录，仅第一次的时候会鉴权</span></span><br><span class="line">auth.authenticate_user()</span><br><span class="line">gauth = GoogleAuth()</span><br><span class="line">gauth.credentials = GoogleCredentials.get_application_default()</span><br><span class="line">drive = GoogleDrive(gauth)</span><br></pre></td></tr></table></figure></li></ul><h3 id="File-IO"><a href="#File-IO" class="headerlink" title="File IO"></a>File IO</h3><h4 id="Read-file-from-Google-Drive"><a href="#Read-file-from-Google-Drive" class="headerlink" title="Read file from Google Drive"></a>Read file from Google Drive</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get the file by id</span></span><br><span class="line">downloaded = drive.CreateFile(&#123;<span class="string">'id'</span>:<span class="string">'yourfileID'</span>&#125;) <span class="comment"># replace the id with id of file you want to access</span></span><br><span class="line"><span class="comment"># Download file to colab</span></span><br><span class="line">downloaded.GetContentFile(<span class="string">'yourfileName'</span>)  </span><br><span class="line"><span class="comment"># Read file as panda dataframe</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">xyz = pd.read_csv(<span class="string">'yourfileName'</span>)</span><br></pre></td></tr></table></figure><h4 id="Write-file-to-Google-Drive"><a href="#Write-file-to-Google-Drive" class="headerlink" title="Write file to Google Drive"></a>Write file to Google Drive</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a Content file as Cache</span></span><br><span class="line">xyz.to_csv(<span class="string">'over.csv'</span>)</span><br><span class="line"><span class="comment"># Create &amp; upload a text file.</span></span><br><span class="line">uploaded = drive.CreateFile(&#123;<span class="string">'title'</span>: <span class="string">'OK.csv'</span>&#125;)</span><br><span class="line"><span class="comment"># You will have a file named 'OK.csv' which has content of 'over.csv'</span></span><br><span class="line">uploaded.SetContentFile(<span class="string">'over.csv'</span>)</span><br><span class="line">uploaded.Upload()</span><br><span class="line"><span class="comment"># checkout your upload file's ID</span></span><br><span class="line">print(<span class="string">'Uploaded file with ID &#123;&#125;'</span>.format(uploaded.get(<span class="string">'id'</span>)))</span><br></pre></td></tr></table></figure><h2 id="Tensorflow-commonly-used"><a href="#Tensorflow-commonly-used" class="headerlink" title="Tensorflow commonly used"></a>Tensorflow commonly used</h2><h3 id="tf"><a href="#tf" class="headerlink" title="tf"></a>tf</h3><h4 id="read-file"><a href="#read-file" class="headerlink" title="read_file"></a>read_file</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.read_file(</span><br><span class="line">    filename,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="device"><a href="#device" class="headerlink" title="device"></a>device</h4><ol><li>manual mode<ul><li><code>with tf.device(&#39;/cpu:0&#39;)</code>: cpu</li><li><code>with tf.device(&#39;/gpu:0&#39;)</code>or<code>with tf.device(&#39;/device:GPU:0&#39;)</code>   </li></ul></li><li>GPU config<ul><li><code>import os</code></li><li><code>os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;]=&#39;0, 1&#39;</code><h4 id="random-normal"><a href="#random-normal" class="headerlink" title="random_normal"></a>random_normal</h4>Outputs random values from a normal distribution.<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.random_normal(</span><br><span class="line">    shape,</span><br><span class="line">    mean=<span class="number">0.0</span>,</span><br><span class="line">    stddev=<span class="number">1.0</span>,</span><br><span class="line">    dtype=tf.float32,</span><br><span class="line">    seed=<span class="keyword">None</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br><span class="line">tf.random_normal((<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="ConfigProto"><a href="#ConfigProto" class="headerlink" title="ConfigProto"></a>ConfigProto</h4><p>allowing GPU memory growth by the process.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="keyword">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br></pre></td></tr></table></figure></p><h4 id="reduce-sum"><a href="#reduce-sum" class="headerlink" title="reduce_sum"></a>reduce_sum</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_sum(</span><br><span class="line">    input_tensor,</span><br><span class="line">    axis=<span class="keyword">None</span>,</span><br><span class="line">    keepdims=<span class="keyword">None</span>,</span><br><span class="line">    name=<span class="keyword">None</span>,</span><br><span class="line">    reduction_indices=<span class="keyword">None</span>,</span><br><span class="line">    keep_dims=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Returns: The reduced tensor</p><h4 id="device-1"><a href="#device-1" class="headerlink" title="device"></a>device</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.device(device_name_or_function)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br></pre></td></tr></table></figure><h3 id="tf-image"><a href="#tf-image" class="headerlink" title="tf.image"></a>tf.image</h3><h4 id="decode-jpeg"><a href="#decode-jpeg" class="headerlink" title="decode_jpeg"></a>decode_jpeg</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.image.decode_jpeg(</span><br><span class="line">    contents,</span><br><span class="line">    channels=<span class="number">0</span>, <span class="comment"># 3: output an RGB image.</span></span><br><span class="line">    ratio=<span class="number">1</span>,</span><br><span class="line">    fancy_upscaling=<span class="keyword">True</span>,</span><br><span class="line">    try_recover_truncated=<span class="keyword">False</span>,</span><br><span class="line">    acceptable_fraction=<span class="number">1</span>,</span><br><span class="line">    dct_method=<span class="string">''</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="resize-images"><a href="#resize-images" class="headerlink" title="resize_images"></a>resize_images</h4><h3 id="tf-layers"><a href="#tf-layers" class="headerlink" title="tf.layers"></a>tf.layers</h3><h4 id="conv2d"><a href="#conv2d" class="headerlink" title="conv2d"></a>conv2d</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">tf.layers.conv2d(</span><br><span class="line">    inputs,</span><br><span class="line">    filters,</span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    padding=<span class="string">'valid'</span>,</span><br><span class="line">    data_format=<span class="string">'channels_last'</span>,</span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    activation=<span class="keyword">None</span>,</span><br><span class="line">    use_bias=<span class="keyword">True</span>,</span><br><span class="line">    kernel_initializer=<span class="keyword">None</span>,</span><br><span class="line">    bias_initializer=tf.zeros_initializer(),</span><br><span class="line">    kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    bias_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    activity_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    kernel_constraint=<span class="keyword">None</span>,</span><br><span class="line">    bias_constraint=<span class="keyword">None</span>,</span><br><span class="line">    trainable=<span class="keyword">True</span>,</span><br><span class="line">    name=<span class="keyword">None</span>,</span><br><span class="line">    reuse=<span class="keyword">None</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">random_image_gpu = tf.random_normal((<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br><span class="line">net_gpu = tf.layers.conv2d(random_image_gpu, <span class="number">32</span>, <span class="number">7</span>)</span><br></pre></td></tr></table></figure><p>Returns: Output tensor.</p><h3 id="tf-test"><a href="#tf-test" class="headerlink" title="tf.test"></a>tf.test</h3><ul><li>gpu_device_name(): Check out GPU whether can be found.</li></ul><h2 id="scikit-learn-sklearn"><a href="#scikit-learn-sklearn" class="headerlink" title="scikit-learn(sklearn)"></a>scikit-learn(sklearn)</h2><h3 id="utils"><a href="#utils" class="headerlink" title="utils"></a>utils</h3><ul><li>shuffle(*array):Shuffle arrays or sparse matrices in a consistent way<h3 id="model-selection"><a href="#model-selection" class="headerlink" title="model_selection"></a>model_selection</h3></li><li>train_test_split(*array): Split arrays or matrices into random train and test subsets</li></ul><h2 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h2><p>A high-API to build and train deep learning models.</p><h3 id="applications"><a href="#applications" class="headerlink" title="applications"></a>applications</h3><h4 id="inception-v3"><a href="#inception-v3" class="headerlink" title="inception_v3"></a>inception_v3</h4><ul><li><p>InceptionV3(…): Instantiates the Inception v3 architecture.</p>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.applications.InceptionV3(</span><br><span class="line">include_top=<span class="keyword">True</span>, <span class="comment"># whether to include the fully-connected layer at the top of the network.</span></span><br><span class="line">weights=<span class="string">'imagenet'</span>,</span><br><span class="line">input_tensor=<span class="keyword">None</span>,</span><br><span class="line">input_shape=<span class="keyword">None</span>,</span><br><span class="line">pooling=<span class="keyword">None</span>,</span><br><span class="line">classes=<span class="number">1000</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>decode_predictions(…): Decodes the prediction of an ImageNet model.</p></li><li>preprocess_input(…): Preprocesses a numpy array encoding a batch of images.</li></ul><h3 id="utils-1"><a href="#utils-1" class="headerlink" title="utils"></a>utils</h3><ul><li>get_file: Downloads a file from a URL if it not already in the cache.</li></ul><blockquote><p>Reference:</p><ol><li><a href="https://segmentfault.com/a/1190000012731724" target="_blank" rel="noopener">https://segmentfault.com/a/1190000012731724</a></li><li><a href="https://tensorflow.google.cn/api_docs/" target="_blank" rel="noopener">https://tensorflow.google.cn/api_docs/</a></li><li><a href="https://www.jianshu.com/p/d7283bc427b1" target="_blank" rel="noopener">https://www.jianshu.com/p/d7283bc427b1</a></li><li><a href="http://scikit-learn.org/stable/modules" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> DeepLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> colab </tag>
            
            <tag> tensorflow </tag>
            
            <tag> sklearn </tag>
            
            <tag> Keras </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Zero-shot Learning</title>
      <link href="/2018/08/22/zero-shot-learning/"/>
      <url>/2018/08/22/zero-shot-learning/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Zero-shot Learning is a concept from Transfer-Learning. In traditional machine learning method, Generalization is difficult since big data and time-consuming training are needed in general. Therefore more and more researchers pay attention to <strong>Zero-shot Learning</strong>/<strong>One-shot Learning</strong>/<strong>Few-shot Learning</strong></p><h3 id="types-of-Learning"><a href="#types-of-Learning" class="headerlink" title="types of Learning"></a>types of Learning</h3><h4 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h4><p>A model can create a map $X\rightarrowY$ automatically for the categories which have not appeared in a training set.</p><h4 id="One-shot-Learning"><a href="#One-shot-Learning" class="headerlink" title="One-shot Learning"></a>One-shot Learning</h4><p>One-shot learning is an object categorization problem in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training images.</p><h4 id="Few-shot-Leaning"><a href="#Few-shot-Leaning" class="headerlink" title="Few-shot Leaning"></a>Few-shot Leaning</h4><h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><h3 id="DeVise-A-Deep-Visual-Semantic-Embedding-Model"><a href="#DeVise-A-Deep-Visual-Semantic-Embedding-Model" class="headerlink" title="DeVise: A Deep Visual-Semantic Embedding Model"></a>DeVise: A Deep Visual-Semantic Embedding Model</h3><h4 id="Core-idea"><a href="#Core-idea" class="headerlink" title="Core idea"></a>Core idea</h4><p>Combine <strong>feature vector</strong> from Computer Vision and <strong>semantic vector</strong> from NLP to realize zero-shot learning.</p><h3 id="Zero-shot-Learning-by-Convex-Combination-of-Semantic-Embeddings"><a href="#Zero-shot-Learning-by-Convex-Combination-of-Semantic-Embeddings" class="headerlink" title="Zero-shot Learning by Convex Combination of Semantic Embeddings"></a>Zero-shot Learning by Convex Combination of Semantic Embeddings</h3><h3 id="Objects2action-Classifying-and-localizing-actions-without-any-video-example"><a href="#Objects2action-Classifying-and-localizing-actions-without-any-video-example" class="headerlink" title="Objects2action: Classifying and localizing actions without any video example"></a>Objects2action: Classifying and localizing actions without any video example</h3><blockquote><p>Reference:</p><ol><li><a href="https://en.wikipedia.org/wiki/One-shot_learning" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/One-shot_learning</a></li><li><a href="https://blog.csdn.net/jningwei/article/details/79235019" target="_blank" rel="noopener">https://blog.csdn.net/jningwei/article/details/79235019</a></li></ol></blockquote>]]></content>
      
      
    </entry>
    
    <entry>
      <title>论文笔记：Deep Reinforcement Learning for Dialogue Generation</title>
      <link href="/2018/08/18/paper-note-deep-reinfocement-learning-for-Dialogue-Generation/"/>
      <url>/2018/08/18/paper-note-deep-reinfocement-learning-for-Dialogue-Generation/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="论文基本信息"><a href="#论文基本信息" class="headerlink" title="论文基本信息"></a>论文基本信息</h2><ol><li>论文名：Deep Reinforcement Learning for Dialogue Generation</li><li>论文链接：<a href="https://arxiv.org/abs/1606.01541" target="_blank" rel="noopener">https://arxiv.org/abs/1606.01541</a></li><li>论文源码：<ul><li><a href="https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow" target="_blank" rel="noopener">https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow</a></li><li><a href="https://github.com/agsarthak/Goal-oriented-Dialogue-Systems" target="_blank" rel="noopener">https://github.com/agsarthak/Goal-oriented-Dialogue-Systems</a></li><li><a href="https://github.com/jiweil/Neural-Dialogue-Generation" target="_blank" rel="noopener">https://github.com/jiweil/Neural-Dialogue-Generation</a></li></ul></li><li>关于作者：<ul><li>Jiwei Li：斯坦福大学博士毕业生，截至发稿被引次数：2156</li><li>Will Monroe：斯坦福大学博士在读，截至发稿被引次数：562</li><li>Alan Ritter：俄亥俄州立大学教授，截至发稿被引次数：4608</li><li>Michel Galley：微软高级研究员，截至发稿被引次数：4529</li><li>Jianfeng Gao：雷德蒙德微软研究院（总部），截至发稿被引次数：11944</li><li>Dan Jurafsky：，斯坦福大学教授，截至发稿被引次数：32973</li></ul></li><li>关于笔记作者：<ul><li>朱正源,北京邮电大学研究生，研究方向为多模态与认知计算。</li></ul></li></ol><h2 id="论文推荐理由与摘要"><a href="#论文推荐理由与摘要" class="headerlink" title="论文推荐理由与摘要"></a>论文推荐理由与摘要</h2><p>最近对话生成的神经模型为会话Agent生成响应提供了很大的帮助，但其结果往往是短视的：一次预测一个话语会忽略它们对未来结果的影响。对未来的对话方向进行建模，这对于产生连贯，有趣的对话至关重要。这种对话需要在传统的NLP对话模式的技术上使用强化学习。在本文中，我们将展示如何整合这些目标，应用深度强化学习来模拟聊天机器人对话中的未来奖励。该模型模拟两个虚拟代理之间的对话，使用策略梯度方法来奖励显示三个有用会话属性的序列：信息性，连贯性和易于回答（与前瞻性功能相关）。我们在多样性，长度以及人类评判方面评估我们的模型，表明所提出的算法产生了更多的交互式响应，并设法在对话模拟中促进更持久的对话。这项工作标志着基于对话的长期成功学习神经对话模型的第一步。</p><h2 id="对话系统的缺点不再致命：深度强化学习带来的曙光"><a href="#对话系统的缺点不再致命：深度强化学习带来的曙光" class="headerlink" title="对话系统的缺点不再致命：深度强化学习带来的曙光"></a>对话系统的缺点不再致命：深度强化学习带来的曙光</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><h4 id="论文的写作动机"><a href="#论文的写作动机" class="headerlink" title="论文的写作动机"></a>论文的写作动机</h4><blockquote><p>Seq2Seq Model：将一个领域的序列(如英文句子)转换为另一个领域（如中文句子）的序列。在论文中是一种神经生成模型，它能最大限度地根据在前面的对话，生成回复的概率。</p></blockquote><p>Seq2Seq模型用于对话生成系统虽然已经取得一些成功，但是还存在两个问题：</p><ol><li><p>SEQ2SEQ模型是通过使用最大似然估计(MLE)目标函数,预测给定上下文中的下一个会话来训练的。SEQ2SEQ模型倾向于生成高度通用的响应，例如“我不知道”等。然而，“我不知道”显然不是一个好的回复。</p></li><li><p>基于最大似然估计的Seq2Seq模型无法结局重复的问题，因此对话系统通常会陷入重复性应答的无限循环之中。</p></li></ol><p>以上问题如下图所示：</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf3bujstcj20b509zgmm.jpg" alt=""></p><h4 id="论文思路的亮点"><a href="#论文思路的亮点" class="headerlink" title="论文思路的亮点"></a>论文思路的亮点</h4><p>首先提出对话系统应当具备的两种能力：</p><ol><li>结合开发人员定义的奖励函数，更好地模拟聊天机器人开发的真正目标。</li><li>在正在进行的对话中,对生成应答的长期影响进行建模。</li></ol><p>紧接着提出利用强化学习的生成方法来改进对话系统：</p><blockquote><p>encoder-decoder architecture:一种标准的神经机器翻译方法，用于解决seq2seq问题的递归神经网络。<br>Policy Gradient 策略梯度:</p></blockquote><p>该模型以encoder-decoder结构为骨干，模拟两个Agent之间的对话，在学习最大化预期回报的同时，探索可能的活动空间(回复的可能性)。Agent通过从正在进行的对话中优化长期Reward函数来学习策略。学习方式则使用策略梯度而非最大似然。</p><p>改进后的模型如下图所示：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf47elgdkj20af09yjse.jpg" alt=""></p><h3 id="论文模型的细节"><a href="#论文模型的细节" class="headerlink" title="论文模型的细节"></a>论文模型的细节</h3><h4 id="符号以及定义"><a href="#符号以及定义" class="headerlink" title="符号以及定义"></a>符号以及定义</h4><ol><li>$p$: 第一个Agent生成的句子</li><li>$q$: 第二个Agent生成的句子</li><li>$p_1,q_1,p_2,q_2,…,p_i,q_i$: 一段对话，或者称之为上下文.</li><li>$[p_i,q_i]$: Agent所处的状态，也即Agent的前两轮对话。</li><li>$p_{RL}(p_{i+1}|p_i,q_i)$: 策略(policy),论文中以LSTM encoder-decoder的形式出现。</li><li>$r$: 每个动作（每轮对话）的奖励函数。</li><li>$\mathbb{S}$: 人工构建的”迟钝回复”，例如“我不知道你在说什么”。</li><li>$N_{\mathbb{S}}$: 表示$N_{\mathbb{S}}$的基数</li><li>$N_{s}$: 表示“迟钝回复”$s$的符号数量。</li><li>$p_{seq2seq}$: 表示SEQ2SEQ模型的似然输出</li><li>$h_{p_i}$和$h_{p_{i+1}}$: 从encoder中获取的，代表Agent两轮连续对话$p_i$和$p_{i+1}$的表示。</li></ol><h4 id="Reward的定义和作用："><a href="#Reward的定义和作用：" class="headerlink" title="Reward的定义和作用："></a>Reward的定义和作用：</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug2dvizhhj209o01wdfq.jpg" alt=""></p><blockquote><p>$N_{\mathbb{S}}$:表示$N_{\mathbb{S}}$的基数<br>$N_{s}$: 表示“迟钝回复”$s$的符号数量<br>$p_{seq2seq}$: 表示SEQ2SEQ模型的似然输出</p><ul><li>$r_1$是为了降低回复的困难程度。这个奖励函数的灵感来自于前瞻性函数：计算当模型产生的响应$a$作为输入时模型输出$s$的概率，在对$\mathbb{S}$集合中的每一句话进行求和。因为$p_seq2seq}可定小于1，所以log项大于零，则r1小于零。通过r1的奖励机制，模型最终产生的action会慢慢的远离dull response，而且也会一定程度上估计到下一个人的回复，让对方可以更容易回复。</li></ul></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug5a6naokj20b302d747.jpg" alt=""></p><blockquote><p>$h_{p_i}$和$h_{p_{i+1}}$: 从encoder中获取的，代表Agent两轮连续对话$p_i$和$p_{i+1}$的表示。</p><ul><li>$r_2$是为了增加信息流的丰富程度，避免两次回复之间相似程度很高的情况。所以r2使用余弦相似度来计算两个句子之间的语义相似程度，很容易发现r2也是一个小于零的数，用来惩罚相似的句子。</li></ul></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug5av9bkgj20bp028mx4.jpg" alt=""></p><blockquote><p>$p_{seq2seq}(a|p_i, q_i)$: 表示在给定对话上文$[p_i,q_i]$的情况下生成回复a的概率<br>$p^{backward}_{seq2seq}(q_i|a)$: 表示基于响应$a$来生成之前的对话$q_i$的概率。</p><ul><li>$r_3$是为了增强语义连贯性，避免模型只产生那些高reward的响应，而丧失回答的充分性和连贯性。为了解决这个问题模型采用互信息来实现。反向的seq2seq是使用source和target反过来训练的另外一个模型，这样做的目的是为了提高q和a之间的相互关系，让对话更具有可持续性。可以看出来，$r_3$的两项都是正值。</li></ul></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug5beurspj209y01dt8k.jpg" alt=""></p><ul><li>最终的奖励函数式对$r_1，r_2，r_3$进行加权求和,论文中设定$\lambda_1=0.25, \lambda_2=0.25, \lambda3=0.5$。最后总模型在训练的时候也是先使用Seq2Seq模型先预训练一个基础模型，然后在其基础上在使用reward进行policy gradient的训练来优化模型的效果。</li></ul><h4 id="强化学习模型细节"><a href="#强化学习模型细节" class="headerlink" title="强化学习模型细节"></a>强化学习模型细节</h4><blockquote><p>完全监督环境（fully supervised setting）: 一个预先训练的SEQ2SEQ模型，用作初始化强化学习模型。<br>注意力模型（Attention）: 模型在产生输出的时候，还会产生一个“注意力范围”表示接下来输出的时候要重点关注输入序列中的哪些部分，然后根据关注的区域来产生下一个输出，如此往复。</p></blockquote><p>论文采用了AlphaGo风格的模型：通过一个完全监督的环境下的一般响应生成策略来初始化强化学习模型。其中，SEQ2SEQ模型加入了Attention机制并且该模型在<strong>OpenSubtitles dataset</strong>数据集上训练。</p><p>论文并未采用预训练的Seq2Seq模型来初始化强化学习策略模型，而是使用了第一作者本人在2016年提出的生成最大互信息响应的encoder-decoder模型: 使用$p_{SEQ2SEQ}(a|p_i, q_i)$来初始化$p_{RL}$。从生成的候选集$A={\hat{a}|\hat{a}~p_{RL}}$中的$\hat{a}$获取互信息的得分$m(\hat{a}, [p_i, q_i])$，那么对一个sequence的期望奖励函数为：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuhd5cu9doj208j01ddfo.jpg" alt=""></p><p>通过似然率估计的梯度为：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuhd6s09lyj20ax01awed.jpg" alt=""></p><p>通过随机梯度下降就可以更新encoder-decoder的参数。论文中通过借鉴curriculum learning strategy对梯度进行了改进。</p><p>最终的梯度为：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuhdbxz4kij20b401tjra.jpg" alt=""></p><p>优化模型过程中则使用策略梯度来寻找可以最大化奖励函数的参数：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuief5dqqxj209j01n0sn.jpg" alt=""></p><h3 id="仿真实验细节"><a href="#仿真实验细节" class="headerlink" title="仿真实验细节"></a>仿真实验细节</h3><h4 id="对话仿真流程："><a href="#对话仿真流程：" class="headerlink" title="对话仿真流程："></a>对话仿真流程：</h4><ol><li>从训练集中挑选一个message给Agent-A</li><li>Agent-A对message进行编码并解码出一个响应作为输出。</li><li>Agent-B以Agent-A的输出作为输入，并且通过encoder-decoder来</li></ol><p>而策略policy就是Seq2Seq模型生成的相应的概率分布。我们可以把这个问题看成是上下文的对话历史输入到神经网络中，然后输出是一个response的概率分布：$pRL(pi+1|pi,qi)$。所谓策略就是进行随机采样，选择要进行的回答。最后使用policy gradient进行网络参数的训练。</p><p>两个agent互相对话最终得到的reward来调整base model的参数。</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf4u98teyj20lv0aatav.jpg" alt=""></p><h3 id="实验结果分析"><a href="#实验结果分析" class="headerlink" title="实验结果分析"></a>实验结果分析</h3><h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><blockquote><p>BLEU: bilingual evaluation understudy，一个评估机器翻译准确度的算法。<br>论文并没有使用 广泛应用的BLEU作为评价标准。</p></blockquote><ol><li><p>对话的长度，作者认为当对话出现dull response的时候就算做对话结束，所以使用对话的轮次来作为了评价指标：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0a67z3dj20fi051q3c.jpg" alt=""></p></li><li><p>不同unigrams、bigrams元组的数量和多样性，用于评测模型产生回答的丰富程度：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0boign2j20e104a3z0.jpg" alt=""></p></li><li><p>人类评分：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0gegq71j20gc03sgm9.jpg" alt=""></p></li><li><p>最终对话效果<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0hq4jzaj20g203k3z5.jpg" alt=""></p></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作者使用深度强化学习的方法来改善多轮对话的效果，并提出了三种reward的定义方式。可以算是DRL与NLP结合的一个比较不错的例子。但是从最后的结果部分也可以看得出，作者无论是在reward的定义、还是最后的评价指标都没有采用使用比较广泛的BLUE指标。这种手工定义的reward函数不可能涵盖一段理想对话所具有特点的的方方面面。</p><h3 id="引用与参考"><a href="#引用与参考" class="headerlink" title="引用与参考"></a>引用与参考</h3><ol><li><a href="https://www.paperweekly.site/papers/notes/221" target="_blank" rel="noopener">https://www.paperweekly.site/papers/notes/221</a></li><li><a href="https://scholar.google.com/" target="_blank" rel="noopener">https://scholar.google.com/</a></li><li><a href="https://blog.csdn.net/u014595019/article/details/52826423" target="_blank" rel="noopener">https://blog.csdn.net/u014595019/article/details/52826423</a></li></ol>]]></content>
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> note </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>对话AI的论文列表</title>
      <link href="/2018/08/09/convAI-paper-list/"/>
      <url>/2018/08/09/convAI-paper-list/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>论文列表格式<br>&emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校/机构），代码链接</p></blockquote><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="Existing-Models-of-Dialog-System"><a href="#Existing-Models-of-Dialog-System" class="headerlink" title="Existing Models of Dialog System"></a>Existing Models of Dialog System</h3><h4 id="Task-Oriented-Dialog"><a href="#Task-Oriented-Dialog" class="headerlink" title="Task-Oriented Dialog"></a>Task-Oriented Dialog</h4><ul><li>13: <a href="https://ieeexplore.ieee.org/document/6407655/" target="_blank" rel="noopener"><strong>POMDP-Based Statistical Spoken Dialog Systems: A Review</strong></a>: Steve Young(Cambridge University)</li><li>11: <a href="https://www.wiley.com/en-us/Spoken+Language+Understanding:+Systems+for+Extracting+Semantic+Information+from+Speech-p-9780470688243" target="_blank" rel="noopener"><strong>Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</strong></a>: Book!</li><li>11:<a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener"><strong>Data-Driven Response Generation in Social Media</strong></a>: Alan Ritter(University of Washington Seattle)</li><li><p>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener"><strong>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</strong></a>: Alessandro Sordoni(Universite de Montreal)</p></li><li><p>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener"><strong>A Neural Conversational Model</strong></a>: Oriol Vinyals(Google), <a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</p></li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener"><strong>Neural Responding Machine for Short-Text Conversation</strong></a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener"><strong>code</strong></a> via theano and tensorflow</li></ul><h3 id="Traditional-NLP-component-stack"><a href="#Traditional-NLP-component-stack" class="headerlink" title="Traditional NLP component stack"></a>Traditional NLP component stack</h3><h4 id="Challenge-of-NLP"><a href="#Challenge-of-NLP" class="headerlink" title="Challenge of NLP"></a>Challenge of NLP</h4><ul><li>09: <a href="https://www.cs.colorado.edu/~martin/slp.html" target="_blank" rel="noopener"><strong>SPEECH and LANGUAGE PROCESSING An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Second Edition</strong></a>: book </li></ul><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h4 id="application-scenarios"><a href="#application-scenarios" class="headerlink" title="application scenarios"></a>application scenarios</h4><ol><li>Web search<ul><li>13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), <a href="https://github.com/wangtianqi1993/DL-WebSearch" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</li><li>14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li></ul></li><li>Entity linking<ul><li>14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Image captioning<ul><li>15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul></li><li>Machine Translation<ul><li><a href="http://aclweb.org/anthology/P/P14/P14-1066.pdf" target="_blank" rel="noopener"><strong>Learning Continuous Phrase Representations for Translation Modeling</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Online recommendation<ul><li>[<strong>duplicate</strong>] 14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfneg Gao(Microsoft Research)</li></ul></li></ol><h4 id="Framework-of-Model"><a href="#Framework-of-Model" class="headerlink" title="Framework of Model"></a>Framework of Model</h4><ul><li>[<strong>duplicate</strong>] 13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), [<strong>code</strong>]<ul><li>[<strong>duplicate</strong>] 14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li></ul></li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li><li><a href="http://aka.ms/sent2vec" target="_blank" rel="noopener">Sent2Vec</a>: software by microsoft</li></ul><h4 id="Go-beyound-DSSM"><a href="#Go-beyound-DSSM" class="headerlink" title="Go beyound DSSM"></a>Go beyound DSSM</h4><ul><li>[<strong>duplicate</strong>] 15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul><hr><h2 id="Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC"><a href="#Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC" class="headerlink" title="Question answeriing(QA) and Machine Readiing Comprehension(MRC)"></a>Question answeriing(QA) and Machine Readiing Comprehension(MRC)</h2><h3 id="Open-Domain-Question-Answering"><a href="#Open-Domain-Question-Answering" class="headerlink" title="Open-Domain Question Answering"></a>Open-Domain Question Answering</h3><h4 id="Knowledge-Base-QA"><a href="#Knowledge-Base-QA" class="headerlink" title="Knowledge Base-QA"></a>Knowledge Base-QA</h4><ol><li>Symbolic approach via Large-scale knowledge graphs<ul><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>: Stephen D.Richardson(Microsoft Research)</li><li>13: <a href="http://www.aclweb.org/anthology/D13-1160" target="_blank" rel="noopener">Semantic Parsing on Freebase from Question-Answer Pairs</a>: Jonathan Berant(Stanford University)</li><li>15: <a href="https://arxiv.org/pdf/1510.08565.pdf" target="_blank" rel="noopener">Attention with Intention for a Neural Network Conversation Model</a>: Kaisheng Yao(Microsoft Research)</li><li>14: <a href="http://www.aclweb.org/anthology/P14-1091" target="_blank" rel="noopener">Knowledge-Based Question Answering as Machine Translation</a>: Junwei Bao(Harbin Institute of Technology)</li><li>15: <a href="http://aclweb.org/anthology/P15-1128" target="_blank" rel="noopener">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</a>:Wen-tau Yih(Microsoft Research)</li></ul></li><li><p><strong>ReasoNet</strong> with Shared Memory</p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Search Controller in <strong>ReasoNet</strong> </p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li></ul></li><li><strong>ReasoNet</strong> in symbolic vs neural space<ul><li>Symbolic is comprehensible but not robust<ul><li>11: <a href="http://www.cs.cmu.edu/~tom/pubs/lao-emnlp11.pdf" target="_blank" rel="noopener">Random Walk Inference and Learning in A Large Scale Knowledge Base</a>:Ni Lao(Carnegie Mellon University)</li><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>:Stephen D.Richardson(Microsoft Research)</li></ul></li><li>Neural is robust but not comprehensible<ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>15: <a href="https://arxiv.org/abs/1412.6575" target="_blank" rel="noopener">EMBEDDING ENTITIES AND RELATIONS FOR LEARNING AND INFERENCE IN KNOWLEDGE BASES</a>:Bishan Yang(Cornell University)</li></ul></li><li>Hybrid is robust and  comprehensible<ul><li>18: <a href="https://arxiv.org/pdf/1802.04394.pdf" target="_blank" rel="noopener">M-Walk: Learning to Walk in Graph with Monte Carlo Tree Search</a>:Yelong Shen(Microsoft Research&amp;Tecent AI Lab)</li><li>18: <a href="https://arxiv.org/abs/1707.06690" target="_blank" rel="noopener">DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning</a>:Wenhan Xiong(University of California,Santa Barbara), <a href="https://github.com/xwhan/DeepPath" target="_blank" rel="noopener">code1</a> <a href="https://github.com/arunarn2/DeepPathwithTensorforce" target="_blank" rel="noopener">code2</a></li><li>18: <a href="https://arxiv.org/abs/1711.05851" target="_blank" rel="noopener">GO FOR A WALK AND ARRIVE AT THE ANSWER: REASONING OVER PATHS IN KNOWLEDGE BASES USING REINFORCEMENT LEARNING</a>:Rajarshi Das(University of Massachusetts,Amherst), </li></ul></li></ul></li><li>Multi-turn KB-QA<ul><li>Programmed Dialogue policy<ul><li>15: <a href="https://arxiv.org/pdf/1504.07182.pdf" target="_blank" rel="noopener">A Probabilistic Framework for Representing Dialog Systems and Entropy-Based Dialog Management through Dynamic Stochastic State Evolution</a>:Ji Wu(IEEE)</li></ul></li><li>Trained via RL Dialogue policy<ul><li>16: <a href="https://arxiv.org/abs/1604.04562" target="_blank" rel="noopener">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>:Tsung-Hsien Wen(Cambridge University)</li><li>17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)</li></ul></li></ul></li></ol><h4 id="Text-QA"><a href="#Text-QA" class="headerlink" title="Text-QA"></a>Text-QA</h4><ol><li>MS MARCO<ul><li>16: <a href="https://arxiv.org/abs/1611.09268" target="_blank" rel="noopener">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</a>:Tri Nguyan(Microsoft AI&amp;Research)</li></ul></li><li>SQuAD<ul><li>16: <a href="https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf" target="_blank" rel="noopener">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a>:Pranav Rajpurkar(Stanford University)</li></ul></li></ol><h3 id="Neural-MRC-Models"><a href="#Neural-MRC-Models" class="headerlink" title="Neural MRC Models"></a>Neural MRC Models</h3><h4 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h4><ul><li>16: <a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION</a>:Minjoon Seo(University of Washington)<ul><li><a href="https://github.com/imraviagrawal/ReadingComprehension" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/bentrevett/bidaf" target="_blank" rel="noopener">code2</a> </li><li><a href="https://github.com/akhil-vader/MachineComprehension_SQuAD" target="_blank" rel="noopener">code3</a> </li><li><a href="https://github.com/RamkishanPanthena/Machine-Comprehension-using-SQuAD-Dataset" target="_blank" rel="noopener">code4</a></li></ul></li></ul><h4 id="SAN"><a href="#SAN" class="headerlink" title="SAN"></a>SAN</h4><ul><li>18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul><h4 id="Neural-MRC-Models-on-SQuAD"><a href="#Neural-MRC-Models-on-SQuAD" class="headerlink" title="Neural MRC Models on SQuAD"></a><strong>Neural MRC Models on SQuAD</strong></h4><ol><li><p>Encoding: map each text span to a semantic vector</p><ul><li>Word Embedding<ul><li>14: <a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a>:Jeffrey Pennington(Stanford University)<ul><li><a href="https://github.com/brangerbriz/midi-glove" target="_blank" rel="noopener">code:midi-glove</a></li><li><a href="https://github.com/fdurant/wiki_glove" target="_blank" rel="noopener">code:wiki-glove</a></li></ul></li><li>13: <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a>:Tomas Mikolov(Google Inc.)<ul><li><a href="https://github.com/brijml/mikolov_word2vec" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/shuuchen/keras_word2vec" target="_blank" rel="noopener">code2</a><ul><li>Context Embedding</li></ul></li></ul></li></ul></li></ul><ol><li>capture context info for each word<ul><li>16: <a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li><li>18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li><li>Context Embedding via BiLSTM/ELmo<ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>17: <a href="https://arxiv.org/abs/1708.00107" target="_blank" rel="noopener">Learned in Translation: Contextualized Word Vectors</a>:Bryan McCann(SalesForce)</li><li>16: [duplicate]<a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li></ul></li><li>Context Embedding<ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li></ol><ul><li>Query-context/Content-query attention</li></ul></li><li><p>Reasoning: rank and re-rank semantic vectors</p><ul><li><p>Multi-step reasoning for Text-QA</p><ul><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Stochastic Answer Net</p><ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul></li></ul></li></ol><hr><h2 id="Task-oriented-dialogues"><a href="#Task-oriented-dialogues" class="headerlink" title="Task-oriented dialogues"></a>Task-oriented dialogues</h2><h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><h4 id="A-Example-Dialogue-with-Movie-Bot"><a href="#A-Example-Dialogue-with-Movie-Bot" class="headerlink" title="A Example Dialogue with Movie-Bot"></a>A Example Dialogue with Movie-Bot</h4><ul><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a><h4 id="Conversation-as-Reinforcement-Learning"><a href="#Conversation-as-Reinforcement-Learning" class="headerlink" title="Conversation as Reinforcement Learning"></a>Conversation as Reinforcement Learning</h4></li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)<h4 id="Dialogue-System-Evaluation-Simulated-Users"><a href="#Dialogue-System-Evaluation-Simulated-Users" class="headerlink" title="Dialogue System Evaluation(Simulated Users)"></a>Dialogue System Evaluation(Simulated Users)</h4></li></ul><ol><li>Agenda based<ul><li>09: <a href="https://ieeexplore.ieee.org/document/4806280/" target="_blank" rel="noopener">The Hidden Agenda User Simulation Model</a>:Jost Schatzmann(IEEE)</li><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a> </li></ul></li><li>Model based<ul><li>16: <a href="https://arxiv.org/abs/1607.00070" target="_blank" rel="noopener">A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems</a>: Layla El Asri(Maluuba Research)</li><li>17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul></li></ol><h3 id="traditional-approache"><a href="#traditional-approache" class="headerlink" title="traditional approache"></a>traditional approache</h3><h4 id="Decison-theoretic-View-of-Dialogue-Management"><a href="#Decison-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decison-theoretic View of Dialogue Management"></a>Decison-theoretic View of Dialogue Management</h4><ul><li>[<strong>duplicate</strong>] 00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>00: <a href="http://www.aclweb.org/anthology/P98-2219" target="_blank" rel="noopener">Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email</a>: Marilyn A.Walker(ATT Labs Research)</li><li>02: <a href="https://dl.acm.org/citation.cfm?id=1289246" target="_blank" rel="noopener">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li></ul><h4 id="Language-Understanding-Uncertainty-POMDP-as-a-principled-framework"><a href="#Language-Understanding-Uncertainty-POMDP-as-a-principled-framework" class="headerlink" title="Language Understanding Uncertainty: POMDP as a principled framework"></a>Language Understanding Uncertainty: POMDP as a principled framework</h4><ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">Spoken Dialogue Management Using Probabilistic Reasoning</a>: Nicholas Roy(Carnegie Mellon University)</li><li>01: <a href="http://www.wytsg.org:88/reslib/400/180/110/020/010/130/L000000000233767.pdf" target="_blank" rel="noopener">Spoken Dialogue Management as Planning and Acting under Uncertainty</a>:Bo Zhang(Tech. of China)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul><h4 id="scaling-up-Dialogue-Optimization"><a href="#scaling-up-Dialogue-Optimization" class="headerlink" title="scaling up Dialogue Optimization"></a>scaling up Dialogue Optimization</h4><ol><li>Use approxmiate POMDP algorithms leveraging problem-specific structure<ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul></li><li>Use Reinforcement Learning algorithms with function approximation<ul><li>08: <a href="http://www.aclweb.org/anthology/J08-4002" target="_blank" rel="noopener">Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets</a>: James Henderson</li><li>09: <a href="https://pdfs.semanticscholar.org/a950/d7836e101e7d649791714d8383a804a6f671.pdf" target="_blank" rel="noopener">Reinforcement Learning for Dialog Management using Least-Squares Policy Iteration and Fast Feature Selection</a>: Lihong Li(Rutgers University)</li><li>14: <a href="http://mi.eng.cam.ac.uk/~sjy/papers/gktb14.pdf" target="_blank" rel="noopener">Incremental on-line adaptation of POMDP-based dialogue managers to extended domains</a>:M.Gasic[Cambridge University]</li></ul></li></ol><h3 id="Natural-language-understanding-and-dialogue-state-tracking"><a href="#Natural-language-understanding-and-dialogue-state-tracking" class="headerlink" title="Natural language understanding and dialogue state tracking"></a>Natural language understanding and dialogue state tracking</h3><h4 id="Language-Understanding"><a href="#Language-Understanding" class="headerlink" title="Language Understanding"></a>Language Understanding</h4><ol><li><p>DNN for Domain/Intent Classification</p><ul><li>15:  <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RNNLM_addressee.pdf" target="_blank" rel="noopener">Recurrent Neural Network and LSTM Models for Lexical Utterance Classification</a>: Suman Raviuri(University of California,Berkeley)</li></ul></li><li><p>Slot filling</p><ul><li>16: <a href="https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_MultiJoint.pdf" target="_blank" rel="noopener">Multi-Domain Joint Semantic Frame Parsing using Bi-directional RNN-LSTM</a>: Dilek Hakkani-Tur(Microsoft Research)</li></ul></li><li><p>Further details on NLU</p><ul><li><a href="https://www.csie.ntu.edu.tw/~yvchen/doc/OpenDialogue_Tutorial_IJCNLP.pdf" target="_blank" rel="noopener">ppt</a></li><li>E2E MemNN for Contectual LU: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/IS16_ContextualSLU.pdf" target="_blank" rel="noopener">End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding</a>: Yun-Nung Chen(National Taiwan University )</li><li>[<strong>duplicate</strong>] LU Importance: 17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul></li></ol><h4 id="Dialogue-State-Tracking-DST"><a href="#Dialogue-State-Tracking-DST" class="headerlink" title="Dialogue State Tracking(DST)"></a>Dialogue State Tracking(DST)</h4><ol><li>DSTC(Dialog State Tracking Challenge)<ul><li><a href="https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/" target="_blank" rel="noopener">DSTC1 official website</a></li><li><a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="noopener">DSTC2&amp;3 official website</a></li><li><a href="http://www.colips.org/workshop/dstc4/" target="_blank" rel="noopener">DSTC4 official website</a></li><li><a href="http://workshop.colips.org/dstc5/" target="_blank" rel="noopener">DSTC5 official website</a></li></ul></li><li><p>Neural Belief Tracker</p><ul><li>16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li></ul></li><li><p>NN-Based DST</p><ul><li>13: <a href="http://www.anthology.aclweb.org/W/W13/W13-4073.pdf" target="_blank" rel="noopener">Deep Neural Network Approach for the Dialog State Tracking Challenge</a>: Matthew Henderson(University of Cambridge)</li><li>15: <a href="https://arxiv.org/abs/1506.07190" target="_blank" rel="noopener">Multi-domain Dialog State Tracking using Recurrent Neural Networks</a>: Nikola Mrksic(University of Cambridge)</li><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li></ul></li></ol><h3 id="Deep-RL-for-dialogue-policy-learning"><a href="#Deep-RL-for-dialogue-policy-learning" class="headerlink" title="Deep RL for dialogue policy learning"></a>Deep RL for dialogue policy learning</h3><h4 id="Two-main-classed-of-RL-algorithms"><a href="#Two-main-classed-of-RL-algorithms" class="headerlink" title="Two main classed of RL algorithms"></a>Two main classed of RL algorithms</h4><ol><li>Value function based:<ul><li>15: <a href="https://www.nature.com/articles/nature14236" target="_blank" rel="noopener">Human-level control through deep reinforcement learning</a>: Volodymyr Minh<ul><li><a href="https://github.com/devsisters/DQN-tensorflow" target="_blank" rel="noopener">code1</a> by tensorflow</li><li><a href="https://github.com/pianomania/DQN-pytorch" target="_blank" rel="noopener">code2</a> by pytorch</li></ul></li><li>16: <a href="https://arxiv.org/pdf/1606.02560.pdf" target="_blank" rel="noopener">Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning</a>: Tiancheng Zhao(Carnegie Mellon University)</li></ul></li><li>Policy based:<ul><li>92: <a href="https://doi.org/10.1007/BF00992696" target="_blank" rel="noopener">Simple statistical gradient-following algorithms for connectionist reinforcement learning</a>: Ronald J.Williams</li><li>17: <a href="http://www.aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="noopener">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a>: Pei-Hao Su(University of Cambridge)<h4 id="Domain-Extension-and-Exploration-BBQ-network"><a href="#Domain-Extension-and-Exploration-BBQ-network" class="headerlink" title="Domain Extension and Exploration(BBQ network)"></a>Domain Extension and Exploration(BBQ network)</h4></li></ul></li></ol><ul><li>18: <a href="https://arxiv.org/pdf/1608.05081.pdf" target="_blank" rel="noopener">BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems</a>: Zachary Lipton(Carnegir Mellon University)</li></ul><h4 id="Composite-task-Dialogues"><a href="#Composite-task-Dialogues" class="headerlink" title="Composite-task Dialogues"></a>Composite-task Dialogues</h4><ol><li>A Hierarchical Policy Learner<ul><li>98: <a href="http://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines.pdf" target="_blank" rel="noopener">Reinforcement Learning with Hierarchies of Machines</a>: Ronald Parr(UC Berkeley)</li><li>17: <a href="https://arxiv.org/abs/1704.03084" target="_blank" rel="noopener">Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning</a>: Baolin Peng(Microsoft Research)</li></ul></li><li>Integrating Planning for Dialogue Policy Learning<ul><li>18: <a href="https://arxiv.org/abs/1801.06176" target="_blank" rel="noopener">Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning</a>: Baolin Peng(Microsoft Research) , <a href="https://github.com/MiuLab/DDQ" target="_blank" rel="noopener">code</a></li></ul></li></ol><h3 id="Decision-theoretic-View-of-Dialogue-Management"><a href="#Decision-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decision-theoretic View of Dialogue Management"></a>Decision-theoretic View of Dialogue Management</h3><h4 id="Hybrid-Code-Networks"><a href="#Hybrid-Code-Networks" class="headerlink" title="Hybrid Code Networks"></a>Hybrid Code Networks</h4><ul><li>17: <a href="https://arxiv.org/abs/1702.03274" target="_blank" rel="noopener">Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</a>: Jason D. Williams(Microsoft Research)<h4 id="Differentiating-KB-Accesses"><a href="#Differentiating-KB-Accesses" class="headerlink" title="Differentiating KB Accesses"></a>Differentiating KB Accesses</h4></li><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)<h4 id="An-E2E-Neural-Dialogue-System"><a href="#An-E2E-Neural-Dialogue-System" class="headerlink" title="An E2E Neural Dialogue System"></a>An E2E Neural Dialogue System</h4></li><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul><hr><h2 id="Fully-data-driven-conversation-models-and-chatbots"><a href="#Fully-data-driven-conversation-models-and-chatbots" class="headerlink" title="Fully data-driven conversation models and chatbots"></a>Fully data-driven conversation models and chatbots</h2><h3 id="Historical-overview"><a href="#Historical-overview" class="headerlink" title="Historical overview"></a>Historical overview</h3><h4 id="Response-retrival-system"><a href="#Response-retrival-system" class="headerlink" title="Response retrival system"></a>Response retrival system</h4><ul><li>10: <a href="https://aritter.github.io/chat.pdf" target="_blank" rel="noopener">Filter, Rank, and Transfer the Knowledge: Learning to Chat</a>:<br>Alan Ritter(University of Washington)</li></ul><h4 id="Response-generation-using-Statistical-Machine-Translation"><a href="#Response-generation-using-Statistical-Machine-Translation" class="headerlink" title="Response generation using Statistical Machine Translation"></a>Response generation using Statistical Machine Translation</h4><ul><li>11:  <a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener">Data-Driven Response Generation in Social Media</a>: Alan Ritter(University of Washington)</li></ul><h4 id="First-neural-response-generation-systems"><a href="#First-neural-response-generation-systems" class="headerlink" title="First neural response generation systems"></a>First neural response generation systems</h4><ol><li>Neural Models for Response Generation<ul><li>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>: Alessandro Sordoni(University de Montreal)</li><li>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener">A Neural Conversational Model</a>: Oriol Vinyals(Google .Inc)</li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener">Neural Responding Machine for Short-Text Conversation</a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener">code</a></li></ul></li><li>Neural conversation engine: <ul><li>16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)</li></ul></li></ol><h3 id="challenges-and-remedies"><a href="#challenges-and-remedies" class="headerlink" title="challenges and remedies"></a>challenges and remedies</h3><h4 id="Challenge-The-blandness-problem"><a href="#Challenge-The-blandness-problem" class="headerlink" title="Challenge: The blandness problem"></a>Challenge: The blandness problem</h4><ul><li>[<strong>duplicate</strong>] 16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)<h4 id="Challenge-The-consistency-problem"><a href="#Challenge-The-consistency-problem" class="headerlink" title="Challenge: The consistency problem"></a>Challenge: The consistency problem</h4></li></ul><ol><li>Solution: Personalized Response Generation<ul><li>Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li></ul></li><li>Personal modeling as multi-task learning<ul><li>17: <a href="https://arxiv.org/abs/1710.07388" target="_blank" rel="noopener">Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation Models</a>: Yi Luan(University of Washington)</li></ul></li><li>Improving personalization with multiple losses<ul><li>16: <a href="https://arxiv.org/pdf/1606.00372.pdf" target="_blank" rel="noopener">Conversational Contextual Cues: The Case of Personalization and History for Response Ranking</a>: Rami Al-Rfou(Google .Inc)<h4 id="Challenge-Long-conversational-context"><a href="#Challenge-Long-conversational-context" class="headerlink" title="Challenge: Long conversational context"></a>Challenge: Long conversational context</h4></li></ul></li><li>It can be challenging for LSTM/GRU to encode very long context<ul><li>18: <a href="https://arxiv.org/abs/1805.04623" target="_blank" rel="noopener">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a>: Urvashi Khadelwal(Stanford University)</li></ul></li><li>Hierarchical Encoder-Decoder(HRED), <a href="https://github.com/urvashik/lm-context-analysis" target="_blank" rel="noopener">code</a><ul><li>16: <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160" target="_blank" rel="noopener">Building End-to-End Dialogue Systems Using Generative Hierarchical Neural Network Models</a>: Iulian V.Serban(University de Montreal), <a href="https://github.com/hsgodhia/hred" target="_blank" rel="noopener">code</a></li></ul></li><li>Hierarchical Latent Variable Encoder-Decoder(VHRED)<ul><li>17: <a href="http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf" target="_blank" rel="noopener">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>: Iulian V. Serban</li></ul></li></ol><h3 id="Grounded-conversation-models"><a href="#Grounded-conversation-models" class="headerlink" title="Grounded conversation models"></a>Grounded conversation models</h3><h4 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a>A Knowledge-Grounded Neural Conversation Model</h4><ul><li>15: <a href="https://arxiv.org/pdf/1503.08895.pdf" target="_blank" rel="noopener">End-To-End Memory Networks</a>: Sainbayar Sukhbaatar(New York University)<ul><li><a href="https://github.com/carpedm20/MemN2N-tensorflow" target="_blank" rel="noopener">code1</a> via Tensorflow</li><li><a href="https://github.com/domluna/memn2n" target="_blank" rel="noopener">code2</a> via Tensorflow</li><li><a href="https://github.com/vinhkhuc/MemN2N-babi-python" target="_blank" rel="noopener">code3</a> for bAbI QA tasks</li></ul></li><li>17: <a href="https://arxiv.org/abs/1702.01932" target="_blank" rel="noopener">A Knowledge-Grounded Neural Conversation Model</a>: Marjan Gahzvininejad(USC)<h4 id="Grounded-E2E-Dialogue-Systems"><a href="#Grounded-E2E-Dialogue-Systems" class="headerlink" title="Grounded E2E Dialogue Systems"></a>Grounded E2E Dialogue Systems</h4></li><li>16: <a href="https://arxiv.org/abs/1611.08669" target="_blank" rel="noopener">Visual Dialog</a>: Abhishek Das(Georgia Institute of Tehhnology)<ul><li><a href="https://github.com/batra-mlp-lab/visdial" target="_blank" rel="noopener">code1</a> via Lua</li><li><a href="https://github.com/jiasenlu/visDial.pytorch" target="_blank" rel="noopener">code2</a> via Pytorch</li></ul></li><li>17: <a href="https://arxiv.org/abs/1701.08251" target="_blank" rel="noopener">Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation</a>: Nasrin Mostafazadeh(University of Rochster)</li><li>18: <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/04/huber2018chi.small_.pdf" target="_blank" rel="noopener">Emotional Dialogue Generation using Image-Grounded Language Models</a>:Bernd Huber(Harvard University)</li></ul><h3 id="Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue"><a href="#Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue" class="headerlink" title="Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)"></a>Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)</h3><ul><li>16: <a href="https://arxiv.org/abs/1606.01541" target="_blank" rel="noopener">Deep Reinforcement Learning for Dialogue Generation</a>:Jiwei Li(Stanford University)<ul><li><a href="https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow" target="_blank" rel="noopener">code1</a> via Tensorflow</li><li><a href="https://github.com/agsarthak/Goal-oriented-Dialogue-Systems" target="_blank" rel="noopener">code2</a> via keras</li><li><a href="https://github.com/jiweil/Neural-Dialogue-Generation" target="_blank" rel="noopener">code3</a> by Jiwei Li</li></ul></li></ul><h3 id="Data-and-evaluation"><a href="#Data-and-evaluation" class="headerlink" title="Data and evaluation"></a>Data and evaluation</h3><h4 id="Conversational-datasets-for-social-bots-E2E-dialogue-research"><a href="#Conversational-datasets-for-social-bots-E2E-dialogue-research" class="headerlink" title="Conversational datasets(for social bots, E2E dialogue research)"></a>Conversational datasets(for social bots, E2E dialogue research)</h4><ul><li>15: <a href="https://arxiv.org/abs/1512.05742" target="_blank" rel="noopener">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>: Iulian Vlad Serban(Universite de Montreal)<h4 id="Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation"><a href="#Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation" class="headerlink" title="Evaluating E2E Dialogue Systems via Autumatic evaluation"></a>Evaluating E2E Dialogue Systems via Autumatic evaluation</h4></li></ul><ol><li>Machine-Translation-Based Metric<ul><li>02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>02: <a href="http://www.mt-archive.info/HLT-2002-Doddington.pdf" target="_blank" rel="noopener">Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics</a>: George Doddington</li></ul></li><li>Sentence-level correlation of MT metrics:<ul><li>16: <a href="https://aclweb.org/anthology/D16-1230" target="_blank" rel="noopener">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</a>: Chia-Wei Liu(McGill University)</li><li>15: <a href="http://www.aclweb.org/anthology/N15-1124" target="_blank" rel="noopener">Accurate Evaluation of Segment-level Machine Translation Metrics</a>: Yvette Graham(The University of Melbourne)</li></ul></li></ol><h4 id="The-importance-of-sample-size"><a href="#The-importance-of-sample-size" class="headerlink" title="The importance of sample size"></a>The importance of sample size</h4><ul><li>[<strong>duplicate</strong>] 02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>06: <a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf" target="_blank" rel="noopener">Statistical Significance Tests for Machine Translation Evaluation</a>: Philipp Kowehn(MIT)</li></ul><h4 id="Corpus-level-Correlation"><a href="#Corpus-level-Correlation" class="headerlink" title="Corpus-level Correlation"></a>Corpus-level Correlation</h4><ul><li>[<strong>duplicate</strong>] 02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>[<strong>duplicate</strong>] 06: <a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf" target="_blank" rel="noopener">Statistical Significance Tests for Machine Translation Evaluation</a>: </li></ul><h3 id="Chatbot-in-public"><a href="#Chatbot-in-public" class="headerlink" title="Chatbot in public"></a>Chatbot in public</h3><h4 id="Social-Bots-commercial-systems"><a href="#Social-Bots-commercial-systems" class="headerlink" title="Social Bots: commercial systems"></a>Social Bots: commercial systems</h4><ol><li>For end users<ul><li>Replika.ai system description: <a href="https://github.com/lukalabs/replika-research/blob/master/scai2017/replika_ai.pdf" target="_blank" rel="noopener">replika_ai</a>: Slides</li><li>XiaoIce:<br>15:<a href="https://www.nytimes.com/interactive/2015/07/27/science/chatting-with-xiaoice.html" target="_blank" rel="noopener">Chatting With Xiaoice</a>: News</li></ul></li><li>For bot developers<ul><li>[<strong>duplicate</strong>] Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li><li>Microsoft Personality chat’s API: <a href="https://labs.cognitive.microsoft.com/en-us/project-personality-chat" target="_blank" rel="noopener">Project Personality Chat’s url</a> </li></ul></li></ol><h4 id="Open-Benchmarks"><a href="#Open-Benchmarks" class="headerlink" title="Open Benchmarks"></a>Open Benchmarks</h4><ol><li><p>Alexa Challenge</p><ul><li>website: <a href="https://developer.amazon.com/alexaprize/proceedings" target="_blank" rel="noopener">Alexa Prize Proceedings</a></li></ul></li><li><p>Dialogue System Technology Challenge(DSTC)</p><ul><li><a href="http://workshop.colips.org/dstc7" target="_blank" rel="noopener">DSTC7</a></li><li>Visual-Scene: <a href="https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge" target="_blank" rel="noopener">DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge 2018</a></li><li>background article:<br><a href="https://github.com/DSTC-MSR-NLP/DSTC7-End-to-End-Conversation-Modeling" target="_blank" rel="noopener">DSTC7-End-to-End-Conversation-Modeling 2018</a></li><li>Registration Link:<br><a href="http://workshop.colips.org/dstc7/call.html" target="_blank" rel="noopener">DSTC7 Registration</a></li></ul></li></ol>]]></content>
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> chatbot </tag>
            
            <tag> conversationalAI </tag>
            
            <tag> nlp </tag>
            
            <tag> paper </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>对话AI的术语和学习地图</title>
      <link href="/2018/08/08/convAI-map-and-term/"/>
      <url>/2018/08/08/convAI-map-and-term/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="chatbot基本篇"><a href="#chatbot基本篇" class="headerlink" title="chatbot基本篇"></a>chatbot基本篇</h2><ul><li><p>Natural language processing(自然语言处理/NLP)<br>自然语言处理是人工智能的一个子集领域。自然语言处理是一项包罗万象且相当复杂的技术，它包含许多子集，如自然语言理解。<br>NLP指的是机器理解人类输入的所有东西。为此，NLP引擎将使用许多工具，如NLU，总结算法，情绪分析，标记化等等。</p></li><li><p>Natural language understanding (自然语言理解/NLU)<br>自然语言理解是自然语言处理的一个子集。NLU和NLP经常被混淆，因为它们的意思非常接近。<br>NLU是NLP引擎中非常具体的部分，它检查话语并提取其实体和意图。用更通俗的话说，NLU允许机器理解用户在说什么。<br>说到聊天机器人，可以把NLU想象成阅读人类语言并识别文本不同部分的过程，把它分解成正确的意图和实体</p></li><li><p>Chatbot(聊天机器人)<br><code>chatbot</code>是一个可对话的计算机程序。但是<strong>对话agent</strong>可能是形容这个程序更好的词汇。</p></li><li><p>Utterance(表达)<br>用户对chatbot说的任何话，也可以看做是用户输入。例如，如果用户输入“给我看昨天的财经新闻”，整个句子就是<code>Utterance</code>。</p></li><li><p>Intent(意图))<br><code>Intent</code>代表了用户<code>Utterance</code>的意义。Chatbot将会根据用户一系列的<code>Intent</code>和对<code>Intent</code>的理解来回应用户。例如，如果用户输入“show me yesterday’s financial news”，用户的意图是检索金融标题列表。<code>Intent</code>通常是一个动词和一个名词，如“showNews”。</p></li><li><p>Entity(实体)<br><code>Entity</code>通常修饰<code>Intent</code>。例如，如果用户输入“show me yesterday’s financial news”，那么<code>Entity</code>是“yesterday”和“financial”。<code>Entity</code>会被赋予一个名称，例如“dateTime”和“newsType”。<code>Entity</code>有时也被称为<code>Slots</code>。</p></li></ul><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fu2otnnx3oj21r60x246f.jpg" alt=""></p><ul><li><p>Broadcast(广播)<br><code>Broadcast</code>是预先发送给用户的消息。它不是对用户输入的响应。<code>Broadcast</code>也被称为“订阅消息”，它相当于聊天机器人中的移动应用程序中的推送消息。</p></li><li><p>Ambiguity</p></li><li>Paraphrase</li><li>metric</li></ul><h2 id="术语进阶篇"><a href="#术语进阶篇" class="headerlink" title="术语进阶篇"></a>术语进阶篇</h2><h3 id="NLP常用术语"><a href="#NLP常用术语" class="headerlink" title="NLP常用术语"></a>NLP常用术语</h3><h4 id="词级别"><a href="#词级别" class="headerlink" title="词级别"></a>词级别</h4><ul><li>分词（Seg）</li><li>词性标注（POS）</li><li>命名实体识别（NER）</li><li>未登录词识别</li><li>词向量（word2vec）</li><li>词义消歧</li></ul><h4 id="句子级别"><a href="#句子级别" class="headerlink" title="句子级别"></a>句子级别</h4><ul><li>情感分析</li><li>关系提取</li><li>意图识别</li><li>依存句法分析（parser）</li><li>角色标注，</li><li>浅层语义分析，</li><li>指代消解</li></ul><h4 id="篇章级别"><a href="#篇章级别" class="headerlink" title="篇章级别"></a>篇章级别</h4><ul><li>信息抽取：</li><li>本体提取：</li><li>事件抽取：</li><li>主题提取：</li><li>文档聚类：</li><li>舆情分析：</li><li>篇章理解：</li><li>自动文摘：</li></ul><h4 id="常用基础算法："><a href="#常用基础算法：" class="headerlink" title="常用基础算法："></a>常用基础算法：</h4><ol><li><p>机器学习：</p><ul><li>隐马尔科夫（HMM）</li><li>条件随机场（CRF）</li><li>支持向量机（SVM）</li><li>语言模型</li><li>主题模型（LDA）</li><li>TF-IDF</li><li>互信息（PMI）</li><li>贝叶斯模型</li><li>概率图模型   </li></ul></li><li><p>深度学习:</p></li></ol><h3 id="Qustion-Answering-QA"><a href="#Qustion-Answering-QA" class="headerlink" title="Qustion Answering(QA)"></a>Qustion Answering(QA)</h3><h3 id="Reinfoecement-Learning-强化学习-RL"><a href="#Reinfoecement-Learning-强化学习-RL" class="headerlink" title="Reinfoecement Learning(强化学习/RL)"></a>Reinfoecement Learning(强化学习/RL)</h3><h3 id="Markov-Decision-Process-马尔科夫决策过程-MDP"><a href="#Markov-Decision-Process-马尔科夫决策过程-MDP" class="headerlink" title="Markov Decision Process(马尔科夫决策过程/MDP)"></a>Markov Decision Process(马尔科夫决策过程/MDP)</h3><h3 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP"></a>POMDP</h3><h3 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h3><h3 id="Phonology"><a href="#Phonology" class="headerlink" title="Phonology"></a>Phonology</h3><h3 id="分词（Segment）"><a href="#分词（Segment）" class="headerlink" title="分词（Segment）"></a>分词（Segment）</h3><p>中英文都存在分词的问题，不过相对来说，英文单词与单词之间本来就有空格进行分割，所以处理起来相对方便。但是中文书写是没有分隔符的，所以分词的问题就比较突出。分词常用的手段可以是基于字典的最长串匹配，据说可以解决85%的问题，但是歧义分词很难。另外就是当下主流的统计机器学习的办法。</p><h3 id="词性标注（Label）"><a href="#词性标注（Label）" class="headerlink" title="词性标注（Label）"></a>词性标注（Label）</h3><p>基于机器学习的方法里，往往需要对词的词性进行标注。标注的目的是用来表示，词的一种隐状态，隐藏状态构成的转移就构成了状态转移序列。例如：苏宁易购/n 投资/v 了/u 国际米兰/n。其中，n代表名词，v代表动词，n,v都是标注。以此类推。</p><h3 id="命名实体识别（Named-Entity-Recognition）"><a href="#命名实体识别（Named-Entity-Recognition）" class="headerlink" title="命名实体识别（Named Entity Recognition）"></a>命名实体识别（Named Entity Recognition）</h3><p>本质上还是标注问题的一种。只不过把标注细化了。比如，苏宁/cmp_s 易购/cmp_e 是/v B2C/n 电商/n。我们把苏宁易购 标注成cmp_s和cmp_e,分别表征公司名的起始和结束。这样，当遇上苏宁/云商/易购这种场景时，也可以完整得识别出它是一个公司名称。如果，按照传统的标注方式，苏宁/cmp 易购/cmp这样笼统地标注可能会有问题。</p><h3 id="句法分析（Syntax-Parsing）"><a href="#句法分析（Syntax-Parsing）" class="headerlink" title="句法分析（Syntax Parsing）"></a>句法分析（Syntax Parsing）</h3><p>句法分析往往是一种基于规则的专家系统。当然也不是说它不能用统计学的方法进行构建，不过最初的时候，还是利用语言学专家的知识来构建的。句法分析的目的是解析句子的中各个成分的依赖关系。所以，往往最终生成的结果，是一棵句法分析树。句法分析可以解决传统词袋模型不考虑上下文的问题。比如，张三是李四的领导；李四是张三的领导。这两句话，用词袋模型是完全相同的，但是句法分析可以分析出其中的主从关系，真正理清句子的关系。</p><h3 id="指代消解-Anaphora-Resolution"><a href="#指代消解-Anaphora-Resolution" class="headerlink" title="指代消解(Anaphora Resolution)"></a>指代消解(Anaphora Resolution)</h3><p>中文中代词出现的频率很高，它的作用的是用来表征前文出现过的人名、地名等词。例如，苏宁易购坐落在南京，这家公司目前位于中国B2C市场前三。在这句话中，其实“苏宁易购”这个词出现了2次，“这家公司”指代的就是苏宁易购。但是出于中文的习惯，我们不会把“苏宁易购”再重复一遍。</p><h2 id="AI模型篇"><a href="#AI模型篇" class="headerlink" title="AI模型篇"></a>AI模型篇</h2><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h3 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h3><h3 id="Machine-Reading-Comprehension-MRC"><a href="#Machine-Reading-Comprehension-MRC" class="headerlink" title="Machine Reading Comprehension(MRC)"></a>Machine Reading Comprehension(MRC)</h3><h3 id="Knowledge-Base-QA-KBQA"><a href="#Knowledge-Base-QA-KBQA" class="headerlink" title="Knowledge Base-QA(KBQA)"></a>Knowledge Base-QA(KBQA)</h3><ul><li>WordNet(1998)</li><li>Freebase(2008)</li><li>Yago(2007)</li></ul><h3 id="Knowledge-base-completion-KBC"><a href="#Knowledge-base-completion-KBC" class="headerlink" title="Knowledge base completion(KBC)"></a>Knowledge base completion(KBC)</h3><h2 id="chatbot领域学习地图："><a href="#chatbot领域学习地图：" class="headerlink" title="chatbot领域学习地图："></a>chatbot领域学习地图：</h2><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fue50ug6o9j217m88pb2c.jpg" alt=""></p><blockquote><p>参考与引用</p><ol><li><a href="https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/</a></li><li><a href="https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4" target="_blank" rel="noopener">https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4</a></li><li><a href="https://blog.ubisend.com/discover-chatbots/chatbot-glossary" target="_blank" rel="noopener">https://blog.ubisend.com/discover-chatbots/chatbot-glossary</a></li><li><a href="https://blog.csdn.net/wangongxi/article/details/52662177" target="_blank" rel="noopener">https://blog.csdn.net/wangongxi/article/details/52662177</a></li><li><a href="https://www.jianshu.com/p/d7ec29abbcb8" target="_blank" rel="noopener">https://www.jianshu.com/p/d7ec29abbcb8</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> chatbot </tag>
            
            <tag> conversationalAI </tag>
            
            <tag> nlp </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习手写笔记</title>
      <link href="/2018/08/03/Deeplearning-note/"/>
      <url>/2018/08/03/Deeplearning-note/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><div class="row"><iframe src="https://drive.google.com/file/d/14hBEl8WUtbBdDHcIE4uAMledytupRDzP/preview" style="width:100%; height:550px"></iframe></div>]]></content>
      
      <categories>
          
          <category> HandWriting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deepLearning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>博客主题配置</title>
      <link href="/2018/07/26/blog-config/"/>
      <url>/2018/07/26/blog-config/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="hexo基本使用"><a href="#hexo基本使用" class="headerlink" title="hexo基本使用"></a>hexo基本使用</h2><h3 id="创建新页面"><a href="#创建新页面" class="headerlink" title="创建新页面"></a>创建新页面</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page your_page_name</span><br></pre></td></tr></table></figure><p>执行命令后会生成<code>/source/your_page_name/index.md</code>。</p><p>接着在<code>theme/next/_condig.yml</code>找到<code>menu</code>属性设置路由即可。</p><p>如有必要，需要在<code>theme/next/languages</code>找到<code>menu</code>进行设置。</p><h3 id="创建新博客文章"><a href="#创建新博客文章" class="headerlink" title="创建新博客文章"></a>创建新博客文章</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 创建新的文章</span><br><span class="line">hexo new post your_post_name</span><br><span class="line"><span class="meta">#</span> 创建新的草稿</span><br><span class="line">hexo new draft your_draft_name</span><br></pre></td></tr></table></figure><h2 id="博客主题的基本配置"><a href="#博客主题的基本配置" class="headerlink" title="博客主题的基本配置"></a>博客主题的基本配置</h2><p>博客基本信息修改位置为：<code>/_config.yml</code></p><h3 id="博客logo修改位置为："><a href="#博客logo修改位置为：" class="headerlink" title="博客logo修改位置为："></a>博客logo修改位置为：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/themes/next/source/images/apple-touch-icon-next.png;/themes/next/source/images/favicon-16*16-next.png;/themes/next/source/images/favicon-32*32-next.png;</span><br></pre></td></tr></table></figure><p>三个文件需要修改，缩放图片建议使用百度搜索的<strong>改图宝</strong>。</p><h3 id="博客大背景图片修改位置为："><a href="#博客大背景图片修改位置为：" class="headerlink" title="博客大背景图片修改位置为："></a>博客大背景图片修改位置为：</h3><p><code>/theme/next/source/css/_custom/custom.styl</code></p><h3 id="在右上角实现fork-me-on-github"><a href="#在右上角实现fork-me-on-github" class="headerlink" title="在右上角实现fork me on github:"></a>在右上角实现fork me on github:</h3><p>从<a href="https://github.com/blog/273-github-ribbons" target="_blank" rel="noopener">这里</a>复制代码到<code>themes/next/layout/_layout.swig</code>文件中的<code>&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</code>一句下面并修改<code>href</code>。</p><h3 id="点击动画特效："><a href="#点击动画特效：" class="headerlink" title="点击动画特效："></a>点击动画特效：</h3><p>修改位置为<code>themes/next/source/js/src/click-effect.js</code>，动画特效可以自己DIY,默认设置的特效为社会主义核心价值观。</p><h3 id="修改文章底部的那个带-号的标签为更漂亮的样式："><a href="#修改文章底部的那个带-号的标签为更漂亮的样式：" class="headerlink" title="修改文章底部的那个带#号的标签为更漂亮的样式："></a>修改文章底部的那个带#号的标签为更漂亮的样式：</h3><p>修改模板<code>/themes/next/layout/_macro/post.swig</code>，搜索<code>rel=&quot;tag&quot;&gt;#</code>，将<code>#</code>换成<code>&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code></p><h3 id="修改作者头像："><a href="#修改作者头像：" class="headerlink" title="修改作者头像："></a>修改作者头像：</h3><p><code>/themes/next/source/images/avater.jpg</code></p><h3 id="语言设置bug"><a href="#语言设置bug" class="headerlink" title="语言设置bug:"></a>语言设置bug:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.在hexo 文件夹里主题 next文件夹里的language 文件夹 找到 zh-Hans.yml 重命名 zh-CN.yml</span><br><span class="line">2.在hexo 文件夹里的_config.yml 修改 language: zh-CN</span><br></pre></td></tr></table></figure><h3 id="文章加密访问："><a href="#文章加密访问：" class="headerlink" title="文章加密访问："></a>文章加密访问：</h3><p>打开<code>themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig</code>文件，在<code>rel=&quot;stylesheet&quot;</code>的下一行添加如下代码：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    (<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">'&#123;&#123; page.password &#125;&#125;'</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (prompt(<span class="string">'请输入文章密码'</span>) !== <span class="string">'&#123;&#123; page.password &#125;&#125;'</span>) &#123;</span><br><span class="line">                alert(<span class="string">'密码错误！'</span>);</span><br><span class="line">                <span class="keyword">if</span> (history.length === <span class="number">1</span>) &#123;</span><br><span class="line">                    location.replace(<span class="string">"http://xxxxxxx.xxx"</span>); <span class="comment">// 这里替换成你的首页</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    history.back();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)();</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure></p><p>使用方法如下：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1ftorxsujudj20k00c6dgz.jpg" alt=""></p><h3 id="友情链接设置：在-themes-next-config-yml的Blog-rolls中这只链接即可"><a href="#友情链接设置：在-themes-next-config-yml的Blog-rolls中这只链接即可" class="headerlink" title="友情链接设置：在/themes/next/_config.yml的Blog rolls中这只链接即可"></a>友情链接设置：在<code>/themes/next/_config.yml</code>的Blog rolls中这只链接即可</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Blog rolls</span><br><span class="line">links_icon: link</span><br><span class="line">links_title: 友情链接</span><br><span class="line"># links_layout: block</span><br><span class="line">links_layout: inline</span><br><span class="line">links:</span><br><span class="line">  your links</span><br></pre></td></tr></table></figure><h3 id="自定义鼠标样式："><a href="#自定义鼠标样式：" class="headerlink" title="自定义鼠标样式："></a>自定义鼠标样式：</h3><p>在<code>/themes/next/source/css/_custom/custom.styl</code>中添加如下代码</p><p>鼠标样式的<code>ico</code>文件有需要的话可以<a href="http://www.rw-designer.com/cursor-library" target="_blank" rel="noopener">来这里</a>自己DIY。</p><h3 id="博客添加打赏功能："><a href="#博客添加打赏功能：" class="headerlink" title="博客添加打赏功能："></a>博客添加打赏功能：</h3><p>在<code>/themes/next/_config.yml</code>中搜索reward并对收款码进行修改。</p><h2 id="第三方服务配置"><a href="#第三方服务配置" class="headerlink" title="第三方服务配置"></a>第三方服务配置</h2><h3 id="添加RSS"><a href="#添加RSS" class="headerlink" title="添加RSS:"></a>添加RSS:</h3><p>配置位置分别为<code>/_config.yml</code>与<code>/themes/next/_config.yml</code></p><h3 id="访客统计："><a href="#访客统计：" class="headerlink" title="访客统计："></a>访客统计：</h3><p>根据<a href="https://blog.csdn.net/ganzhilin520/article/details/79048021" target="_blank" rel="noopener">教程</a>，在leancloud注册并新建应用，获取id和key后填写到<code>_config.yml</code>里<code>leancloud_visitors</code>的属性中。</p><h3 id="为博客添加宠物："><a href="#为博客添加宠物：" class="headerlink" title="为博客添加宠物："></a>为博客添加宠物：</h3><p>在终端输入<code>npm install -save hexo-helper-live2d</code>在<code>/themes/next/_config.yml</code>中添加代码,详情请见<a href="https://github.com/EYHN/hexo-helper-live2d/blob/61b581634a916cf4ce035c1685174cb2755264f3/README.zh-CN.md" target="_blank" rel="noopener">这里</a></p><h3 id="博客在线显示pdf功能"><a href="#博客在线显示pdf功能" class="headerlink" title="博客在线显示pdf功能"></a>博客在线显示pdf功能</h3><p>首先安装插件<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-pdf</span><br></pre></td></tr></table></figure></p><p>使用方法为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;% pdf http://your_pdf_link.pdf %&#125;</span><br><span class="line">&#123;% pdf ./your_pdf_**relative**_path %&#125;</span><br></pre></td></tr></table></figure></p><h3 id="修改博客的搜索功能："><a href="#修改博客的搜索功能：" class="headerlink" title="修改博客的搜索功能："></a>修改博客的搜索功能：</h3><p>建议使用algolia,因为swiftype已收费。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-algolia --save</span><br><span class="line">```    </span><br><span class="line">在`/themes/next/_config.yml`中搜索algolia,添加代码：</span><br><span class="line">``` js</span><br><span class="line">algolia:</span><br><span class="line">  applicationID: your_algolia_ud</span><br><span class="line">  apiKey: your_apiKey</span><br><span class="line">  indexName: your_index</span><br></pre></td></tr></table></figure></p><h3 id="文章置顶功能"><a href="#文章置顶功能" class="headerlink" title="文章置顶功能"></a>文章置顶功能</h3><p>安装第三方插件<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-generator-index --save</span><br></pre></td></tr></table></figure></p><p>对需要置顶的文章添加属性即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: hexo+GitHub博客搭建实战</span><br><span class="line">date: 2017-09-08 12:00:25</span><br><span class="line">categories: 博客搭建系列</span><br><span class="line">**top: true**</span><br><span class="line">---</span><br></pre></td></tr></table></figure></p><blockquote><p>参考与引用</p><ol><li><a href="https://blog.csdn.net/qq_33232071/article/details/51108062" target="_blank" rel="noopener">https://blog.csdn.net/qq_33232071/article/details/51108062</a></li><li><a href="https://hexo.io/zh-cn/docs/setup.html" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/setup.html</a></li><li><a href="http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html" target="_blank" rel="noopener">http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html</a></li><li><a href="https://segmentfault.com/a/1190000009544924#articleHeader21" target="_blank" rel="noopener">https://segmentfault.com/a/1190000009544924#articleHeader21</a></li><li><a href="https://github.com/shenzekun/shenzekun.github.io/blob/hexo/themes/next/layout/_layout.swig" target="_blank" rel="noopener">https://github.com/shenzekun/shenzekun.github.io/blob/hexo/themes/next/layout/_layout.swig</a></li><li><a href="https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E4%B8%BB%E4%B9%89%E6%A0%B8%E5%BF%83%E4%BB%B7%E5%80%BC%E8%A7%82/3271832?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E4%B8%BB%E4%B9%89%E6%A0%B8%E5%BF%83%E4%BB%B7%E5%80%BC%E8%A7%82/3271832?fr=aladdin</a></li><li><a href="https://blog.csdn.net/ganzhilin520/article/details/79048021" target="_blank" rel="noopener">https://blog.csdn.net/ganzhilin520/article/details/79048021</a></li><li><a href="https://www.zhihu.com/question/41625825" target="_blank" rel="noopener">https://www.zhihu.com/question/41625825</a></li><li><a href="https://www.jianshu.com/p/f5c184047e72" target="_blank" rel="noopener">https://www.jianshu.com/p/f5c184047e72</a></li><li><a href="https://github.com/xiaweizi/BackupBlog/commit/b97173da33837604a31f2e5f78b17ba819306f74" target="_blank" rel="noopener">https://github.com/xiaweizi/BackupBlog/commit/b97173da33837604a31f2e5f78b17ba819306f74</a></li><li><a href="https://blog.csdn.net/luzheqi/article/details/52798557" target="_blank" rel="noopener">https://blog.csdn.net/luzheqi/article/details/52798557</a></li><li><a href="https://blog.csdn.net/qwerty200696/article/details/79010629" target="_blank" rel="noopener">https://blog.csdn.net/qwerty200696/article/details/79010629</a></li><li><a href="https://blog.csdn.net/pop1586082213/article/details/54576131" target="_blank" rel="noopener">https://blog.csdn.net/pop1586082213/article/details/54576131</a></li><li><a href="https://github.com/nodejs/node-v0.x-archive/issues/3911" target="_blank" rel="noopener">https://github.com/nodejs/node-v0.x-archive/issues/3911</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Blog </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hexo-next </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>信息科学原理手写笔记</title>
      <link href="/2018/07/18/infomation-science-handwriting/"/>
      <url>/2018/07/18/infomation-science-handwriting/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="课堂笔记"><a href="#课堂笔记" class="headerlink" title="课堂笔记"></a>课堂笔记</h2><div class="row"><iframe src="https://drive.google.com/file/d/1lli8ZJgdkfyIBUT6-CmVPeujpqpfpJGu/preview" style="width:100%; height:550px"></iframe></div><h2 id="题目参考"><a href="#题目参考" class="headerlink" title="题目参考"></a>题目参考</h2><div class="row"><iframe src="https://drive.google.com/file/d/1Gsc5yuhNsulK-0hRGNEEZ_0QumcebPQJ/preview" style="width:100%; height:550px"></iframe></div><h2 id="题目索引"><a href="#题目索引" class="headerlink" title="题目索引"></a>题目索引</h2><div class="row"><iframe src="https://drive.google.com/file/d/1HaiyMuEi_VjEyKDH3KEchJMT1TEusPio/preview" style="width:100%; height:550px"></iframe></div>]]></content>
      
      <categories>
          
          <category> HandWriting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> informationScience </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>模式识别与机器学习手写笔记</title>
      <link href="/2018/07/10/PRML-handwriting/"/>
      <url>/2018/07/10/PRML-handwriting/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="课堂笔记"><a href="#课堂笔记" class="headerlink" title="课堂笔记"></a>课堂笔记</h2><div class="row"><iframe src="https://drive.google.com/file/d/145ag3TfrL6bY222mopcvCnCedipimPdu/preview" style="width:100%; height:550px"></iframe></div><p>##考试大抄<br><div class="row"><iframe src="https://drive.google.com/file/d/1N8rNwzZp8jq2IvkrDh4LjS0E8S_dpCdM/preview" style="width:100%; height:550px"></iframe></div></p>]]></content>
      
      <categories>
          
          <category> HandWriting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> prml </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>强化学习-DavidSilver(Lecture1 to Lecture3)</title>
      <link href="/2018/06/30/RL-DavidSilver-1-3/"/>
      <url>/2018/06/30/RL-DavidSilver-1-3/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>本科毕业设计的强化学习笔记。许多强化学习的术语使用中文表达容易产生歧义，因此本笔记使用英文。 <a href="https://www.youtube.com/watch?v=2pWv7GOvuf0" target="_blank" rel="noopener">David Silver强化学习课程视频网址</a><br><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">David Silver强化学习课程课件</a>。</p></blockquote><h2 id="Lecture-One"><a href="#Lecture-One" class="headerlink" title="Lecture One"></a>Lecture One</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li>all is about decision</li><li>no supervisor,only <strong>reward</strong> signal(not supervisor learning)</li><li>feedback is delayed,not instantaneous</li><li>the key role:<strong>agent</strong>(brain)</li></ul><h3 id="The-process"><a href="#The-process" class="headerlink" title="The process"></a>The process</h3><ul><li>background:environment(earth) input: observation &amp; reward –&gt; output:action</li><li>history and state:<br>History:  $$H_t=A_1,O_1,A_2,O_2…A_t,O_t,R_t$$<br>State of agent :    $$S_t^a=f(H_t)$$<br>State of environment:    $$S_t=f(H_t)$$</li></ul><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg5bizsrj20xg0ictf8.jpg" alt=""></p><h3 id="keys-of-fundamental-assumptions"><a href="#keys-of-fundamental-assumptions" class="headerlink" title="keys of fundamental assumptions"></a>keys of fundamental assumptions</h3><ol><li>Markov state</li><li>agent may conclude</li></ol><ul><li>policy:to decide agent’s function towards current state</li><li>value:predictive reward of agent’s action</li><li>model:a metaphysical regulation of “world”(<strong>state</strong>&amp;<strong>reward</strong>)</li></ul><ol start="3"><li>exploitation(choose old) and exploration(choose new)</li></ol><h3 id="The-classification-of-agent"><a href="#The-classification-of-agent" class="headerlink" title="The classification of agent"></a>The classification of agent</h3><ul><li>Value Based: only need $max(V)$</li><li>Policy Based: get action directly by state</li><li>AC(Actor Critic):act(i.e. policy), critic(i.e. value function)</li></ul><h3 id="let-us-review-immediately"><a href="#let-us-review-immediately" class="headerlink" title="let us review immediately"></a>let us review immediately</h3><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg3rvl2wj21yu2kz7wh.jpg" alt=""></p><hr><h2 id="Lecture-Two"><a href="#Lecture-Two" class="headerlink" title="Lecture Two"></a>Lecture Two</h2><h3 id="introduction-to-MDP-markov-decision-process"><a href="#introduction-to-MDP-markov-decision-process" class="headerlink" title="introduction to MDP(markov decision process)"></a>introduction to MDP(markov decision process)</h3><blockquote><p>almost all RL problems can be formalised as MDPs</p></blockquote><h3 id="Markov-Property-and-Markov-Process"><a href="#Markov-Property-and-Markov-Process" class="headerlink" title="Markov Property and Markov Process"></a>Markov Property and Markov Process</h3><blockquote><p>the future is independent of the past given the present</p></blockquote><h4 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg8lkc95j20x607mq3j.jpg" alt=""></p><h4 id="Markov-Process"><a href="#Markov-Process" class="headerlink" title="Markov Process"></a>Markov Process</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg9h4fybj20ww08gjst.jpg" alt=""></p><h3 id="State-Transition-Matrix"><a href="#State-Transition-Matrix" class="headerlink" title="State Transition Matrix"></a>State Transition Matrix</h3><blockquote><p>the state transition probability for a Markov state and successor state</p></blockquote><h3 id="Markov-Reward-Process"><a href="#Markov-Reward-Process" class="headerlink" title="Markov Reward Process"></a>Markov Reward Process</h3><blockquote><p>A Markov reward process is a Markov chain with values.(State,Probability,Reward,Discount factor-gamma)</p></blockquote><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fse949pfxej21410f1di6.jpg" alt=""></p><h4 id="return-G"><a href="#return-G" class="headerlink" title="return(G)"></a>return(<strong>G</strong>)</h4><blockquote><p>the return G is the total discounted reward from time-step t. </p></blockquote><p>$$G_t = R_{t+1}+{\gamma}R_{t+2}+ {\gamma} ^2R_{t+3}…+{\gamma}^kR_{t+k+1}$$<br>　we could figure out from equation above if discount factor closes to 0 the return will be “myopic”, if discount factor nevertheless closes to 1 then the return will be “far-sighted”</p><h4 id="Value-Function-Expectation"><a href="#Value-Function-Expectation" class="headerlink" title="Value Function:Expectation"></a>Value Function:<strong>Expectation</strong></h4><blockquote><p>the value function v(s) gives the long-term value of state s.</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgan5dxdj20xa08qjsh.jpg" alt=""></p><p>then we could deduce MRP Bellman Equation below:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgbhlcxoj211s0a4t9x.jpg" alt=""></p><p>Reward only relates to state,therefore Bellman Equation can be decomposition said by:<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgc2frlqj211i0hc3zu.jpg" alt=""></p><h4 id="Bellman-Equation-for-MRPs-in-matrix"><a href="#Bellman-Equation-for-MRPs-in-matrix" class="headerlink" title="Bellman Equation for MRPs in matrix:"></a>Bellman Equation for MRPs in matrix:</h4><p>The bellman equation can be expressed concisely using matrics:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgoq6yy1j211k0j0wg3.jpg" alt=""></p><p>The bellman equation is a kind of linear equation so we could solve it directly:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgfys2wej212w0aimxx.jpg" alt=""></p><p>But time complexity is close to $O(n^3)$,we could solve it by iteration methods:</p><ul><li>Dynamic Programming</li><li>Monto Carlo evaluation</li><li>Temporal-Difference(TD) Learning</li></ul><p>Let us see some other concepts for preparing!</p><h3 id="Markov-Decision-Processes"><a href="#Markov-Decision-Processes" class="headerlink" title="Markov Decision Processes"></a>Markov Decision Processes</h3><blockquote><p>Markov Decison Processes (S,A,P,R,$\gamma$) is a Markov Reward Processed with decisons.It is an environment in which all states are Markov</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgr8o1hsj20q40b6gng.jpg" alt=""></p><h4 id="Policies"><a href="#Policies" class="headerlink" title="Policies"></a>Policies</h4><blockquote><p>A policy $\pi$ is a distribution over actions given states.</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgruhsrtj20bs028q2u.jpg" alt=""></p><p>for MDP, we must calculate state-value function and action-value function, we have definition below:<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgsgz1gaj20pu0esdhw.jpg" alt=""></p><p>just like bellman equation, we could deduce bell expectation equation from state-value function and action-value function:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgtf593bj20r60di0tx.jpg" alt=""></p><p>we finally have different Bellman Expectation Equation for $V^{\pi}$,$Q^{\pi}$ and the Matrix Form is：</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsthdw3ihrj20ow0diaav.jpg" alt=""></p><h4 id="Optimal-Value-Functions"><a href="#Optimal-Value-Functions" class="headerlink" title="Optimal Value Functions"></a>Optimal Value Functions</h4><p>Coming question, how could we judge the performance of our policy?</p><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fseb9v3uaxj20rm0dl3zx.jpg" alt=""></p><h4 id="Optimal-Bellman-Equation"><a href="#Optimal-Bellman-Equation" class="headerlink" title="Optimal Bellman Equation"></a>Optimal Bellman Equation</h4><p>we could deduce the Optimal Bellman Eqution from above first:</p><p align="center"><br>    <img with="400px" height="400px" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthiix1lcj20h00dmdgm.jpg"><br></p><p align="center"><br>    <img with="300px" height="300px" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthirugdzj20lo0coq3t.jpg"><br></p><p>we could solve the equation by:</p><ul><li>Value iteration</li><li>Police iteration</li><li>Q-Learning</li><li>Sarsa</li></ul><h3 id="extension-of-MDP"><a href="#extension-of-MDP" class="headerlink" title="extension of MDP"></a>extension of MDP</h3><ul><li>infinite MDPS</li><li>Reductions of POMDP’s</li></ul><h4 id="infinite-MDPs"><a href="#infinite-MDPs" class="headerlink" title="infinite MDPs"></a>infinite MDPs</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsthjqcbhoj20p80gq767.jpg" alt=""></p><h4 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP:"></a>POMDP:</h4><p>It could be seen as a Hidden Markov Process adding actions!</p><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsebmimapgj21180lejux.jpg" alt=""></p><h3 id="Let-us-review-immediately"><a href="#Let-us-review-immediately" class="headerlink" title="Let us review immediately!"></a>Let us review immediately!</h3><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthrducjcj21yu2kz4r0.jpg" alt=""><br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthqqzx45j21yu2kz1l8.jpg" alt=""></p><hr><h2 id="Lecture-3-Planning-by-Dynamic-Programming"><a href="#Lecture-3-Planning-by-Dynamic-Programming" class="headerlink" title="Lecture 3 : Planning by Dynamic Programming"></a>Lecture 3 : Planning by Dynamic Programming</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><strong>Dynamic</strong> sequential or temporal component to the problem</li><li><strong>Programming</strong> is a optimision of question!<ul><li>optimal substructure</li><li>overlapping subproblems</li></ul></li></ul><p>&emsp;&emsp;There are two applications of DP</p><ol><li><p>for prediction:</p><ul><li>Input：MDP &amp; policy $\pi$</li><li>Output: value function $v_\pi$</li></ul></li><li><p>for control</p><ul><li>Input: MDP</li><li>Output: optimal value function $v_<em>$ &amp; optimal policy $\pi_</em>$</li></ul></li></ol><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsthz8kmyjj21yu2kzb29.jpg" alt=""></p><h3 id="Iterative-Policy-Evaluation"><a href="#Iterative-Policy-Evaluation" class="headerlink" title="Iterative Policy Evaluation"></a>Iterative Policy Evaluation</h3><p>How to evaluate $\pi$?</p><ul><li>solition:iterative application of bellman expectation backup to get the true value function($V_0-&gt;V_\pi$)</li><li>from end to start by iteration.</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst51czfmaj20pm0ewmy8.jpg" alt=""></p><p>&emsp;&emsp;It is just like a weighted average of every probability of each action.</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst8a8p85fj20om0kutb7.jpg" alt=""></p><p>the detail you could see the manuscript!</p><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RL5.jpg" alt=""></p><h3 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration:"></a>Policy Iteration:</h3><ol><li>evaluate the policy $\pi$：fill the maze with number to get $v_\pi$<br>$$V_\pi(s) = E[R_{t+1}+\gamma R_{t+2}+…|S_t = s]$$</li><li>improve the policy by acting greedy with respect to $v_\pi$<br>$$\pi^{‘} = greedy(v_\pi) $$</li></ol><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst59a5cd0j20vr0fn42a.jpg" alt=""></p><ol start="3"><li>Policy improvement:</li></ol><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst9t2rt9bj20vi0kmtc8.jpg" alt=""></p><p>the details you could see the manuscript!<br><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RL5.jpg" alt=""></p><h3 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h3><p>The solution v∗(s) can be found by one-step lookahead, and it start with final rewards and work backwards:<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst5i9k9fzj20vr04ljrr.jpg" alt=""></p><p>There is an example:<br><img src="leanote://file/getImage?fileId=5b373da1afc5ce605c000001" alt=""></p><p>the details you could see the manuscript!</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst5j0ochmj20vo0fcmyf.jpg" alt=""></p><h3 id="Synchronous-Dynamic-Programming-Algorithms"><a href="#Synchronous-Dynamic-Programming-Algorithms" class="headerlink" title="Synchronous Dynamic Programming Algorithms"></a>Synchronous Dynamic Programming Algorithms</h3><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fstbt3m1pkj20wg0aiq4p.jpg" alt=""></p><p>we could see Iterative Policy Evaluation and Policy Iteration as a whole knowledge. The knowledge is all in consideration of policy.They as the same in essence.</p><h3 id="Asynchronous-Dynamic-Programming"><a href="#Asynchronous-Dynamic-Programming" class="headerlink" title="Asynchronous Dynamic Programming"></a>Asynchronous Dynamic Programming</h3><ul><li>In-Place Dynamic Programming</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fstet5a8koj20w60iaacj.jpg" alt=""></p><p>the main difference between two methods above is the number of copy for reducing storage.</p><ul><li>Prioritised sweeping</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fstevcscvuj20w00eowgs.jpg" alt=""></p><ul><li>Real-time dynamic programming</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fsteyfhrxoj20rm0cswg6.jpg" alt=""></p>]]></content>
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reinforcementLearning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>卷积神经网络</title>
      <link href="/2018/06/29/CNN-note/"/>
      <url>/2018/06/29/CNN-note/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="视觉感知"><a href="#视觉感知" class="headerlink" title="视觉感知"></a>视觉感知</h2><blockquote><p>相同的图片经过不同的视觉系统，会得到适合自己生存环境的感知。</p></blockquote><p>不同的观察角度，决定了图片的识别结果。</p><h2 id="图像表达"><a href="#图像表达" class="headerlink" title="图像表达"></a>图像表达</h2><p>画面识别的输入$x$是形状为（width, height, depth）的三维张量。其中每一个（width，height）的矩阵称为一个channel。</p><blockquote><p>画面不变性：一个物体在channel中的位置不应该影响对该物体的识别结果。</p></blockquote><h2 id="为什么前馈神经网络不能完成任务？"><a href="#为什么前馈神经网络不能完成任务？" class="headerlink" title="为什么前馈神经网络不能完成任务？"></a>为什么前馈神经网络不能完成任务？</h2><p>输入图片是一个三维张量，但是很明显前馈神经网络很难识别不同位置的“相同”样本。<br>也即：应当使前馈神经网络在识别图片中的物体时，即使物体在不同位置也能顺利识别出来。<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsrxt7affrj20k00ce0z1.jpg" alt=""></p><h2 id="卷积神经网络：让权重在不同位置共享的神经网络"><a href="#卷积神经网络：让权重在不同位置共享的神经网络" class="headerlink" title="卷积神经网络：让权重在不同位置共享的神经网络"></a>卷积神经网络：让权重在不同位置共享的神经网络</h2><p>卷积神经网络的最基本的操作：</p><ol><li>卷积</li><li>非线性（ReLu）</li><li>Pooling池化</li><li>分类（全连接层）</li></ol><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><ul><li><p>使用局部区域去扫描整张图片<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsrzmkrrypj20e90ea43u.jpg" alt=""><br>其中：红框表示<strong>filter</strong>或者<strong>kernel</strong>,隐藏层节点为kernel的线性组合。<br>那么，隐藏层节点$y_0$的表达式即为：<br>$$ y_0=x_0<em>w_1+x_1</em>w_2+x4<em>w_3+x_5</em>w_4+b_0 $$</p></li><li><p>空间共享<br>不同的区域共享同一个“权重矩阵”和偏移量$b_0$。</p></li><li><p>矩阵形式的输出表达：<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fss08p95qjj20e90eawjr.jpg" alt=""><br>经过一次feature detector后的隐藏层就可以看做是“卷积”的特征。</p></li><li><p>处理Depth这一个维度:将三个channel看成三组不同的权重矩阵<br>特别的，针对$$ 2\cdot2\cdot3 $$(RGB)的kernel有：<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fss0q4vy7kj207t01ajr8.jpg" alt=""><br>也就是说，<strong>depth维是以被贯穿的方式处理的</strong>。<br>在实践中，Depth的数值与filter的个数相同。</p></li><li><p>步长（Stride）：<br>这个参数决定了filter滑动一次所跨越的像素数量。本文的例子中步长均为1。</p></li><li><p>Zero padding<br>为了保证卷积后的图片尺寸不变，则需要在最外一层填充0，</p></li><li><p>多filters<br>不同的filters对同一个图像抓取到的Feature Maps也会不同。<br>每一个不同的filter代表了每一个不同的操作，下图就展示了filter对用一张图片不同的处理结果。</p></li></ul><p align="center"><br>  <img width="60%" height="60%" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fss2yuhw9dj20ia0u2485.jpg"><br></p><h3 id="非线性（ReLu）"><a href="#非线性（ReLu）" class="headerlink" title="非线性（ReLu）"></a>非线性（ReLu）</h3><p>回顾一下老朋友ReLU:Rectified Linear Unit<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss3hexqnoj20tr09c3zw.jpg" alt=""><br>这个环节的主要作用就是把一些值为负数的像素点全部设置为0，</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss42edfvbj215k0fkjzp.jpg" alt=""></p><h3 id="Pooling池化"><a href="#Pooling池化" class="headerlink" title="Pooling池化"></a>Pooling池化</h3><ul><li>Max pooling<br>整个图片被不重叠的分割成若干个同样大小的小块（pooling size）。每个小块内只取最大的数字，再舍弃其他节点后，保持原有的平面结构得出output。那么为什么要有这个环节？<blockquote><p>卷积后的Feature Map中有对于识别物体不必要的冗余信息。 </p></blockquote></li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss45xe26bj20rg0nedlu.jpg" alt=""></p><p>&emsp;&emsp;注：上图的步长设置为1</p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>卷积网络的最后会将末端得到的长方体平摊(flatten)成一个长长的向量，并送入全连接层配合输出层进行分类。</p><h2 id="小结：卷积神经网络的训练过程"><a href="#小结：卷积神经网络的训练过程" class="headerlink" title="小结：卷积神经网络的训练过程"></a>小结：卷积神经网络的训练过程</h2><ol><li>随机初始化所有的filter、参数、权重</li><li>将训练图像作为输入，通过卷积-&gt;ReLu-&gt;池化（pooling）-&gt;全连接层的过程找到每个分类的概率。</li><li>在输出层计算总误差。</li><li>使用梯度下降反向传播更新所有filter、参数、权重的值。其中，权重按它们所占误差的比例更新；</li></ol><hr><h2 id="再用一个例子查漏补缺"><a href="#再用一个例子查漏补缺" class="headerlink" title="再用一个例子查漏补缺"></a>再用一个例子查漏补缺</h2><p><a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" target="_blank" rel="noopener">可视化CNN游戏，强烈建议尝试一下！</a></p><p>游戏截图如下：<br>一副图片由1024（$32*32$）个像素组成。<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss7xncql9j21q0172x6p.jpg" alt=""></p><p>第一个卷积层由6个$5*5$并且步长设置为1的filter生成，我们可以形象的理解为它的depth维度为6。注：下图将ReLu环节与卷积环节合二为一了，请读者心中有数。</p><p align="center"><br>  <img width="200px" height="400px" src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss7zpo0cxj20go0vmdne.jpg"><br><br></p><p>紧接着针对每一个feature map使用$2*2$并且步长为2的max pooling。可以看到Pooling层的每一个像素对应Conv层的四个像素。</p><p align="center"><br>    <img with="200" height="400px" src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssbu4uyuwj20ek0gwn0t.jpg"><br></p><p>接下来是最难理解的第二次的卷积层和max pooling层的环节：<br>首先，观察第一层max pooling到第二层卷积的个数，为什么8个feature map经过filter的f卷积之后变成了16个feature map？<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssctu1m8lj219y0620yl.jpg" alt=""></p><p>为了寻找答案，我们来观察下第二层feature maps的filter都是长成什么样的：<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssd06wljtj210w0k67fd.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssd0qrdugj21aq0kek7e.jpg" alt=""></p><p>请大家仔细观察上图：我们会发现，第二层卷积层的filter的形状和所选择的第一层max pooling的feature map息息相关！也就是说，我们在做第二层的卷积时，只考察了第一层的局部特征！</p><p>第二层的max pooling与第一层同理，我就不再赘述了。</p><p>之后是全连接层，全连接层利用了所有的特征：</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssd8ndkubj21cg02yn25.jpg" alt=""></p><p>全连接层的全景图如下：<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssdbxdtm0j21oq0c2gzj.jpg" alt=""></p><blockquote><p>参考与引用</p><ol><li><a href="https://zhuanlan.zhihu.com/p/27642620" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27642620</a></li><li><a href="https://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">https://cs231n.github.io/convolutional-networks/</a></li><li><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" target="_blank" rel="noopener">https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</a></li><li><a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" target="_blank" rel="noopener">http://scs.ryerson.ca/~aharley/vis/conv/flat.html</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> DeepLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> cnn </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>人类简史与未来简史</title>
      <link href="/2018/06/27/some-great-books-note/"/>
      <url>/2018/06/27/some-great-books-note/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="人类简史"><a href="#人类简史" class="headerlink" title="人类简史"></a>人类简史</h2><h3 id="以问题为导向阅读"><a href="#以问题为导向阅读" class="headerlink" title="以问题为导向阅读"></a>以问题为导向阅读</h3><h4 id="问题1：人类如何从不相关的物种变成了地球的主宰者？"><a href="#问题1：人类如何从不相关的物种变成了地球的主宰者？" class="headerlink" title="问题1：人类如何从不相关的物种变成了地球的主宰者？"></a>问题1：人类如何从不相关的物种变成了地球的主宰者？</h4><p>&emsp;答案：集体层面上，人类可以<em>灵活</em>地进行<em>大型合作</em>。其中，灵活相对于地球上的其他物种，例如：蚁群可以高效的合作，但是它们不会策划去推翻蚁后的统治。大型合作代表一种在信任机制，即陌生人“绑定”之间的契约。</p><p>&emsp;列举一些只会出现在人类这个物种上的合作机制：</p><ul><li>屠宰场</li><li>监狱</li><li>集中营</li></ul><p>&emsp;启发：人类之所以可以进行灵活地大型合作，我认为一部分要归功于人类的自我意识。而人工意识真的是当前人工智能的发展未来吗？人类进化成为“有意识”的物种花费了数百万年的时间。目前计算机接口并不具备像人类一样与现实世界进行交互，通过自然选择筛选基因的外部条件。因此人工智能也许会跳过意识这一环节，成为无意识的超级智能。再或者，计算机通过其特有的接口“互联网”，直接进化出超级意识。</p><h4 id="问题2：人类为何能建立前所未有的合作机制？"><a href="#问题2：人类为何能建立前所未有的合作机制？" class="headerlink" title="问题2：人类为何能建立前所未有的合作机制？"></a>问题2：人类为何能建立前所未有的合作机制？</h4><p>&emsp;答案：想象力：人类可以创造虚幻或者虚幻的故事。只要人们广泛“相信”/“信任”这些故事，大家便会遵循相同的规定、准则、价值观。</p><ul><li>动物仅仅用语言描述现实世界，而人类使用语言创造新的（虚构的）现实。例如：上帝、人权、国家、民族、公司、货币。</li></ul><p>&emsp;启发：正在飞速发展的AI恰恰会有相同形式机制，比如医疗领域，人类医生有数千万，但是他们参差不齐的水平和文化背景经常会导致误诊。而共享单一医疗网络的AI医生将会共享同一个“准则”，第一时间可以获取到最新具有抗药性的病毒，这无疑对医疗来说是巨大的进步。</p><h3 id="2-按照时间顺序阅读"><a href="#2-按照时间顺序阅读" class="headerlink" title="2. 按照时间顺序阅读"></a>2. 按照时间顺序阅读</h3><ol><li>认知革命：语言沟通进行合作。</li><li>农业革命：驯化地球上的其他物种；使用文字进行记录。</li><li>科学革命：人类发现自己的“无知”，进而不断探索未知的领域。</li><li>？？革命：？？</li></ol><p>&emsp;启发：人类会无意识的进入一个全新的时代。在时代的转换过程中阶层流动将会变得十分迅速，而每次转换都会让资源集中在更少的人手中。越来越多的权力由人类涌向算法，最后十分有可能是一个无意识的智能体控制这个星球。</p><h2 id="未来简史"><a href="#未来简史" class="headerlink" title="未来简史"></a>未来简史</h2><h3 id="观点导向阅读"><a href="#观点导向阅读" class="headerlink" title="观点导向阅读"></a>观点导向阅读</h3><ol><li><p>人类一直在追求“永生”，而计算机（硅基生命）天生“永生”。<br><br>启发：按照进化论的观点，通过不断地“死亡”来筛选适合生存的突变基因，碳基生命完成了进化。相反，硅基生命则不需要通过这种方式完成进化。那么我们需不需要编码一个“原始”的硅基生命体（含有基本代码片的单片机）使其模拟人类进化的过程呢？</p></li><li><p>科技革命产生了人文主义宗教。<br><br>科学，本身成为了一种宗教。“圣经“们打下了有神论宗教的基础。”牛顿与苹果“，”马尔科夫假设“，”神经网络“，成为了计算机乃至科学的基石。我常常恐惧于：如果有一天计算机科学的基石崩塌，这门学科将会向</p></li><li><p>人文主义将会面临彻底的失败。<br><br>人文主义的基本假设是：人是有自我意识的。但是神经科学家告诉我们：人的意识仅仅是神经信号，并不比地球上的其他物种高明多少，也没有21克的”灵魂“存在。未来数据主义十分有可能成为新的主流信仰，即全世界的低级碳基生命伴随着高级硅基生命一起进化，最终变成一个巨大的综合生命体。</p></li></ol><h3 id="章节顺序阅读"><a href="#章节顺序阅读" class="headerlink" title="章节顺序阅读"></a>章节顺序阅读</h3><ul><li>幸福：幸福感的本质是神经元之间传递的电化学反应信号，或许真的有一串代码可以传递一个”幸福矩阵“于神经网络之中呢？</li><li>直觉：生物自有的算法（适者生存）已经保证了，地球上的生物最起码是局部最优的。而人类决策算法中最重要的”直觉“或者说”无意识部分“，需要进行巧妙地编码。</li><li>意识：意识本质上是个体的退化与集体的进化。自由意志本身也只是一个算法。那么首先，如何让冷冰冰的代码具有主观能动性呢？是需要给他们编码一个最基本的生存动机？还是其他方式呢？</li><li>左右脑的启发：当前最为火爆的GAN(对抗神经网络)模型，可以类比人类的左右脑。因为脑科学实验表明，左脑和右脑本来就是两套不同的决策体系，它们通过神经纤维连接了起来，最终作出一致的决策。因此，从神经元到深度神经网络到对抗式神经网络，人类不经意间走着仿生学的”正确“道路。一步一步实现人工智能。（此处可以添加GAN相关论文成果）</li></ul><h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><ul><li>当前世界的时间节点，无论是中国倡导的“经济全球化”，还是美国倡导的“美国优先”，都是在讲一个故事，创造一种幻觉。</li><li>pytorch, tensorflow最终会变成一个超级平台，规范一切关于人工智能的进化过程。C语言就像是现实世界的物理定律，底层硬件就像是现实世界中的实体。</li><li>人类只是简单地算法，人工智能需要一个本领域的”质能方程“。 </li></ul>]]></content>
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> aBriefHistoryOfHumankind </tag>
            
            <tag> homoDeus </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>深度学习设计理念手写笔记</title>
      <link href="/2018/06/16/YJango-Deep-Learning/"/>
      <url>/2018/06/16/YJango-Deep-Learning/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><div class="row"><iframe src="https://drive.google.com/file/d/1cski1XD1gfZauuDb-TOw8HqxmGixbkoO/preview" style="width:100%; height:550px"></iframe></div>]]></content>
      
      <categories>
          
          <category> HandWriting </category>
          
      </categories>
      
      
        <tags>
            
            <tag> deeplearning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>超智能体读书笔记</title>
      <link href="/2018/06/15/super-organism-YJango/"/>
      <url>/2018/06/15/super-organism-YJango/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>版权说明：<br>本文仅记录在阅读 于建国（YJango）博士的《超智能体》一书过程中的笔记。本文作者已通过邮件联系作者，获得授权。</p></blockquote><h2 id="智能的本质"><a href="#智能的本质" class="headerlink" title="智能的本质"></a>智能的本质</h2><p>　智能起源于随机性（熵）：随着时间的推移，孤立系统会自发朝向最大熵状态演化[不去刻意整理的宿舍会越来越乱]。</p><blockquote><p>智能：根据环境变化做出相应变化的能力，即熵减的能力[减少“不确定性”]</p></blockquote><p>　想要探究智能，我们必须具备正确描述世界状态和不同时间下的状态变化。线性代数则给了我们答案。</p><h3 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h3><blockquote><p>线性代数：有关任意维度空间下事物<strong>状态</strong>和<strong>变化状态</strong>的规则</p></blockquote><h4 id="矩阵的本质：存储状态（静态）或变化（动态）的信息"><a href="#矩阵的本质：存储状态（静态）或变化（动态）的信息" class="headerlink" title="矩阵的本质：存储状态（静态）或变化（动态）的信息"></a>矩阵的本质：存储状态（静态）<strong>或</strong>变化（动态）的信息</h4><ol><li>矩阵的静态信息：<br>　向量可以描述一个事物的状态，许多具有相同维度的向量的有序排列构成了矩阵。<ul><li>关于张量：多个标量有序排列后形成向量，多个向量有序排列后形成矩阵，多个矩阵有序排列后形成三维张量（3D tensor）。</li></ul></li><li><p>矩阵的动态信息：<br>　此时矩阵可以看做是多个维度相同的权重的有序排列，并且可以对另一个矩阵的静态信息进行批量变化。这便是矩阵乘法的本质。</p><blockquote><p>两个矩阵相乘，一个矩阵提供状态信息，另个矩阵提供变化信息</p></blockquote></li><li><p>向量空间：能够容纳所有线性组合的状态集合。</p><ul><li>向量空间一定在各个维度可以无限延伸（因为实数域无限）</li><li>子空间：子空间内的向量空间<ul><li>最小的子空间：0</li><li>空集不可以是向量空间</li></ul></li></ul></li><li><p>线性变换：<br> 矩阵乘以矩阵可以视作一个矩阵内部向量的批量线性变换（lineartransformation）。方便理解起见可以仅讨论由矩阵乘以向量所形成的一次线性变换。直接上图：<br> <img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/superorganism-1.png" alt=""></p></li><li><p>线性变化：不同维度空间下的向量组的投影。例如$y_{2<em>1}=A_{2</em>3}x_{3*1}$便是将三维向量$x$经过线性变换后变成二维空间的向量$y$。<br>注：神经网络的核心 $$ y=a(Ax+b)$$ </p></li></ol><h4 id="维度的扩展"><a href="#维度的扩展" class="headerlink" title="维度的扩展"></a>维度的扩展</h4><p><strong>思维空间</strong>：人们认为自己拥有自由的意识和思维。然而这种自由也是有限的。它好比线性空间里的张成,能张成多大的意识空间<strong>取决于脑中有多少互不相关的因素</strong>,也就是维度（秩）。</p><p>　维度的作用：</p><ul><li>复数的理解:进一步扩展的数的域。</li><li>傅里叶变换的理解:在x-y坐标系上增加1维时,一切豁然开朗。</li><li><p>弦理论的理解:尝试融合相对论和量子力学的理论,但只有当扩充到10维空间+1维时间时,数学公式才合理。</p></li><li><p><strong>弦理论</strong>：</p><ul><li>1.问题的起源：<ul><li>宇宙也许存在高维度的空间</li><li>构成世界最基础的成分是什么？</li></ul></li><li>2.物质的构成：分子-&gt;原子-&gt;质子、中子-&gt;？？？<br>  可能是不断<strong>跳动</strong>的能量<strong>线条</strong>：宇宙万物的一切皆源于此。</li><li>3.上述理论的数学证明之后在十维空间和一维时间的情况下才成立。那么我们的宇宙的确可能存在高纬度的空间</li><li>4.新的问题：当我们观测一个宇宙的状态时，我们确定了20个数值（粒子的质量，重力场的强度，…），并且如果这20个数中的任何一个数有所变化，我们的宇宙将不复存在。那么这20个数值是因为什么而确定的呢？<br>  也许是更高纬度的空间</li><li><ol start="5"><li>通过实验证明高纬度空间的存在：<br>欧洲大型强子对撞机通过将质子加速对撞，观测：如果对撞后的能量有所损失，则可能是因为对撞的一部分“残骸”进入到了高纬度空间！</li></ol></li></ul></li></ul><p>小结：<strong>当问题无法被理解时，往往是因为找错的地方，不妨尝试扩展维度，增加搜索空间。</strong>然而由于信息量的限制，很多事物无法确定变化后的状态，因此需要概率为我们提供依据。</p><h3 id="概率"><a href="#概率" class="headerlink" title="概率"></a>概率</h3><blockquote><p>概率是用来衡量事物在跨时间后的不同状态的确信度</p></blockquote><h3 id="熵与生命"><a href="#熵与生命" class="headerlink" title="熵与生命"></a>熵与生命</h3><blockquote><p>生命活着就在减熵：利用信息压缩（或者说抽象）后形成的知识，对抗熵增！</p></blockquote><p>　智能的条件</p><ul><li>智能LV1:从环境到行动的关联能力[生存]（植物&amp;微生物）</li><li>智能LV2:利用过去到未来的关联能力[预测]（动物）</li><li>智能的实现：通过存储关联的材料（遗传物质）</li></ul><hr><h2 id="自然智能"><a href="#自然智能" class="headerlink" title="自然智能"></a>自然智能</h2><h3 id="RNA与DNA（智能LV1）"><a href="#RNA与DNA（智能LV1）" class="headerlink" title="RNA与DNA（智能LV1）"></a>RNA与DNA（智能LV1）</h3><ul><li>识别：DNA上的信息：蛋白质合成。</li><li>学习：繁衍，变异，筛选。</li><li>进化：<strong>进化是以种群为单位的被动过程</strong><br>　问题：在<strong>《未来简史》</strong>中，作者描述人类将打破自然选择的进化理论，转而通过基因改造技术“主动”进化。</li><li>永生的缺陷：永生者失去了为种群提供差异性的筛选功能。</li></ul><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><ol><li>神经元的本质行为：<br>$$y=a(Wx+b),其中x是输入信号，y是输出信号$$</li></ol><hr><h2 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h2><h3 id="梯度下降的问题"><a href="#梯度下降的问题" class="headerlink" title="梯度下降的问题"></a>梯度下降的问题</h3><ul><li>局部最小值（鞍点）的解决方案：<ul><li>随机梯度下降：每次只更新一个样本所计算的梯度</li><li>小批量梯度下降：每次更新若干样本所计算梯度的平均值</li><li>.etc</li></ul></li></ul><h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><blockquote><p>神经网络不缺少新结构，但缺少一个该领域的$E=mc^2$</p></blockquote><ol><li>为什么神经网络高效：并行的先验知识使得模型可用线性级数量的样本学习指数级数量<br>的变体：</li><li>学习的本质是什么：将变体拆分成因素和知识（Disentangle Factors of Variation）</li><li>为什么深层神经网络比浅层神经网络更高效：</li><li>神经网络在什么问题上不具备优势：<ul><li>非函数问题：需要想办法将问题转化为函数问题</li><li>非迭代：该层的状态不是由上层状态构成的任务</li></ul></li></ol><h3 id="深度学习计算机实现平台：tensorflow"><a href="#深度学习计算机实现平台：tensorflow" class="headerlink" title="深度学习计算机实现平台：tensorflow"></a>深度学习计算机实现平台：tensorflow</h3><p>Tensorflow基本用法</p><ol><li>准备阶段：组装计算图<ul><li>计算图<code>想象成一个管道</code>：需要组装的结构，由许多操作组成</li><li>操作<code>想象成不通管道分支的连接处</code>：对零个或多个数据进行输入与输出</li><li>数据类型：1.张量（tensor）2.变量（variable）3.常量（constant）<ul><li>张量<code>想象成管道中的液体</code>：多维度array或者list<br>  tener_name = tf.placeholder(type, shape, name)</li><li>变量：在同一时刻对图中所有其他操作都保持静态的数据（管道中的阀门）<br>  name_variable = tf.Variable(value, name)</li><li>常量：无需初始化的变量<br>  name_constant = tf.constant(value)</li></ul></li></ul></li><li>执行阶段：使用计算图<ul><li>执行语句: sess.run(op)</li><li>送值（feed）: 输入操作的输入值（输入液体）<br>  sess.run([output], feed_dict={input1:value1, input2:value2})</li><li>取值（fetch）: 获取操作的输出值（得到液体）<br>  sess.run(one op)<br>  sess.run([a list of op])</li></ul></li></ol><h3 id="DEMO部分："><a href="#DEMO部分：" class="headerlink" title="DEMO部分："></a>DEMO部分：</h3><p>YJango博士的部分demo由于tensorflow版本问题可能无法运行，我将部分代码已经“修正”并已上传至github，本地环境测试均可通过，请大家放心使用。<br><a href="https://github.com/824zzy/TutorialTensorflow" target="_blank" rel="noopener">代码部分的笔记</a></p><blockquote><p>参考与引用: 1. 《超智能体》 于建国（Yjango）博士</p></blockquote>]]></content>
      
      <categories>
          
          <category> AI </category>
          
      </categories>
      
      
        <tags>
            
            <tag> readingNote </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GRE填空逻辑方法总结</title>
      <link href="/2018/06/10/GRE-verbal-method/"/>
      <url>/2018/06/10/GRE-verbal-method/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="同意重复"><a href="#同意重复" class="headerlink" title="同意重复"></a>同意重复</h2><blockquote><p>同意重复定义：句中通过一些明显的指示代词和指代性的名词对前文或者后文的内容进行重复的题目考点</p></blockquote><ol><li>同意重复常见标志代词：<code>this,that,such,this very（正是这个）,the,the same,the former/later</code>等</li><li>同意重复扩展标志词：<code>necessarily, surely, definitely, equally, parallel</code></li></ol><p>广义同/反义词</p><blockquote><p>在评价正负性方向相同/相反的词汇和短语（善良、勇敢 VS 无知 吝啬）</p></blockquote><p>补充知识点：if的用法</p><ol><li>如果：</li><li>是否：</li><li>即使：if not all（即使不是全部），“大部分”的意思</li><li>其他短语：<ul><li>If any:即便有</li><li>If ever:如果真有</li><li>If at all:即使某事真的 发生</li></ul></li></ol><hr><h2 id="因果关系"><a href="#因果关系" class="headerlink" title="因果关系"></a>因果关系</h2><h3 id="因果关系逻辑词"><a href="#因果关系逻辑词" class="headerlink" title="因果关系逻辑词"></a>因果关系逻辑词</h3><ul><li><p>表原因：because, since, for, in that(GRE常用！), now that（既然）,  as, because of, due to, given（GRE常用！）, on the ground that, on ground of, as long as </p><h4 id="例句："><a href="#例句：" class="headerlink" title="例句："></a>例句：</h4><ul><li>Dramatic literature often recapitulates the history of a culture in that <strong>it takes as its subject matter the important event</strong> that have shaped and guided the culture.</li><li>=Dramatic literature often recapitalates the history of a culture in that it takes the important events that have shaped and guided the culture as its subject matter.<br>补充知识点：宾语后置<blockquote><p>宾语后置：在“主语+谓语+宾语+状语”的句型中。有时候宾语如果有修饰成分，则可以把宾语后置 </p></blockquote></li></ul></li><li><p>表结果：therefore, thereby, thus, so, whereby, as a result, consequently, so(such)…that…, so(such)…as to, too…to…等</p></li><li>其他因果逻辑词：result in(左边导致右边), result from(右边导致左边), lead to, give rise to, bring about</li></ul><h3 id="解题要点"><a href="#解题要点" class="headerlink" title="解题要点"></a>解题要点</h3><p>根据已知的因果关系判断空格语义，再选取同义或者广义同义。</p><p>补充知识点：as long as用法</p><pre><code>- 和...一样长：This stick is as long as that one- 只要...,如果：We can do this directly as long as we have certain types of information- 既然，因为：As long as you have been here, you could wait for a moment.</code></pre><hr><h2 id="目的手段"><a href="#目的手段" class="headerlink" title="目的手段"></a>目的手段</h2><h3 id="表示目的的词或者短语："><a href="#表示目的的词或者短语：" class="headerlink" title="表示目的的词或者短语："></a>表示目的的词或者短语：</h3><p>to do, for doing, in order to, so that, for fear that, lest, in case, for 等</p><h3 id="表示手段的词或者短语："><a href="#表示手段的词或者短语：" class="headerlink" title="表示手段的词或者短语："></a>表示手段的词或者短语：</h3><p>by doing, whereby, by means of, be way of, depend on, rely on, by virtur of 等</p><h3 id="目的手段题目解题要点"><a href="#目的手段题目解题要点" class="headerlink" title="目的手段题目解题要点"></a>目的手段题目解题要点</h3><p>根据目的反推手段或者方法，或者根据手段推导目的或者结果</p><hr><h2 id="解释说明"><a href="#解释说明" class="headerlink" title="解释说明"></a>解释说明</h2><h3 id="解释说明标志词："><a href="#解释说明标志词：" class="headerlink" title="解释说明标志词："></a>解释说明标志词：</h3><p>冒号（：），破折号（-），定语从句，分词短语做状语，同位语，形容词短语，主系表结构等 </p><h3 id="解题要点-1"><a href="#解题要点-1" class="headerlink" title="解题要点"></a>解题要点</h3><p>对解释说明的信息进行同义改写</p><hr><h2 id="类比关系"><a href="#类比关系" class="headerlink" title="类比关系"></a>类比关系</h2><h3 id="类比关系标志词"><a href="#类比关系标志词" class="headerlink" title="类比关系标志词"></a>类比关系标志词</h3><p><code>just as, like, as...as, as if/as though, resemble, similarly, in the same way, like wise 等</code></p><h3 id="解题要点-2"><a href="#解题要点-2" class="headerlink" title="解题要点"></a>解题要点</h3><p>找类比关系进行同义改写</p><hr><h2 id="并列关系"><a href="#并列关系" class="headerlink" title="并列关系"></a>并列关系</h2><h3 id="并列关系标志词"><a href="#并列关系标志词" class="headerlink" title="并列关系标志词"></a>并列关系标志词</h3><p><code>and, or, not only...but alse, not just...but also, as well as, at once...and等</code></p><h3 id="并列分为顺承并列和转折并列"><a href="#并列分为顺承并列和转折并列" class="headerlink" title="并列分为顺承并列和转折并列"></a>并列分为顺承并列和转折并列</h3><ul><li>我欣赏她的美丽和善良</li><li>我既喜欢这本书又介意它的一些细节</li></ul><h3 id="解题要点-3"><a href="#解题要点-3" class="headerlink" title="解题要点"></a>解题要点</h3><p>　找同义广义词（很少找直接同义词）</p><hr><h2 id="递进关系"><a href="#递进关系" class="headerlink" title="递进关系"></a>递进关系</h2><h3 id="递进关系逻辑词"><a href="#递进关系逻辑词" class="headerlink" title="递进关系逻辑词"></a>递进关系逻辑词</h3><p><code>even, not only ... but also, indeed, especially, particularly, in addition, moreover, futher more, all the more</code></p><h3 id="注意even的停发"><a href="#注意even的停发" class="headerlink" title="注意even的停发"></a>注意even的停发</h3><ul><li>even表示让步转折：多放在句首，<strong>即使</strong></li><li>even表示递进关系：多放在句中，<strong>更加</strong></li></ul><h3 id="解题要点-4"><a href="#解题要点-4" class="headerlink" title="解题要点"></a>解题要点</h3><p>　加强递进/减弱递进</p><hr><h2 id="让步转折"><a href="#让步转折" class="headerlink" title="让步转折"></a>让步转折</h2><h3 id="让步转折逻辑词"><a href="#让步转折逻辑词" class="headerlink" title="让步转折逻辑词"></a>让步转折逻辑词</h3><p><code>even, although, though, despite, however, nevertheless, but, in spite of, for all=despite, even as, even when, as</code></p><h3 id="解题要点-5"><a href="#解题要点-5" class="headerlink" title="解题要点"></a>解题要点</h3><p>　取反义或广义反义</p><h2 id=""><a href="#" class="headerlink" title="　"></a>　</h2><h2 id="对比关系"><a href="#对比关系" class="headerlink" title="对比关系"></a>对比关系</h2><h3 id="对比关系逻辑词"><a href="#对比关系逻辑词" class="headerlink" title="对比关系逻辑词"></a>对比关系逻辑词</h3><ul><li>连接性关系词：<code>rather than, far from, on the contratary, in contrast to, compare with, unlike, different from, not but</code></li><li>对比关系的其他逻辑词：<code>ironic, surprising, stunning, strange, mask, belie, veil, seem, appear, paradox, contradiction, dichtomy</code></li></ul><h3 id="解题要点-6"><a href="#解题要点-6" class="headerlink" title="解题要点"></a>解题要点</h3><p>　取反义或广义反义词</p>]]></content>
      
      <categories>
          
          <category> GRE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> verbal </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GRE阅读导学</title>
      <link href="/2018/06/10/GRE-reasoning-overall/"/>
      <url>/2018/06/10/GRE-reasoning-overall/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="语言-amp-题目"><a href="#语言-amp-题目" class="headerlink" title="语言&amp;题目"></a>语言&amp;题目</h2><ul><li>Specify your problems</li><li>Simplify your solutions</li></ul><h2 id="GRE-General-Test"><a href="#GRE-General-Test" class="headerlink" title="GRE General Test"></a>GRE General Test</h2><ul><li>Analytical Writing</li><li>Verbal Reasoning</li><li>Quantitative Reasoning</li></ul><h3 id="Analytical-Writing-2-tasks"><a href="#Analytical-Writing-2-tasks" class="headerlink" title="Analytical Writing(2 tasks)"></a><strong>Analytical Writing</strong>(2 tasks)</h3><h3 id="Verbal-Reasoning-2-sections"><a href="#Verbal-Reasoning-2-sections" class="headerlink" title="Verbal Reasoning(2 sections)"></a><strong>Verbal Reasoning</strong>(2 sections)</h3><p>30 min &amp; 20 proplems</p><h3 id="Quantitative-Reasoning-2-sections"><a href="#Quantitative-Reasoning-2-sections" class="headerlink" title="Quantitative Reasoning(2 sections)"></a><strong>Quantitative Reasoning</strong>(2 sections)</h3><h3 id="Unscored-positon-varies"><a href="#Unscored-positon-varies" class="headerlink" title="Unscored(positon varies)"></a>Unscored(positon varies)</h3><h3 id="score-standard"><a href="#score-standard" class="headerlink" title="score standard"></a>score standard</h3><p>section-level(根据第一部分的分数决定第二部分的难度)</p><hr><h2 id="GRE-Verbal-Reasoning"><a href="#GRE-Verbal-Reasoning" class="headerlink" title="GRE Verbal Reasoning"></a>GRE Verbal Reasoning</h2><ul><li>Reading Comprehension(20 min)</li><li>Text Completion</li><li>Sentence Equivalence</li></ul><h3 id="Reading-Comprehension"><a href="#Reading-Comprehension" class="headerlink" title="Reading Comprehension"></a>Reading Comprehension</h3><ul><li>长文章 4</li><li>短文章 2</li><li>逻辑单题 1</li></ul><h3 id="文章初体验"><a href="#文章初体验" class="headerlink" title="文章初体验"></a>文章初体验</h3><ul><li>plant <strong>communities</strong>:群落</li><li>more <strong>susceptible</strong> than:易受影响的</li><li><strong>inconsistent</strong> theroy:前后不一致的</li><li>resource-release <strong>mechanisms</strong>:方式方法</li><li><strong>ecological</strong> correlates: 生态学的</li><li>no <strong>necessary</strong> relationship:必然的</li><li>this may <strong>arise from</strong> sth:由于</li></ul>]]></content>
      
      <categories>
          
          <category> GRE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reasoning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GRE填空逻辑方法总结</title>
      <link href="/2018/06/10/GRE-verbal-overall/"/>
      <url>/2018/06/10/GRE-verbal-overall/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="GRE填空简介"><a href="#GRE填空简介" class="headerlink" title="GRE填空简介"></a>GRE填空简介</h2><ol><li>题目数量：每个section10个题目，一共两个section共20题</li><li>题目类型：</li></ol><ul><li>单空题：五选一</li><li>双空题：三选一</li><li>三空题：三选一</li><li>句子等价：六选二（选同义词）</li></ul><hr><h2 id="如何取得高分？"><a href="#如何取得高分？" class="headerlink" title="如何取得高分？"></a>如何取得高分？</h2><ol><li><p>词汇：不能低于12000，最好在15000以上</p><blockquote><p>五遍以下纯裸考，十遍以下比基尼考</p></blockquote><ul><li>relying on the <strong>well-to-do</strong> for <strong>commissions</strong>：有钱人&amp;佣金</li><li>hypocrite：虚伪</li><li>egotist：以自我为中心这</li><li>sycophant：奉承者</li><li>adulator：奉承者</li><li>braggart：自夸者</li><li>coward：懦夫</li><li>if sth at all：即使真的发生某事</li></ul></li><li>句子结构（主要是语法问题）<ul><li>后置定语（四种）：<ul><li>The boy <strong>who is reading a book</strong>：定语从句做后置定语</li><li>The boy <strong>reading a book</strong>：分词短语做后置定语</li><li>The boy <strong>in a red sweater</strong>:介词短语做后置定语</li><li>The boy angry at his teacher:形容词短语做后置定语</li><li>真题例句：The writer so <strong>wary of extravagance</strong> was <strong>profligate</strong> with paper：对奢侈浪费十分谨慎;浪荡 行为不检点</li></ul></li><li>倒装句<ul><li>1.部分倒装：Only by ignoring decades of mismanagement and inefficiency could investors conclude that a fresh <strong>infusion of cash</strong> of cash would provide anything other than a <strong>fleeting solution</strong> to the company’s <strong>financial woes</strong>.：注入现金；短暂的方案；金融危机<ul><li>主句正常结构是：Investors could conclude that … only by ignoring decades of …</li><li>部分倒装（助动词，Be动词，情态动词提前）<ul><li>only + 状语提前句子部分倒装</li><li>否定副词提前句子部分倒装</li></ul></li></ul></li><li>2.完全倒装：Burke is often on slippery ground when it comes to her primary sources;<strong>especially duious is the mode</strong> by which she gathered her oral evidence<ul><li>正常语序：Burke is often on slippery ground when it comes to her primary sources;<strong>the mode is especially duious</strong> by which she gathered her oral evidence</li><li>完全倒装知识讲解：<ul><li>1.“主谓句+地点状语/时间状语”中状语可以提前</li><li>2.“主语+be动词+表语（形容词短语，介词短语，分词短语）”</li></ul></li></ul></li></ul></li><li>插入语：<ul><li>常见插入语例子：To be frank；The teacher,along with the headmaster,is doing sth</li><li>如何处理插入语：先看插入语之外的句子结构，再带入插入语进行完整的理解。</li></ul></li><li>That引导主语从句（that的从句用作主语）</li><li>As引导的让步状语从句<ul><li>1.作为：As a student, I must study hard</li><li>2.当：It was raining as I came back to my car</li><li>3.因为：As he is a child, we should not blame him</li><li>4.如此：I am as tall as my father</li><li>5.与…比起来：I am as tall as my father</li><li>6.尽管：<ul><li>Child as he is, he know everything = Although he is a child, he knows everything</li><li>Object as you may, I will go = Although you may object, I will go</li><li>Much as you like it, I will not buy it. = Although you like it, I will not buy it for you.</li></ul></li></ul></li><li>语法补充知识点（自学）<ul><li>六大从句</li><li>强调句</li><li>虚拟语气</li><li>非谓语动词</li></ul></li></ul></li></ol><ol start="3"><li><p>逻辑推理</p><ul><li>逻辑要收敛：任何推理都要基于题目本身！<ul><li>erudite：博学的</li><li>insular：与世隔绝的</li><li>cosmopolitan：四海为家的</li><li>imperturbable：泰然自若的</li></ul></li><li>很多时候我们只需要掌握句子的逻辑主线，不必过于纠结于汉语的翻译。<ul><li>savor：品尝 欣赏</li><li>rejoice:庆祝</li><li>prevarication：搪塞</li><li>flattery：奉承</li><li>affectat：感动</li><li>narcissism：自恋；水仙花</li><li>indolence：懒散</li><li>fecundit：肥沃富饶</li><li>economy：节约；理财</li></ul></li></ul></li><li><p>对应技巧</p><ul><li>填空核心方法总结<strong>：读懂句意-简化句意-梳理核心逻辑-找到空格对应点-选出答案</strong></li><li>练习：<ul><li>disdain：蔑视</li><li>egalitarian：平等主义</li><li>maverick：特立独行</li><li>dilettante：一知半解者</li><li>iconoclast：偶像破坏者</li><li>purveyor：承办商</li><li>prose:散文</li><li>general：将军</li><li>belligerence:好战的</li><li>indigence：贫穷</li><li>perfidy：背信弃义</li><li>betrayal：揭露</li><li>haughty：高傲的</li></ul></li></ul></li></ol>]]></content>
      
      <categories>
          
          <category> GRE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> verbal </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>GRE阅读方法总结</title>
      <link href="/2018/06/10/GRE-reasoning-method/"/>
      <url>/2018/06/10/GRE-reasoning-method/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Reading的正确打开方式"><a href="#Reading的正确打开方式" class="headerlink" title="Reading的正确打开方式"></a>Reading的正确打开方式</h2><blockquote><p>Reading is <strong>not</strong> translation! 方向错了，就算再努力，也会在错误的方向越走越远</p></blockquote><ol><li><p>先读文章：<br> Key words =&gt; Important information =&gt; Function of sentences</p></li><li><p>答题原则</p></li></ol><ul><li>忠于文本</li><li>区分题型</li><li>读懂选项</li></ul><hr><h2 id="短文章题目类型（前四类）"><a href="#短文章题目类型（前四类）" class="headerlink" title="短文章题目类型（前四类）"></a>短文章题目类型（前四类）</h2><ul><li>although/though/even tho ugh/even if：表示让步（句内逻辑）</li><li>任何英语句子：1.表示thing 2.表示state</li></ul><h3 id="全文主旨题："><a href="#全文主旨题：" class="headerlink" title="全文主旨题："></a><strong>全文主旨题</strong>：</h3><ul><li>The passage is <strong>primarily concerned</strong> with</li><li>Which of the following best states <strong>the central idea</strong> of the passage</li><li>The <strong>primary purpose</strong> of the passage is to<br>  思路：文章结构+文章开头</li></ul><h3 id="推理题（基于原文）："><a href="#推理题（基于原文）：" class="headerlink" title="推理题（基于原文）："></a><strong>推理题</strong>（基于原文）：</h3><ul><li>标志词：<code>inferred</code>/<code>suggest</code>/<code>implies</code></li><li>It can be inferred from the passage that …?</li><li>The author suggests/implies which of the following about …?<br>  思路：<ol><li>定位（scanning 问啥找啥 找第一次）</li><li>读定位词所在句（OR 其前后1-2句）</li><li>匹配选项（定位词所在句OR 其前后1-2句 的同意替换）</li></ol></li></ul><h3 id="作者意图题"><a href="#作者意图题" class="headerlink" title="作者意图题"></a><strong>作者意图题</strong></h3><ul><li>标志词：The author of the passage mentions … primarily <code>in order to</code><br>  思路：<ol><li>定位…所在句</li><li>句内/句间 逻辑</li></ol></li></ul><h3 id="事实内容题"><a href="#事实内容题" class="headerlink" title="事实内容题"></a><strong>事实内容题</strong></h3><ul><li>标志词：<code>which of the following is true of sth</code><br>  思路：<ol><li>定位包含信息点的句子：</li><li>直接看选项找同意替换的选项</li><li>如果没有答案，就接着看下一句</li></ol></li></ul><hr><h2 id="其他题型"><a href="#其他题型" class="headerlink" title="其他题型"></a>其他题型</h2><h3 id="不定项选择题"><a href="#不定项选择题" class="headerlink" title="不定项选择题"></a><strong>不定项选择题</strong></h3><p>依题目要求作答</p><h3 id="观点论证题"><a href="#观点论证题" class="headerlink" title="观点论证题"></a><strong>观点论证题</strong></h3><p>观点标志词</p><ul><li><code>notion</code>/<code>belief</code>/<code>view</code>/<code>point</code>/<code>perception</code>…</li><li>…<code>argue</code>…：认为 </li></ul><h3 id="补充知识点-qualify"><a href="#补充知识点-qualify" class="headerlink" title="补充知识点: qualify"></a>补充知识点: qualify</h3><blockquote><p>If you qualify a statement, you make it less strong or less general by adding a detail or explanation to it.</p></blockquote><h3 id="高亮句作用题"><a href="#高亮句作用题" class="headerlink" title="高亮句作用题"></a><strong>高亮句作用题</strong></h3><ul><li>读懂<code>高亮句</code></li><li>读懂<code>前后句</code></li><li>理解<code>句间关系</code></li></ul><h3 id="补充知识点：句间关系"><a href="#补充知识点：句间关系" class="headerlink" title="补充知识点：句间关系"></a>补充知识点：句间关系</h3><blockquote><p>英文常用顶真方式连接文章逻辑。<code>上句末尾，本句开头</code></p></blockquote><h3 id="文学评论"><a href="#文学评论" class="headerlink" title="文学评论"></a><strong>文学评论</strong></h3><h4 id="补充知识点：wry"><a href="#补充知识点：wry" class="headerlink" title="补充知识点：wry"></a>补充知识点：wry</h4><blockquote><p>a wry expression or wry humor shows that you know a situation is bad, but you alse think it is slightly amusing</p></blockquote><hr><h2 id="精读速度训练"><a href="#精读速度训练" class="headerlink" title="精读速度训练"></a>精读速度训练</h2><h3 id="反应速度训练"><a href="#反应速度训练" class="headerlink" title="反应速度训练"></a>反应速度训练</h3><ol><li>中文（sentence by sentence） 每天2-3篇 练5天；卡壳就查/录音查漏补缺</li><li>英文（sentence by sentence） 每天2-3篇 练5天；卡壳就查/录音查漏补缺</li><li>英文（不出声 停顿两秒想这句话的意思<code>keyword and meaning</code>） 每天2-3篇 练5天</li></ol><h3 id="专注度"><a href="#专注度" class="headerlink" title="专注度"></a>专注度</h3><h3 id="记忆力"><a href="#记忆力" class="headerlink" title="记忆力"></a>记忆力</h3><hr><h2 id="意群划分"><a href="#意群划分" class="headerlink" title="意群划分"></a>意群划分</h2><ol><li>介词短语：prepositional phrase(prep)<ul><li>of individual folktales</li><li>in the place</li></ul></li><li>分词短语：participial phrase（part）<ul><li>concerning the exact point</li><li>told by aliens</li></ul></li><li>形容词短语：adjective pharse(adj)<ul><li>full of books</li><li>useful for me</li></ul></li><li>不定式：infinitive phrase(inf)<ul><li>to do</li></ul></li><li>从句：subordinate clause(sub)<ul><li>that/which/whose</li></ul></li></ol><h2 id="长文章"><a href="#长文章" class="headerlink" title="长文章"></a>长文章</h2><h3 id="类型-思路"><a href="#类型-思路" class="headerlink" title="类型/思路"></a>类型/思路</h3><ol><li>详略结合<br>详读<br>（主题句 + 段末总结 + 逻辑关系）<br>略读<br>（举例 + 展开描述）</li><li>分清题型</li></ol><h3 id="段内关系"><a href="#段内关系" class="headerlink" title="段内关系"></a>段内关系</h3><h3 id="段间关系"><a href="#段间关系" class="headerlink" title="段间关系"></a>段间关系</h3><hr><h2 id="逻辑单题的类型-思路-解题步骤"><a href="#逻辑单题的类型-思路-解题步骤" class="headerlink" title="逻辑单题的类型/思路/解题步骤"></a>逻辑单题的类型/思路/解题步骤</h2><h3 id="逻辑单题的类型"><a href="#逻辑单题的类型" class="headerlink" title="逻辑单题的类型"></a>逻辑单题的类型</h3><ul><li>假设<ol><li>提问方式<ul><li>Which of the following is an <strong>assumption</strong> on which the argument depends?</li><li>Which of the following is an <strong>assumption</strong> on which the argument relies?</li></ul></li><li>检查选项的逻辑成立的条件</li></ol></li><li>推理<ol><li>提问方式<ul><li>The information given, if accurate,most strongly supports which of the following <strong>hypotheses</strong>? </li><li>Which of the following <strong>conclusions</strong> is the best supported by the information? </li></ul></li></ol></li><li>加强<ol><li>提问方式<ul><li>Which of the following,if true,<strong>most strengthens</strong> the argument given?</li><li>Which is the following provide <strong>the most support</strong> for the argument</li></ul></li><li>选项提高结论的可信度</li></ol></li><li>句子功能<ol><li>提问方式<ul><li>In the argument given, the <strong>two highlighted portions</strong> play which of the following roles?</li></ul></li></ol></li><li>削弱<ol><li>提问方式<ul><li>Which of the following,if true,<strong>most weakens</strong> the argument given?</li><li>Which of the following,if true,<strong>most seriously undermines</strong>…?</li></ul></li></ol></li><li>填空<ol><li>提问方式<ul><li>Which of the following,if true,most logically complete the argument?</li></ul></li></ol></li></ul><h3 id="逻辑单题的解题步骤"><a href="#逻辑单题的解题步骤" class="headerlink" title="逻辑单题的解题步骤"></a>逻辑单题的解题步骤</h3><ol><li><p>看题目（确定类型）{5秒钟}</p></li><li><p>看文章（读懂逻辑）{45秒钟}</p></li><li>想原理（预设提问）[用中文想]{20秒钟}</li><li>看选项（排除错选）{60秒钟}</li></ol>]]></content>
      
      <categories>
          
          <category> GRE </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reasoning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>MongoDB进阶设计模式</title>
      <link href="/2018/06/09/mongodb-design-mode/"/>
      <url>/2018/06/09/mongodb-design-mode/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>使用了mongodb这么长时间，似乎遇到了瓶颈。本文通过几篇博客再次学习mongo，希望有新的认识。温故而知新~</p></blockquote><h2 id="MongoDB的主体认识："><a href="#MongoDB的主体认识：" class="headerlink" title="MongoDB的主体认识："></a>MongoDB的主体认识：</h2><ul><li>高可用</li><li>分布式</li><li>灵活模式</li><li>文档数据库</li></ul><h3 id="传统关系模型（SQL）和文档模型的区别"><a href="#传统关系模型（SQL）和文档模型的区别" class="headerlink" title="传统关系模型（SQL）和文档模型的区别"></a>传统关系模型（SQL）和文档模型的区别</h3><p><img src="http://www.mongoing.com/wp-content/uploads/2016/01/MongoDB-%E6%A8%A1%E5%BC%8F%E8%AE%BE%E8%AE%A1%E8%BF%9B%E9%98%B6%E6%A1%88%E4%BE%8B_%E9%A1%B5%E9%9D%A2_04-1024x791.png" alt=""></p><h3 id="文档模型的优点"><a href="#文档模型的优点" class="headerlink" title="文档模型的优点"></a>文档模型的优点</h3><ul><li>读写效率高：Data Locality</li><li>可扩展能力强: 无关联易分库</li><li>动态模式：灵活应付不同的数据模式</li><li>模型自然：最接近于对象模型</li></ul><hr><h2 id="MongoDB文档模式设计的基本策略"><a href="#MongoDB文档模式设计的基本策略" class="headerlink" title="MongoDB文档模式设计的基本策略"></a>MongoDB文档模式设计的基本策略</h2><h3 id="优先考虑内嵌，再去考虑引用"><a href="#优先考虑内嵌，再去考虑引用" class="headerlink" title="优先考虑内嵌，再去考虑引用"></a>优先考虑内嵌，再去考虑引用</h3><p><img src="http://www.mongoing.com/wp-content/uploads/2016/01/MongoDB-%E6%A8%A1%E5%BC%8F%E8%AE%BE%E8%AE%A1%E8%BF%9B%E9%98%B6%E6%A1%88%E4%BE%8B_%E9%A1%B5%E9%9D%A2_06.png" alt=""></p><h3 id="MongoDB设计模式原则"><a href="#MongoDB设计模式原则" class="headerlink" title="MongoDB设计模式原则"></a>MongoDB设计模式原则</h3><ul><li>为应用程序服务，而不是为了存储优化</li><li>为实现最佳性能而设计</li></ul><hr><h2 id="经典的模式设计案例"><a href="#经典的模式设计案例" class="headerlink" title="经典的模式设计案例"></a>经典的模式设计案例</h2><h3 id="电商（ECommerce）"><a href="#电商（ECommerce）" class="headerlink" title="电商（ECommerce）"></a>电商（ECommerce）</h3><h4 id="设计考量"><a href="#设计考量" class="headerlink" title="设计考量"></a>设计考量</h4><ul><li>一个购物车数据项不会太大，一般项数少于100</li><li>数据自动过期（15-30分钟无交互）</li><li>用冗余的方式来提供读取性能</li></ul><h4 id="参考数据模型"><a href="#参考数据模型" class="headerlink" title="参考数据模型"></a>参考数据模型</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"_id"</span>: ObjectId(<span class="string">"*"</span>)</span><br><span class="line">    <span class="string">"userid"</span>: <span class="number">1234</span>,</span><br><span class="line">    <span class="string">"last_activity"</span>: ISODate(...), // 使用TTL来自动删除未付款的购物车</span><br><span class="line">    <span class="string">"status"</span>: <span class="string">"active"</span>,</span><br><span class="line">    <span class="string">"items"</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"itemid"</span>: <span class="number">1234</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Milk"</span>,</span><br><span class="line">            <span class="string">"price"</span>: <span class="number">5.00</span>,</span><br><span class="line">            <span class="string">"quantity"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">"img_url"</span>: <span class="string">"milk,jpg"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"itemid"</span>: <span class="number">4567</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Eggs"</span>,</span><br><span class="line">            <span class="string">"price"</span>: <span class="number">3.00</span>,</span><br><span class="line">            <span class="string">"quantity"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">"img_url"</span>: <span class="string">"eggs.jpg"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="对模型的操作"><a href="#对模型的操作" class="headerlink" title="对模型的操作"></a>对模型的操作</h4><ul><li><p>添加商品到购物车</p>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">db.cart.update(&#123;</span><br><span class="line">    <span class="string">"_id"</span>: ObjectId(<span class="string">"*"</span>)</span><br><span class="line">&#125;, &#123;</span><br><span class="line">    $push:&#123;</span><br><span class="line">        <span class="string">"items"</span>:&#123;</span><br><span class="line">            <span class="string">"itemid"</span>: <span class="number">2345</span>,</span><br><span class="line">            <span class="string">"title"</span>: <span class="string">"Bread"</span>,</span><br><span class="line">            <span class="string">"price"</span>: <span class="number">2.00</span>,</span><br><span class="line">            <span class="string">"quantity"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">"img_url"</span>: <span class="string">"bread.jpg"</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    $set:&#123;</span><br><span class="line">        <span class="string">"last_activity"</span>: ISODate()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure></li><li><p>更新某个商品的数量</p>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">db.carts.update(&#123;</span><br><span class="line">    <span class="string">"id"</span>: ObjectId(<span class="string">"*"</span>)</span><br><span class="line">    <span class="string">"items.itemid"</span>: <span class="number">4567</span></span><br><span class="line">&#125;,&#123;</span><br><span class="line">    $set:&#123;</span><br><span class="line">        <span class="string">"item.$.quantity"</span>: <span class="number">5</span>,</span><br><span class="line">        <span class="string">"last_activity"</span>: ISODate()</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>统计商品总数（<strong>聚合运算</strong>）</p>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">db.cart.createIndex(&#123;<span class="string">"items.itemid"</span>: <span class="number">1</span>&#125;)</span><br><span class="line">db.cart.aggregate(</span><br><span class="line">    &#123; $match: &#123;<span class="string">"items.itemid"</span>: <span class="number">8910</span>&#125;&#125;, <span class="comment"># 筛选出购物车里id为8910的商品</span></span><br><span class="line">    &#123; $unwind: <span class="string">"$items"</span> &#125;, <span class="comment">#　展开items数组，每个数组的元素变成一个文档</span></span><br><span class="line">    &#123; $group: &#123;</span><br><span class="line">        <span class="string">"_id"</span>: <span class="string">"$items.itemid"</span>,</span><br><span class="line">        <span class="string">"amount"</span>: &#123; <span class="string">"$sum"</span> : <span class="string">"$items.quantity"</span> &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;<span class="comment">#使用聚合运算$sum吧每一件商品的数量求和</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li></ul><h3 id="社交（Social）"><a href="#社交（Social）" class="headerlink" title="社交（Social）"></a>社交（Social）</h3><h4 id="设计考量-1"><a href="#设计考量-1" class="headerlink" title="设计考量"></a>设计考量</h4><ul><li>维护朋友关系-关注、被关注</li><li>朋友圈设计、名人效应</li></ul><h4 id="经典文档设计的问题"><a href="#经典文档设计的问题" class="headerlink" title="经典文档设计的问题"></a>经典文档设计的问题</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"id"</span>: <span class="string">"Yuan"</span>,</span><br><span class="line">    <span class="string">"fullname"</span>: <span class="string">"Zhu Zheng Yuan"</span>,</span><br><span class="line">    <span class="string">"followers"</span>: [<span class="string">"Oscar"</span>, <span class="string">"Mandy"</span>],</span><br><span class="line">    <span class="string">"following"</span>: [<span class="string">"Mandy"</span>, <span class="string">"Bert"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　如果TJ我是一个明星，他们关注我的人可能有千万。一个千万级的数组会有两个问题：<br>1.有可能超出一个文档最大16M的硬性限制； 2. MongoDB数组太大会严重影响性能。<br>　解决方案是建立一个专门的集合来描述关注关系。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; db.follower.find()</span><br><span class="line">&#123;<span class="string">"_id"</span>: ObjectId(), <span class="string">"user"</span>: <span class="string">"Yuan"</span>, <span class="string">"following"</span>: <span class="string">"Mandy"</span>&#125;</span><br><span class="line">&#123;<span class="string">"_id"</span>: ObjectId(), <span class="string">"user"</span>: <span class="string">"Yuan"</span>, <span class="string">"following"</span>: <span class="string">"Bert"</span>&#125;</span><br><span class="line">&#123;<span class="string">"_id"</span>: ObjectId(), <span class="string">"user"</span>: <span class="string">"Oscar"</span>, <span class="string">"following"</span> : <span class="string">"Yuan"</span>&#125;</span><br><span class="line">&#123;<span class="string">"_id"</span>: ObjectId(), <span class="string">"user"</span>: <span class="string">"Mandy"</span>, <span class="string">"following"</span>: <span class="string">"Yuan"</span>&#125;</span><br></pre></td></tr></table></figure><h4 id="微博墙的实现"><a href="#微博墙的实现" class="headerlink" title="微博墙的实现"></a>微博墙的实现</h4><blockquote><p>微博墙：列表显示所有<strong>关注用户</strong>的<strong>最新状态</strong></p></blockquote><p>解决方案：</p><ul><li>扇出读（常规玩法）：当你需要去获得所有你关注用户的最新更新的时候，你就去到每一个你关注用户的数据区，把最新的一些数据取回来。[最慢服务器响应时间决定了总体的响应时间]</li><li>扇出写（土豪玩法）：当被关注用户发布微博的时候，一条数据会写多次：直接写到每一个关注你的粉丝的墙上。[写入需求会被放大]</li></ul><blockquote><p>参考资料：</p><ol><li>MongoDB 进阶模式设计：<a href="http://www.mongoing.com/mongodb-advanced-pattern-design" target="_blank" rel="noopener">http://www.mongoing.com/mongodb-advanced-pattern-design</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Database </category>
          
      </categories>
      
      
        <tags>
            
            <tag> mongoDB </tag>
            
            <tag> designMode </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>机器学习中的梯度下降法</title>
      <link href="/2018/05/18/gradientDescent/"/>
      <url>/2018/05/18/gradientDescent/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="引言："><a href="#引言：" class="headerlink" title="引言："></a>引言：</h2><p>梯度下降法的在机器学习中的地位：当神经网络使用反向传播算法之后，需要使用最优化算法来减小误差。而在各种最优化算法中，梯度下降法是最简单、最常见的一种，在深度学习的训练中被广泛使用。</p><h2 id="最优化问题"><a href="#最优化问题" class="headerlink" title="最优化问题"></a>最优化问题</h2><blockquote><p>求解函数极值的问题，包括极大值和极小值</p></blockquote><ol><li>只要函数是可导的，极值点的导数必定为0。</li><li><strong>其中x称为优化变量，f称为目标函数。极大值问题可以转换成极小值问题来求解，只需要将目标函数加上负号即可</strong>：<br>$$max_xf(x)\equiv{min_x{-f(x)}}$$<!-- ![](http://ww1.sinaimg.cn/large/ca26ff18ly1fsqyceiqsdj20hs02n74p.jpg){:height="50px" width="200px"} --></li></ol><h2 id="导数与梯度"><a href="#导数与梯度" class="headerlink" title="导数与梯度"></a>导数与梯度</h2><ol><li>多元函数的梯度定义为：<br>$$\nabla{f(x)=(\frac{\partial{f}}{\partial{x_1}},…,\frac{\partial{f}}{\partial{x_n}})^{T}}$$</li></ol><p>&emsp;其中$\nabla$称为梯度算子，它作用于一个多元函数，得到一个向量。下面是计算函数梯度的一个例子：$\nabla{(x^2+xy-y^2)=(2x+y,x-2y)}$</p><ol start="2"><li>梯度为0只是函数取极值的必要条件而不是充分条件</li><li><p>如何确定驻点是极大值还是极小值？<br> 要看二阶导数/Hessian矩阵：</p><ul><li>如果Hessian矩阵正定，函数有极小值</li><li>如果Hessian矩阵负定，函数有极大值</li><li>如果Hessian矩阵不定，则需要进一步讨论</li></ul></li><li><p>为什么不可以直接求函数的梯度，来解方程？<br>答：方程可能很难解：对于有指数函数，对数函数，三角函数的方程，我们称为超越方程。比如$3x^2e^{xy}+xcos(xy)=0$。其求解的难度并不比求极值本身小。</p></li></ol><h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsr7fgqxxyj21yu2kzhe3.jpg" alt=""></p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsr7h1sclgj21yu2kze8a.jpg" alt=""></p><h2 id="面临的问题"><a href="#面临的问题" class="headerlink" title="面临的问题"></a>面临的问题</h2><blockquote><p>补充：驻点要求一阶导数必须存在，而极值点对导数没有要求</p><ol><li>局部极小值点</li><li>鞍点问题</li></ol></blockquote><h2 id="变种"><a href="#变种" class="headerlink" title="变种"></a>变种</h2><ol><li>AdaGrad(自适应梯度)</li><li>AdaDelta</li><li>Adam(adaptive moment estimation)</li><li>NAG<h2 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h2>随机梯度下降法在数学期望的意义下收敛，但并不能保证每次迭代时函数值一定下降。</li></ol><blockquote><p>参考与引用</p></blockquote><ol><li><a href="https://mp.weixin.qq.com/s/lqwUkimO4irkIZmAnp0bcg" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/lqwUkimO4irkIZmAnp0bcg</a></li><li><a href="https://blog.csdn.net/lanchunhui/article/details/52504859" target="_blank" rel="noopener">https://blog.csdn.net/lanchunhui/article/details/52504859</a></li></ol>]]></content>
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> gradientDescent </tag>
            
            <tag> mathematics </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>RNN原理介绍以及二进制加法器</title>
      <link href="/2018/04/23/RNN-introduction/"/>
      <url>/2018/04/23/RNN-introduction/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="前言：神经网络拓扑学-amp-convJS"><a href="#前言：神经网络拓扑学-amp-convJS" class="headerlink" title="前言：神经网络拓扑学&amp;convJS"></a>前言：神经网络拓扑学&amp;convJS</h2><p>两个博客的动图形象的展示了神经网络内部的工作过程。</p><blockquote><p><a href="https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/" target="_blank" rel="noopener">https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/</a><br><a href="https://cs.stanford.edu/people/karpathy/convnetjs/" target="_blank" rel="noopener">https://cs.stanford.edu/people/karpathy/convnetjs/</a></p></blockquote><h2 id="RNN（Recurrent-Neural-Network）"><a href="#RNN（Recurrent-Neural-Network）" class="headerlink" title="RNN（Recurrent Neural Network）"></a>RNN（Recurrent Neural Network）</h2><p><strong>为了简易教学过程，我会从“简易”的RNN模型逐渐过渡到“真实”的RNN模型</strong></p><h3 id="为什么会有RNN？"><a href="#为什么会有RNN？" class="headerlink" title="为什么会有RNN？"></a>为什么会有RNN？</h3><ul><li>类比人类的思考过程。人们对新事物的思考总是包含着先验知识（记忆）的</li><li>尝试从后向前背字母表的十分困难的，因为人类总是以序列为单位记忆。（就像链表）</li></ul><h3 id="RNN长成什么样？"><a href="#RNN长成什么样？" class="headerlink" title="RNN长成什么样？"></a>RNN长成什么样？</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_1.png" alt=""></p><ul><li>由上图可见，RNN的信息流是：</li></ul><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_2.png" alt=""></p><ul><li>RNN中的记忆代表prev_hidden（之前的隐层“记忆”）也被当做了输入用来训练神经网络！</li></ul><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_3.png" alt=""></p><blockquote><p>注意区分上图：一个RNN可以看作数多个相同神经网络的复制版本！</p></blockquote><ul><li>假设我们有一个时间步长为4的RNN，那么它的信息流就是<br><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_4.png" alt=""></li></ul><ul><li>让我们形象的看看“记忆”是如何影响RNN的</li></ul><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_5.png" alt=""></p><h3 id="RNN可以解决什么问题？"><a href="#RNN可以解决什么问题？" class="headerlink" title="RNN可以解决什么问题？"></a>RNN可以解决什么问题？</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_6.png" alt=""></p><blockquote><p>时间序列和列表模型：语音识别，语言模型，翻译，图像捕捉等</p></blockquote><h3 id="RNN有什么缺点吗？"><a href="#RNN有什么缺点吗？" class="headerlink" title="RNN有什么缺点吗？"></a>RNN有什么缺点吗？</h3><ul><li>the clouds are in the sky</li><li>I grew up in France… I speak fluent French.</li></ul><h4 id="长期依赖：当gap越来越大，RNN就不太可能学习有用的信息了"><a href="#长期依赖：当gap越来越大，RNN就不太可能学习有用的信息了" class="headerlink" title="长期依赖：当gap越来越大，RNN就不太可能学习有用的信息了"></a>长期依赖：当gap越来越大，RNN就不太可能学习有用的信息了</h4><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_7.png" alt=""></p><h3 id="如何解决长期依赖？"><a href="#如何解决长期依赖？" class="headerlink" title="如何解决长期依赖？"></a>如何解决长期依赖？</h3><p>看看我们大脑是如何工作的：我们的大脑有遗忘的功能，即只记住记忆中关键的信息点，而不去存储完整的记忆。这种功能让我们大脑的计算负荷大大减少。—-于是LSTM诞生了</p><h2 id="LSTM-（Long-Short-Term-Memory）"><a href="#LSTM-（Long-Short-Term-Memory）" class="headerlink" title="LSTM （Long Short Term Memory）"></a>LSTM （Long Short Term Memory）</h2><h3 id="LSTM与RNN的结构差异"><a href="#LSTM与RNN的结构差异" class="headerlink" title="LSTM与RNN的结构差异"></a>LSTM与RNN的结构差异</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_8.png" alt=""></p><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_9.png" alt=""></p><p>LSTM将RNN的单层神经网络变成了四层神经网络</p><h3 id="wtf-赶快讲讲细节"><a href="#wtf-赶快讲讲细节" class="headerlink" title="wtf?赶快讲讲细节"></a>wtf?赶快讲讲细节</h3><h4 id="我们在图中有以下约定："><a href="#我们在图中有以下约定：" class="headerlink" title="我们在图中有以下约定："></a>我们在图中有以下约定：</h4><ul><li>图中的线条代表一个完整的向量</li><li>粉色圆圈代表一个向量操作</li></ul><h3 id="LSTM的核心思想"><a href="#LSTM的核心思想" class="headerlink" title="LSTM的核心思想"></a>LSTM的核心思想</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_10.png" alt=""></p><ul><li><p>上图表示LSTM有能力给Cell state添加或者删除信息（这些能力被一种叫做<strong>gates</strong>的结构控制）</p></li><li><p>gates:一条信息经过的路径由运算函数和sigmoid函数构成</p></li></ul><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_11.png" alt=""></p><h4 id="补充：重新认识sigmoid函数："><a href="#补充：重新认识sigmoid函数：" class="headerlink" title="补充：重新认识sigmoid函数："></a>补充：重新认识sigmoid函数：</h4><p>$$S(x)= \frac{1}{1+e^{-x}}$$</p><p>$$S^{‘}{(x)}=\frac{e^{-x}}{(1+e^{-x})^2}=S(x)(1-S(x))$$</p><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_12.png" alt=""></p><p>　很明显，其作用是把x映射到$[0,1]$：0表示忘记，1表示记住</p><h3 id="LSTM的具体工作流程"><a href="#LSTM的具体工作流程" class="headerlink" title="LSTM的具体工作流程"></a>LSTM的具体工作流程</h3><ol><li>LSTM第一步便是决定从cell state中丢弃的信息(由sigmoid函数完成)</li></ol><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_13.png" alt=""></p><p>$$f_t=\sigma(W_f·[h_{t-1},x_t] + b_f)$$</p><ol start="2"><li><p>LSTM第二步是决定将那些新信息保存至cell state</p><ul><li>sigmoid层决定更新哪些值</li><li><p>tanh层则负责创建一个新的候选值</p><p>$$i_t = \sigma(W_i·[h_{t-1},x_t]+b_i)$$</p><p>$$\hat{C_t}=tanh(W_C·[h_{t-1},x_t]+b_C)$$</p></li></ul></li></ol><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_14.png" alt=""></p><ol start="3"><li>更新$C_{t-1}$为新的$C_t$</li></ol><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_15.png" alt=""></p><p>$$C_t=f_t <em> C_{t-1}+i_t </em> \hat{C_t}$$</p><ol start="4"><li>LSTM决定输出值<ul><li>使用sigmoid层决定那一部分用作输出</li><li>通过tanh和部分输出决定总输出</li></ul></li></ol><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_16.png" alt=""></p><p>$$o_t=\sigma(W_o[h_{t-1},x_t]+b_o)$$</p><p>$$h_t = o_t *tanh(C_t)$$</p><h2 id="回归RNN，我们来简单的描述下RNN梯度下降的过程"><a href="#回归RNN，我们来简单的描述下RNN梯度下降的过程" class="headerlink" title="回归RNN，我们来简单的描述下RNN梯度下降的过程"></a>回归RNN，我们来简单的描述下RNN梯度下降的过程</h2><h3 id="简单介绍传统神经网络的反向传播算法"><a href="#简单介绍传统神经网络的反向传播算法" class="headerlink" title="简单介绍传统神经网络的反向传播算法"></a>简单介绍传统神经网络的反向传播算法</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_17.png" alt=""></p><h3 id="再来看看真实的RNN到底是什么样子的"><a href="#再来看看真实的RNN到底是什么样子的" class="headerlink" title="再来看看真实的RNN到底是什么样子的"></a>再来看看真实的RNN到底是什么样子的</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_18.png" alt=""></p><h4 id="我们约定图中符号为："><a href="#我们约定图中符号为：" class="headerlink" title="我们约定图中符号为："></a>我们约定图中符号为：</h4><ul><li>t时刻的输入：$x^t\in R^{xdim}$</li><li>隐层节点的输出：$h^t\in R^{hdim}$</li><li>输出层的预测值:$y^t\in R^{ydim}$</li><li>从输入到隐层的权重矩阵：$V\in R^{xdim·ydim}$</li><li>隐层的自循环矩阵:$U\in R^{hdim·hdim}$</li><li>隐层到输出层的权重矩阵:$W\in R^{hdim·ydim}$</li><li>各层对应的偏置向量: $b_h\in R^{hdim},b_y\in R^{ydim}$</li><li>输入层、隐层、输出层的节点为标识为$i、j、k$</li><li>真实的输出：$d^t\in R^{ydim}$</li></ul><h4 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h4><ol><li>$h^t=activate_1(x^tV+h^{t-1}U+b_h)$，其中令$net_h^t=x^tV+h^{t-1}U+b_h$</li><li>$y^t=activate_2(h^tW+b_y)$,其中令$net_y^t=h^tW+b_y$</li><li>定义单个时间节点$p$的误差为<br> $$E^t=\sum_p\frac{1}{2}||d^t-y^t||^2$$</li><li><p>则有总误差为</p><p> $$E=\sum_tE^t=\frac{1}{2}\sum_p{\sum^T_{t=1}||y^t-d^t||^2}$$</p></li></ol><h4 id="反向传播：Backpropation-Through-Time-BPTT"><a href="#反向传播：Backpropation-Through-Time-BPTT" class="headerlink" title="反向传播：Backpropation Through Time(BPTT)"></a>反向传播：Backpropation Through Time(BPTT)</h4><ol><li>计算RNN内参数的梯度<br>$$\delta^t_{yk}=\frac{\partial{E}}{\partial{net^t_{yk}}}，\delta^t_{hj}=\frac{\partial{E}}{\partial^t_{hj}}$$</li></ol><blockquote><p>这两个偏导数是为：总误差分别对第t个时间节点的输出层的第k个节点&amp;隐藏层的第j个节点的偏导数</p></blockquote><p>展开则有：</p><p>$$\delta^t_{yk}={\frac{\partial{E}}{\partial{y^t_k}}}{\frac{\partial{y^t_k}}{\partial{net^t_{yk}}}}=(y^t_k-d^t_k){g^{‘}(net^t_{yk})}$$</p><p>将上式向量化表示有：<br>$$\delta_y^t=(y^t-d^t)\circ{g^{‘}(net^t_y)}, \circ表示对应元素相乘而非矩阵乘法$$<br>$$\delta_h^t=(W(\delta_y^t)^T+U(\delta^{t+1}_h)^T)^T\circ{f^{‘}(net^t_h)}$$<br>由此可得各个参数的梯度为：<br>$$\Delta{W}=\sum_t{(h^{t})^T\delta^t_y}$$</p><p>$$\Delta{U}=\sum_t{(h^{t-1})^T\delta^t_h}$$</p><p>$$\Delta{V}=\sum_t{(x^t)^T\delta^t_h}$$</p><p>$$\Delta{by}=\sum_t{\delta^t_y}$$</p><p>$$\Delta{bh}=\sum_t{\delta^t_h}$$</p><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_19.png" alt=""></p><blockquote><p>注意：从上图中可以很明显的观察到计算t时刻的梯度时，需要用到$t-1，t-2,…$时刻计算得到的梯度。</p></blockquote><h2 id="来用python写一个小demo（二进制加法器）试试？"><a href="#来用python写一个小demo（二进制加法器）试试？" class="headerlink" title="来用python写一个小demo（二进制加法器）试试？"></a>来用python写一个小demo（二进制加法器）试试？</h2><h3 id="我们的目标："><a href="#我们的目标：" class="headerlink" title="我们的目标："></a>我们的目标：</h3><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RNN_t_20.png" alt=""></p><p>我们想要完成一个八位二进制加法器：进位从第三位开始！这个加法器可以直接预测两个八位二进制数的结果，并且我们想要RNN学会是否进位这个“记忆”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Author  : zzy824</span></span><br><span class="line"><span class="comment"># @File    : traskRNNTutorial.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute sigmoid nonlinearity</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    output = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert output of sigmoid function to its derivative</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_output_to_derivative</span><span class="params">(output)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> output * (<span class="number">1</span> - output)</span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time    : 2018/4/24 下午2:43</span></span><br><span class="line"><span class="comment"># @Author  : zzy824</span></span><br><span class="line"><span class="comment"># @File    : traskRNNTutorial.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compute sigmoid nonlinearity</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    output = <span class="number">1</span> / (<span class="number">1</span> + np.exp(-x))</span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert output of sigmoid function to its derivative</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_output_to_derivative</span><span class="params">(output)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> output * (<span class="number">1</span> - output)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training dataset generation</span></span><br><span class="line">int2binary = &#123;&#125;</span><br><span class="line">binary_dim = <span class="number">8</span></span><br><span class="line"></span><br><span class="line">largest_number = pow(<span class="number">2</span>, binary_dim)</span><br><span class="line">binary = np.unpackbits(np.array([range(largest_number)], dtype=np.uint8).T, axis=<span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(largest_number):</span><br><span class="line">    int2binary[i] = binary[i]</span><br><span class="line"></span><br><span class="line"><span class="comment"># input variables</span></span><br><span class="line">alpha = <span class="number">0.1</span></span><br><span class="line">input_dim = <span class="number">2</span> <span class="comment"># because we add two number </span></span><br><span class="line">hidden_dim = <span class="number">16</span> </span><br><span class="line">output_dim = <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize neural network weights</span></span><br><span class="line">synapse_0 = <span class="number">2</span> * np.random.random((input_dim, hidden_dim)) - <span class="number">1</span> <span class="comment"># input&amp;hidden</span></span><br><span class="line">synapse_1 = <span class="number">2</span> * np.random.random((hidden_dim, output_dim)) - <span class="number">1</span> <span class="comment"># hidden&amp;output</span></span><br><span class="line">synapse_h = <span class="number">2</span> * np.random.random((hidden_dim, hidden_dim)) - <span class="number">1</span> <span class="comment"># hidden&amp;hidden</span></span><br><span class="line"></span><br><span class="line">synapse_0_update = np.zeros_like(synapse_0)</span><br><span class="line">synapse_1_update = np.zeros_like(synapse_1)</span><br><span class="line">synapse_h_update = np.zeros_like(synapse_h)</span><br><span class="line"></span><br><span class="line"><span class="comment"># training logic</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="comment"># generate a simple addition problem (a + b = c)</span></span><br><span class="line">    a_int = np.random.randint(largest_number / <span class="number">2</span>)  <span class="comment"># int version</span></span><br><span class="line">    a = int2binary[a_int]  <span class="comment"># binary encoding</span></span><br><span class="line">    b_int = np.random.randint(largest_number / <span class="number">2</span>)  <span class="comment"># int version</span></span><br><span class="line">    b = int2binary[b_int]  <span class="comment"># binary encoding</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># true answer</span></span><br><span class="line">    c_int = a_int + b_int</span><br><span class="line">    c = int2binary[c_int]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># where we'll store our best guess (binary encoded)</span></span><br><span class="line">    d = np.zeros_like(c)</span><br><span class="line"></span><br><span class="line">    overallError = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    layer_2_deltas = list()</span><br><span class="line">    layer_1_values = list()</span><br><span class="line">    layer_1_values.append(np.zeros(hidden_dim))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># moving along the positions in the binary encoding</span></span><br><span class="line">    <span class="keyword">for</span> position <span class="keyword">in</span> range(binary_dim):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># generate input and output</span></span><br><span class="line">        X = np.array([[a[binary_dim - position - <span class="number">1</span>], b[binary_dim - position - <span class="number">1</span>]]])</span><br><span class="line">        y = np.array([[c[binary_dim - position - <span class="number">1</span>]]]).T</span><br><span class="line"></span><br><span class="line">        <span class="comment"># hidden layer (input ~+ prev_hidden)</span></span><br><span class="line">        layer_1 = sigmoid(np.dot(X, synapse_0) + np.dot(layer_1_values[<span class="number">-1</span>], synapse_h))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># output layer (new binary representation)</span></span><br><span class="line">        layer_2 = sigmoid(np.dot(layer_1, synapse_1))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># did we miss?... if so, by how much?</span></span><br><span class="line">        layer_2_error = y - layer_2</span><br><span class="line">        layer_2_deltas.append(layer_2_error * sigmoid_output_to_derivative(layer_2))</span><br><span class="line">        overallError += np.abs(layer_2_error[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># decode estimate so we can print it out</span></span><br><span class="line">        d[binary_dim - position - <span class="number">1</span>] = np.round(layer_2[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">        <span class="comment"># store hidden layer so we can use it in the next timestep</span></span><br><span class="line">        layer_1_values.append(copy.deepcopy(layer_1))</span><br><span class="line"></span><br><span class="line">    future_layer_1_delta = np.zeros(hidden_dim)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> position <span class="keyword">in</span> range(binary_dim):</span><br><span class="line">        X = np.array([[a[position], b[position]]])</span><br><span class="line">        layer_1 = layer_1_values[-position - <span class="number">1</span>]</span><br><span class="line">        prev_layer_1 = layer_1_values[-position - <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># error at output layer</span></span><br><span class="line">        layer_2_delta = layer_2_deltas[-position - <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># error at hidden layer</span></span><br><span class="line">        layer_1_delta = (future_layer_1_delta.dot(synapse_h.T) + layer_2_delta.dot(synapse_1.T)) * sigmoid_output_to_derivative(</span><br><span class="line">            layer_1)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># let's update all our weights so we can try again</span></span><br><span class="line">        synapse_1_update += np.atleast_2d(layer_1).T.dot(layer_2_delta)</span><br><span class="line">        synapse_h_update += np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)</span><br><span class="line">        synapse_0_update += X.T.dot(layer_1_delta)</span><br><span class="line"></span><br><span class="line">        future_layer_1_delta = layer_1_delta</span><br><span class="line"></span><br><span class="line">        synapse_0 += synapse_0_update * alpha</span><br><span class="line">        synapse_1 += synapse_1_update * alpha</span><br><span class="line">        synapse_h += synapse_h_update * alpha</span><br><span class="line"></span><br><span class="line">        synapse_0_update *= <span class="number">0</span></span><br><span class="line">        synapse_1_update *= <span class="number">0</span></span><br><span class="line">        synapse_h_update *= <span class="number">0</span></span><br><span class="line">        <span class="comment"># print out progress</span></span><br><span class="line">        <span class="keyword">if</span> j % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"Error:"</span> + str(overallError)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"Pred:"</span> + str(d)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"True:"</span> + str(c)</span><br><span class="line">            out = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> index, x <span class="keyword">in</span> enumerate(reversed(d)):</span><br><span class="line">                out += x * pow(<span class="number">2</span>, index)</span><br><span class="line">            <span class="keyword">print</span> str(a_int) + <span class="string">" + "</span> + str(b_int) + <span class="string">" = "</span> + str(out)</span><br><span class="line">            <span class="keyword">print</span> <span class="string">"------------"</span></span><br></pre></td></tr></table></figure><blockquote><p>引用与参考资料</p><ol><li>pytorch官方文档：<a href="http://pytorch.org/tutorials/" target="_blank" rel="noopener">http://pytorch.org/tutorials/</a></li><li>pytorch官方项目样例：<a href="https://github.com/pytorch/examples" target="_blank" rel="noopener">https://github.com/pytorch/examples</a></li><li>colah博客：<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></li><li>RNN求解过程：<a href="https://www.cnblogs.com/YiXiaoZhou/p/6058890.html" target="_blank" rel="noopener">https://www.cnblogs.com/YiXiaoZhou/p/6058890.html</a></li><li>i am trask博客: <a href="https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/" target="_blank" rel="noopener">https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/</a></li><li>反向传播算法图来源：<a href="https://zhuanlan.zhihu.com/p/31623305" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31623305</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> DeepLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> rnn </tag>
            
            <tag> lstm </tag>
            
            <tag> deepLearning </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>ionic常见报错解决方案&amp;常用命令</title>
      <link href="/2018/04/17/web-app-ionic/"/>
      <url>/2018/04/17/web-app-ionic/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="常见报错"><a href="#常见报错" class="headerlink" title="常见报错"></a>常见报错</h2><ul><li><p><strong>npm WARN checkPermissions Missing write access to</strong><br><strong>Solution</strong></p><ol><li><p>方案一</p><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/web-app-ionic-1.png" alt=""></p></li><li><p>方案二</p><ul><li>sudo npm i -g npm // 重新全局安装npm</li><li>sudo chown -R your_user_name /usr/local/lib // 修改npm文件夹的权限</li></ul></li></ol></li><li><p>Downloading and extracting blank starter - failed!Error: socket hang up<br><strong>Solution</strong>:</p></li></ul><ol><li>针对特定版本的解决方案：<a href="https://www.jianshu.com/p/6509070114e2" target="_blank" rel="noopener">https://www.jianshu.com/p/6509070114e2</a></li><li>sudo cnpm install -g ionic cordova // 需要记住的核心思想：<strong>能用cnpm尽量不要用npm</strong></li><li>ionic start myApp <a href="https://github.com/ionic-team/starters" target="_blank" rel="noopener">https://github.com/ionic-team/starters</a> // 如果模板源的网站没有响应，则可以尝试直接去github上clone源代码</li></ol><ul><li><p>ERROR] The package.json file seems malformed.<br><strong>Solution</strong>:</p><pre><code>In to of package.json at the root(base level), add ‘name’ key like &quot;name&quot;: &quot;My_App_Name&quot;,.Also at same base level add &quot;author&quot;: &quot;YourName&quot;,</code></pre></li><li><p>如果需要安装依赖</p><p>  cnpm install –save （安装完一些包之后要记得save，这个步骤十分容易忘记） </p></li><li><p>➜  ionicdemo ionic serve<br>Error: Cannot find module ‘tslint’<br>  at Function.Module._resolveFilename (module.js:547:15)<br>  at Function.Module._load (module.js:474:25)<br>  at Module.require (module.js:596:17)<br>  at require (internal/module.js:11:18)<br>  at Object.<anonymous> (/Users/zzy824/ionicPrijects/ionicdemo/node<em>modules/</em>@<a href="mailto:ionic_app-scripts@3.1.8" target="_blank" rel="noopener">ionic_app-scripts@3.1.8</a>@@ionic/app-scripts/dist/lint/lint-factory.js:3:16)<br>  at Module._compile (module.js:652:30)<br>  at Object.Module._extensions..js (module.js:663:10)<br>  at Module.load (module.js:565:32)<br>  at tryModuleLoad (module.js:505:12)<br>  at Function.Module._load (module.js:497:3)</anonymous></p><p>  <strong>solution</strong>:</p><pre><code>&gt; rm -rf node_modules  &gt; npm restart&gt; npm update  &gt; cnpm install --save  </code></pre></li><li><p>npm install出现”Unexpected end of JSON input while parsing near” </p></li></ul><p>npm cache clean –force</p><ul><li>ionic中调用摄像头</li></ul><p>提前准备plugman：一个专门为了cordova提供插件的命令行工具<br>        npm installd -g plugman<br>第一步是安装ionic-native/core。所有用到Native的功能，这一步不能省。<br>        npm install @ionic-native/core –save</p><ul><li>“/usr/bin/env: node: No such file or directory”<br>软链接文件： <code>ln -s /usr/bin/nodejs /usr/bin/node</code></li></ul><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//下载依赖包</span></span><br><span class="line">cnpm i </span><br><span class="line"><span class="comment">//移动端启动</span></span><br><span class="line">ionic serve -l </span><br><span class="line"></span><br><span class="line"><span class="comment">//在一个连接的设备上运行项目</span></span><br><span class="line">ionic cordova run [platform] [options]</span><br><span class="line">ionic cordova run [ios/android] [-lc]</span><br><span class="line"></span><br><span class="line"><span class="comment">//在ios手机上运行需要安装平台</span></span><br><span class="line">ionic cordova platform add ios</span><br><span class="line">ionic cordova platform add android</span><br><span class="line"></span><br><span class="line"><span class="comment">//在平台下修改代码后打包</span></span><br><span class="line">ionic build</span><br><span class="line"><span class="comment">//在phoneGap上做测试</span></span><br><span class="line">ionic cordova plugin add phonegap-plugin-local-notification</span><br><span class="line">npm install --save @ionic-native/phonegap-local-notification</span><br><span class="line"><span class="comment">//声明一个组件</span></span><br><span class="line">ionic g component [component name] </span><br><span class="line"><span class="comment">//声明一个新页面</span></span><br><span class="line">ionic g page [page name]</span><br></pre></td></tr></table></figure><blockquote><p>引用与参考</p><ol><li><a href="https://blog.csdn.net/yuxiaofan1245023886/article/details/52251410" target="_blank" rel="noopener">https://blog.csdn.net/yuxiaofan1245023886/article/details/52251410</a></li><li><a href="http://www.jb51.net/article/115645.htm" target="_blank" rel="noopener">http://www.jb51.net/article/115645.htm</a></li><li><a href="https://github.com/nodejs/node-v0.x-archive/issues/3911" target="_blank" rel="noopener">https://github.com/nodejs/node-v0.x-archive/issues/3911</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> App </category>
          
      </categories>
      
      
        <tags>
            
            <tag> ionic </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>量化投资</title>
      <link href="/2018/04/16/quantitative-investment-summary/"/>
      <url>/2018/04/16/quantitative-investment-summary/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h1 id="什么是量化投资？"><a href="#什么是量化投资？" class="headerlink" title="什么是量化投资？"></a>什么是量化投资？</h1><p>股市被认为是混乱的，复杂的，波动的和动态的。通过计算机<strong>程序化</strong>发出买卖指令，以获取<strong>稳定收益</strong>为目的的交易方式。通俗地讲，就是预先设定一套<strong>固定的逻辑</strong>，点明选股及何时买入何时卖出的标准。实盘操作时，实时接收行情数据并进行分析，当达到预先设定的标准时，即<strong>自动进行买入卖出</strong>的操作。</p><h1 id="量化投资的优越性到底在哪里？"><a href="#量化投资的优越性到底在哪里？" class="headerlink" title="量化投资的优越性到底在哪里？"></a>量化投资的优越性到底在哪里？</h1><p>打个比方，我们可以作一个机器人王亚伟。我们可以根据王亚伟什么时候买进，什么时候卖出，我们把一个股票分解成60多个因子。比如，基本面是什么样的，分析员是怎么说的，现在的价、量是什么情况，列出60几个因子。<br>其中，哪几个因子绿灯，是它该买的时候；该卖出的时候，哪几个灯灭掉了。<br>一一对比之后，你知道他买的股票，看重哪几个因子。<br>这样，按照他的方法，我们可以整个市场几千只股票全部扫一遍，计算机每天大概几分钟就扫完了，晒出一大批王亚伟类型的股票。<br>按这个方法去做，实际上可以了一个机器人王亚伟。</p><ul><li>就是把所有的投资决定分散，分地越散越好，而人类的物理性能无法与计算机相匹敌。</li><li>求胜率。每一个投资决定的胜率只要高出平均水平，达到51%。把这两步做到了之后，基本上量化就没有问题了。</li></ul><hr><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/quantitative_investment_1.png" alt=""></p><hr><h1 id="人工智能时代的量化投资策略"><a href="#人工智能时代的量化投资策略" class="headerlink" title="人工智能时代的量化投资策略"></a>人工智能时代的量化投资策略</h1><p>人工智能的浪潮已经席卷生活中越来越多的领域：语音识别、图像识别、风控监控、智能推荐、无人驾驶……<br>机器开始在许多方面逐步代替人类的工作，大大解放了人类的双手，在某些领域还能完成许多人类无法胜任的工作，那么投资如何？</p><h2 id="案例：利用LSTM预测真实金融数据"><a href="#案例：利用LSTM预测真实金融数据" class="headerlink" title="案例：利用LSTM预测真实金融数据"></a>案例：利用LSTM预测真实金融数据</h2><ol><li>通过合理途径获取到金融历史数据</li><li><p>数据清理与归一化</p><ul><li>去极值：跳水比赛或体操比赛中，通常会去掉最高分和最低分，在剩下的裁判打分中取平均值，同样的道理，对于某个单因子，3000多只股票就对应3000多个因子值，有些高的离谱，有些低的离谱，这些异常值就像跳水和体操比赛打分里的极端值，通常给予剔除的处理。</li><li>因子值标准化：试想一下如果小王同学用两个因子来择偶，一个是身高，一个是颜值，身高的取值范围在150-180cm，颜值的取值在0-10分，这两个因子的单位（量纲）都不同，自然不能够相加，这可怎么办呢，小王想了个办法，身高180cm对应10分，150cm对应0分，中间的身高对应得分则用下图的函数映射给出，这个过程就是因子值的标准化。</li><li>值、行业中性处理：每个单因子对股价的影响力都有着千丝万缕的联系，比如市盈率因子与市值因子对股价都有影响，小市值的股票里也有市盈率低的股票，市盈率低的股票也不都是大票。</li></ul><ol><li>特征降维：（主成分分析法）</li></ol></li><li><p>制作数据集：具体操作是：取当前时刻及其之前的N段数据构成序列，将每一段序列作为一个新的数据点。另外，该学习方法属于监督学习，每一个数据都要有其对应的标签（label），我们取其下一时刻的涨跌情况作为label，按照涨跌幅度分为五类，使其近似满足正态分布。</p></li><li><p>划分训练集与测试集</p></li><li>构建LSTM神经网络，开始训练</li><li>编写交易策略。最简单的策略即根据预测涨跌情况直接进行交易选择，如未来连续几个时间点上涨即买入，连续几个时间点下跌即卖出。当然也可以与一般的交易策略结合，如预测金叉与死叉点等，并加入止盈止损策略。</li></ol><h1 id="仰望星空，深度学习我们应该掌握的原理有什么？"><a href="#仰望星空，深度学习我们应该掌握的原理有什么？" class="headerlink" title="仰望星空，深度学习我们应该掌握的原理有什么？"></a>仰望星空，深度学习我们应该掌握的原理有什么？</h1><blockquote><p>近年来，深度神经网络在语音、图像领域取得突出进展，以至于很多人将深度学习与深度神经网络等同视之。</p></blockquote><h2 id="什么是深度学习？"><a href="#什么是深度学习？" class="headerlink" title="什么是深度学习？"></a>什么是深度学习？</h2><p>我们都知道现在人工智能很热，掀起这股的热潮最重要的技术之一就是深度学习技术。今天当我们谈到深度学习的时候，其实已经可以看到在各种各样的应用，包括图像、视频、声音、自然语言处理等等。如果我们问一个问题，什么是深度学习？大多数人基本会认为，深度学习差不多就等于深度神经网络。</p><p><strong>深度学习不等于深度神经网络</strong>：深度强化学习（D.silver&amp;Sutton）、gcForest（周志华）.etc</p><h2 id="什么是神经网络？"><a href="#什么是神经网络？" class="headerlink" title="什么是神经网络？"></a>什么是神经网络？</h2><ul><li><p>神经网络长成什么样？：类比人脑，（简单的计算模型）</p><ul><li>数学表达形式：$y = a(W*x+b)$;</li><li>形象的理解便是：1.升维/降维 2.放大/缩小 3. 旋转 4.平移 5.<strong>“弯曲”</strong> （保证连续，可微分—&gt;BP算法才有用武之地！） </li></ul></li><li><p>神经网络的训练过程如何？</p><ul><li>loss function(目标与预测差距有多少) 【我看到一直老虎却认成一只猫，loss就在于“王”上】</li><li>梯度下降：loss值向当前点对应梯度的反方向不断移动，来降低loss。（BP算法）</li></ul></li></ul><h2 id="为什么是深度学习而不是宽度学习？"><a href="#为什么是深度学习而不是宽度学习？" class="headerlink" title="为什么是深度学习而不是宽度学习？"></a>为什么是深度学习而不是宽度学习？</h2><ul><li>深度学习泛函表达能力会更强（学习到特征的能力会更强，<strong>逐层</strong>抽象能力更强）</li><li>神经网络的万有逼近能力（泰勒公式、傅里叶变换等）</li></ul><h1 id="脚踏实地，让我们谈谈到底该使用什么工具？"><a href="#脚踏实地，让我们谈谈到底该使用什么工具？" class="headerlink" title="脚踏实地，让我们谈谈到底该使用什么工具？"></a>脚踏实地，让我们谈谈到底该使用什么工具？</h1><ul><li>pytorch</li><li>numpy</li><li>pandas</li></ul><h1 id="学术界与工业界的前沿探索"><a href="#学术界与工业界的前沿探索" class="headerlink" title="学术界与工业界的前沿探索"></a>学术界与工业界的前沿探索</h1><ul><li>通过预测公司基本面来改善基于因子的量化投资</li></ul><p>上市公司需要定期发布报告反映公司基本面的财务数据，如收入，营业收入，债务等。这些数据点为公司的财务状况提供了一些参考。学术研究已经验证了一些有效因子，即通过回测分析历史报告数据的计算因子，可以获得超越市场平均水平的表现。其中，两个受欢迎的因子是账面价值（按市值归一化调整）和营业收入（按EBIT / EV归一化调整）。通过回测表明，如果我们能够（透视）选择使用基于未来基本面计算的因子（通过预测）来选择股票，那么我们的投资组合将远远超越标准因子选股方法。受此分析的启发，我们训练深度神经网络以预测未来5年的基本面数据。</p><ul><li>使用机器学习算法预测ETF</li></ul><p>专注于预测几个具有流动性的ETF的涨跌方向（向上或向下），并不试图预测价格变化的幅度。结论：1. 短期价格服从随机游走假设 2. 横截面和跨期的成交量对于一个强大的信息集的重要性 3. 大量特征是可预测性所必需的，因为每个特征提供的贡献非常小。 4. ETFs可以用机器学习算法进行预测，但实践者应该将先前的市场和直觉知识纳入资产类别行为。</p><hr><blockquote><p>引用参考资料和版权说明<br>    <a href="https://zhuanlan.zhihu.com/p/33430725" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33430725</a><br>    <a href="https://zhuanlan.zhihu.com/p/29451486" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29451486</a><br>    <a href="https://zhuanlan.zhihu.com/p/22260743" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22260743</a><br>    <a href="https://zhuanlan.zhihu.com/p/25919734" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25919734</a><br>    <a href="https://zhuanlan.zhihu.com/p/26037052" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26037052</a><br>    <a href="https://zhuanlan.zhihu.com/p/35044817" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/35044817</a><br>    <a href="https://mp.weixin.qq.com/s/ROk5lK5gWj6pl4-ebrHG_A" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/ROk5lK5gWj6pl4-ebrHG_A</a><br>    <a href="https://www.zhihu.com/question/22553761/answer/36429105" target="_blank" rel="noopener">https://www.zhihu.com/question/22553761/answer/36429105</a><br>    <a href="https://arxiv.org/pdf/1711.04837.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1711.04837.pdf</a><br>    <a href="https://arxiv.org/pdf/1801.01777.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1801.01777.pdf</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> QuantitativeInvestment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> machinelearning </tag>
            
            <tag> rnn </tag>
            
            <tag> lstm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>解谜计算机科学-王垠著（连载中）</title>
      <link href="/2018/03/15/yin-wang-riddle-computer-science/"/>
      <url>/2018/03/15/yin-wang-riddle-computer-science/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="绪论：解谜计算机科学"><a href="#绪论：解谜计算机科学" class="headerlink" title="绪论：解谜计算机科学"></a>绪论：解谜计算机科学</h2><h3 id="写作动机"><a href="#写作动机" class="headerlink" title="写作动机"></a>写作动机</h3><blockquote><p>爱因斯坦：如果你不能把一个问题跟六岁小孩解释清楚，那你并不真的理解它</p></blockquote><h3 id="写作目标"><a href="#写作目标" class="headerlink" title="写作目标"></a>写作目标</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(你看过此书):</span><br><span class="line">    <span class="keyword">while</span>(世界末日 <span class="keyword">and</span> 计算机不复存在):</span><br><span class="line">        你可以从头开始制作计算机,cool!</span><br><span class="line">```     </span><br><span class="line">## 第一章：初识计算</span><br><span class="line">### 计算的本质</span><br><span class="line">- 手指算数便是最简单的计算机</span><br><span class="line">- 计算图：抽象是计算机科学至关重要的方法</span><br><span class="line">![](http:<span class="comment">//www.yinwang.org/csbook-images/adder.png)</span></span><br><span class="line">![](http:<span class="comment">//www.yinwang.org/csbook-images/add-mult.png)</span></span><br><span class="line">- 并行计算</span><br><span class="line">![](http:<span class="comment">//www.yinwang.org/csbook-images/parallel.png)</span></span><br><span class="line">#### 并行计算虽好，但是还会引发其他的问题：</span><br><span class="line">- 并行计算的计算机运算速度不一样：等待时间太长了！</span><br><span class="line">- 计算机之间的通信开销会极大地降低效率</span><br><span class="line">- 编译</span><br><span class="line"></span><br><span class="line">``` js</span><br><span class="line">(<span class="number">5</span> - <span class="number">3</span>) * (<span class="number">4</span> + (<span class="number">2</span> * <span class="number">3</span> - <span class="number">5</span>) * <span class="number">6</span>)</span><br><span class="line">===&gt;</span><br><span class="line">&#123;</span><br><span class="line">    a = <span class="number">2</span> * <span class="number">3</span></span><br><span class="line">    b = a - <span class="number">5</span></span><br><span class="line">    c = b * <span class="number">6</span></span><br><span class="line">    d = <span class="number">4</span> + c</span><br><span class="line">    e = <span class="number">5</span> - <span class="number">3</span></span><br><span class="line">    e * d</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="使语句的结果与原来的表达式完全一致。这种保留原来语义的翻译过程，叫做编译"><a href="#使语句的结果与原来的表达式完全一致。这种保留原来语义的翻译过程，叫做编译" class="headerlink" title="使语句的结果与原来的表达式完全一致。这种保留原来语义的翻译过程，叫做编译"></a>使语句的结果与原来的表达式完全一致。这种保留原来语义的翻译过程，叫做编译</h4><ul><li><p>函数<br>考虑如下的场景：我们想要表达一个“风扇控制器”，风扇的转速总是当前气温的两倍。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">t-&gt;t*<span class="number">2</span> <span class="comment">//这便是我们的风扇控制器，也就是一个最简单的函数：</span></span><br><span class="line">f(t) = t*<span class="number">2</span> <span class="comment">//让我们更规范一些</span></span><br><span class="line">f(<span class="number">2</span>)   <span class="comment">// 值为4</span></span><br></pre></td></tr></table></figure></li><li><p>分支<br>考虑如下的场景：我们想要一个“饮料选择器”</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">t-&gt; <span class="keyword">if</span>(t &lt; <span class="number">22</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"hotpot"</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"ice cream"</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>总结：计算的要素</p><ol><li>基础的数值。（整数，字符串，布尔值等等）</li><li>表达式。（基本的算数表达式）</li><li>变量和赋值语句。</li><li>分支语句</li><li><p>函数和函数调用</p><p>像学开车一样，一旦你掌握了油门，刹车，换挡器，方向盘，速度表的功能和用法，你就学会了开所有的汽车，不管它是什么型号的汽车。</p></li></ol></li></ul>]]></content>
      
      <categories>
          
          <category> ComputerScience </category>
          
      </categories>
      
      
        <tags>
            
            <tag> readingNote </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>北邮复试笔试复习</title>
      <link href="/2018/02/20/BUPT-exam-note/"/>
      <url>/2018/02/20/BUPT-exam-note/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>这是我自己复习的时候做的笔记，需要的同学可以简单浏览，最主要的还是多去做真题。</p></blockquote><h1 id="第一门：软件工程"><a href="#第一门：软件工程" class="headerlink" title="第一门：软件工程"></a>第一门：软件工程</h1><h2 id="导学：软件开发过程-6点"><a href="#导学：软件开发过程-6点" class="headerlink" title="导学：软件开发过程:6点"></a>导学：软件开发过程:6点</h2><ul><li>做什么：需求分析</li><li>怎么做：系统设计</li><li>具体做：系统开发</li><li>检查对不对：测试人员</li><li>让用户用：工程实施人员</li><li>维护系统：系统维护人员</li></ul><h2 id="软件工程概述"><a href="#软件工程概述" class="headerlink" title="软件工程概述"></a>软件工程概述</h2><blockquote><p>软件的定义：软件=程序+数据+文档</p></blockquote><h3 id="软件的分类"><a href="#软件的分类" class="headerlink" title="软件的分类"></a>软件的分类</h3><ol><li>系统软件：操作系统、设备驱动程序、通信处理程序</li><li>中间件软件：各种中间件，应用服务器</li><li>应用软件：特定领域内开发，为特定目的服务的一类软件</li></ol><h3 id="软件工程三要素"><a href="#软件工程三要素" class="headerlink" title="软件工程三要素"></a>软件工程三要素</h3><ol><li><strong>方法</strong>：如何做的技术</li><li><strong>工具</strong>：软件支撑环境</li><li><strong>过程</strong>：综合软件工程的方法和工具</li></ol><h3 id="八条一般原理"><a href="#八条一般原理" class="headerlink" title="八条一般原理"></a>八条一般原理</h3><blockquote><p>1.抽象 2.信息隐藏 3.模块化 4.局部化 5.确定性 6.一致性 7.完备性 8.可验证性</p></blockquote><h2 id="软件生命周期模型"><a href="#软件生命周期模型" class="headerlink" title="软件生命周期模型"></a>软件生命周期模型</h2><ul><li>瀑布模型：阶段性顺序串行</li><li>原型方法：通过小型原型软件添枝加叶</li><li>演化模型：综合瀑布模型和原型方法，两次开发。</li><li>增量模型：建立原型然后增量更新</li><li>螺旋模型：引入了明确的风险管理的四个象限（制定计划、风险分析、实施工程、客户评价）</li><li>喷泉模型：佛系开发，无章法。</li><li>构建组装模型：模块化组件开发</li><li>快速应用开发模型：快速增量型开发</li><li>统一过程模型：博采众家之长</li><li><p>敏捷模型：<strong>一种态度，非方法论</strong></p><blockquote><p>极限编程：最新理论成果</p><ul><li>小版本高速迭代</li><li>简单设计</li><li>结对编程</li><li>代码共有</li></ul></blockquote></li></ul><h2 id="系统需求分析和可行性分析"><a href="#系统需求分析和可行性分析" class="headerlink" title="系统需求分析和可行性分析"></a>系统需求分析和可行性分析</h2><blockquote><p>系统需求分析和可行性分析的目的：明确系统是否值得做，避免投资损失。</p></blockquote><ul><li>需求规格说明书：软件验收的依据（<strong>不包括可行性研究</strong>）；软件要做什么的共同理解；软件设计的依据</li></ul><h3 id="可行性分析：经济、技术、法律、实施"><a href="#可行性分析：经济、技术、法律、实施" class="headerlink" title="可行性分析：经济、技术、法律、实施"></a>可行性分析：<strong>经济</strong>、<strong>技术</strong>、<strong>法律</strong>、<strong>实施</strong></h3><h3 id="技术可行性分析：开发风险、资源可用性、技术条件"><a href="#技术可行性分析：开发风险、资源可用性、技术条件" class="headerlink" title="技术可行性分析：开发风险、资源可用性、技术条件"></a>技术可行性分析：<strong>开发风险</strong>、<strong>资源可用性</strong>、<strong>技术条件</strong></h3><h2 id="软件需求分析"><a href="#软件需求分析" class="headerlink" title="软件需求分析"></a>软件需求分析</h2><h3 id="需求分析的操作性原则"><a href="#需求分析的操作性原则" class="headerlink" title="需求分析的操作性原则"></a>需求分析的操作性原则</h3><ul><li>问题的信息域必须被表示和理解，即<strong>数据模型</strong>(ER图)</li><li>软件将完成的工程必须被定义，即<strong>功能模型</strong>(数据流图)</li><li>软件的行为必须被表示，即<strong>行为模型</strong>(状态迁移图)</li></ul><h2 id="结构化需求分析"><a href="#结构化需求分析" class="headerlink" title="结构化需求分析"></a>结构化需求分析</h2><blockquote><p>数据建模：实体关系图（ER图）把用户的数据要求表达出来所建立的概念性的模型</p></blockquote><ul><li>第一范式：每个属性值都是不可在分的最小数据单位（详细至极）</li><li>第二范式：非主属性<strong>完全依赖</strong>于关键字（非主属性开始拆分出去）</li><li>第三范式：非主属性相互独立，消除函数依赖（关系通过外键连接，形成多个关系集合）</li></ul><h2 id="软件设计"><a href="#软件设计" class="headerlink" title="软件设计"></a>软件设计</h2><blockquote><p>总体设计包括：<strong>处理方式</strong>设计；<strong>数据结构</strong>设计；<strong>可靠性</strong>设计：</p></blockquote><h3 id="模块化："><a href="#模块化：" class="headerlink" title="模块化："></a>模块化：</h3><ul><li>模块的三个基本属性：<strong>功能</strong>、<strong>逻辑</strong>、<strong>状态</strong></li><li>度量准则：模块间的耦合和模块间的内聚<ul><li>内聚:模块功能强度的度量：最低为<strong>巧合内聚</strong>，最高为<strong>功能内聚</strong></li><li>耦合：模块之间的相对独立性<ul><li>最好使用数据耦合</li><li>完全不用内容耦合</li><li>少用控制耦合</li></ul></li></ul></li></ul><h2 id="结构化设计方法"><a href="#结构化设计方法" class="headerlink" title="结构化设计方法"></a>结构化设计方法</h2><ul><li>扇入：是指直接调用该模块的上级模块的个数。扇入大表示模块的<strong>复用程度高</strong>。</li><li>扇出: 是指该模块直接调用的下级模块的个数。扇出大表示模块的<strong>复杂度高</strong>。</li></ul><blockquote><p>用例图–功能需求模型– 用例模型–领域模型–识别系统–系统操作契约</p></blockquote><h2 id="面向对象基本思想：一切都看成是对象"><a href="#面向对象基本思想：一切都看成是对象" class="headerlink" title="面向对象基本思想：一切都看成是对象"></a>面向对象基本思想：一切都看成是对象</h2><blockquote><p>面向对象 = 对象 + 类 + 继承 + 通信</p></blockquote><ul><li>对象：类的实例</li><li>类：</li><li>关联和链</li><li>继承/泛华</li><li>聚合</li></ul><h3 id="几种经典的面向对象的分析和设计方法"><a href="#几种经典的面向对象的分析和设计方法" class="headerlink" title="几种经典的面向对象的分析和设计方法"></a>几种经典的面向对象的分析和设计方法</h3><ul><li>OOA/OOD（面向对象分析、面向对象设计）：概念清晰，简单易学</li><li>Booch方法：四个主图（实体）和两个辅图（状态）</li><li>对象建模技术（OMT）</li><li>面向对象软件工程方法（OOSE）</li></ul><h3 id="统一建模语言UML（类似于状态图）"><a href="#统一建模语言UML（类似于状态图）" class="headerlink" title="统一建模语言UML（类似于状态图）"></a>统一建模语言UML（类似于状态图）</h3><ul><li>静态图：<ul><li>用例图</li><li>类图</li><li>对象图</li><li>构件图</li><li>部署图</li></ul></li><li>动态图：<ul><li>顺序图</li><li>协作图</li><li>状态图</li><li>活动图</li></ul></li></ul><h2 id="面向对象分析"><a href="#面向对象分析" class="headerlink" title="面向对象分析"></a>面向对象分析</h2><h3 id="综述"><a href="#综述" class="headerlink" title="综述"></a>综述</h3><blockquote><p>用例图-&gt;功能需求模型-&gt;用例模型-&gt;领域模型-&gt;识别系统操作-&gt;建立系统操作契约 </p></blockquote><ol><li>用例建模</li><li>创建领域类型</li><li>绘制系统顺序图</li><li>创建系统操作契约</li></ol><h2 id="面向对象设计"><a href="#面向对象设计" class="headerlink" title="面向对象设计"></a>面向对象设计</h2><h3 id="模型的层次化"><a href="#模型的层次化" class="headerlink" title="模型的层次化"></a>模型的层次化</h3><h3 id="面向对象设计原则"><a href="#面向对象设计原则" class="headerlink" title="面向对象设计原则"></a>面向对象设计原则</h3><ol><li>单一职责原则(SRP)：就一个类而言，应该仅有一个引起它变化的原因</li><li>开闭原则：软件实体应该是可以扩展但是不可以修改的。</li><li>里氏替换原则：子类可以替换父类并出现在父类能够出现的任何地方。</li><li>依赖倒置原则：高层模块不应该依赖于底层模块，二者都应该依赖于抽象；抽象不应该依赖于细节，细节应该依赖于抽象。</li><li>接口隔离原则:采用多个接口好于采用一个接口来涵盖多个业务方法</li><li>组合/聚合复用原则：在一个新对象里面使用一些已有对象，使之成为新对象的一部分。（达到复用目的）</li><li>迪米特法则（最少知识法则）：一个对象应当尽可能少的了解其他对象。</li></ol><h3 id="设计用例实现方案"><a href="#设计用例实现方案" class="headerlink" title="设计用例实现方案"></a>设计用例实现方案</h3><h2 id="软件实现"><a href="#软件实现" class="headerlink" title="软件实现"></a>软件实现</h2><ul><li>程序设计语言与集成开发环境</li><li>程序设计方法<ul><li>结构化程序设计方法：自顶向下，逐步求精<ul><li>三种基本控制结构：<strong>顺序、选择、重复</strong></li></ul></li><li>面向对象程序设计方法</li></ul></li><li>程序设计风格</li><li>程序效率<blockquote><p>指程序执行速度和占用的内存存储空间</p></blockquote></li></ul><h2 id="软件测试"><a href="#软件测试" class="headerlink" title="软件测试"></a>软件测试</h2><ul><li>软件测试基础：<strong>发现错误而非证明软件正确</strong></li><li>软件的正确性：软件产品达到预期的功能</li><li>软件测试<strong>不包括对代码进行调试</strong><h3 id="软件测试方法与技术"><a href="#软件测试方法与技术" class="headerlink" title="软件测试方法与技术"></a>软件测试方法与技术</h3></li><li>静态测试</li><li>动态测试<ul><li>黑盒测试：单纯从外部<ul><li>等价类划分</li><li>边界值分析</li><li>错误推测法</li><li>因果图</li></ul></li><li>白盒测试：证明内部操作和内部工作流程<ul><li>基本路径测试：<strong>最强</strong></li><li>语句覆盖：<strong>最弱</strong></li><li>判断覆盖</li><li>条件覆盖</li><li>判断-条件覆盖</li><li>条件组合覆盖</li></ul></li></ul></li></ul><h3 id="软件测试过程"><a href="#软件测试过程" class="headerlink" title="软件测试过程"></a>软件测试过程</h3><ul><li>单元测试：白盒为主，黑盒测试为辅</li><li>集成测试：测试所有模块组成的系统</li><li>确认测试：验证软件的有效性</li><li><p>系统测试：不同实际运行环境下测试</p><ul><li>恢复测试</li><li>压力测试</li><li>性能测试</li><li>安全测试</li></ul></li><li><p>何时停止测试：一定测试时间内出故障的次数。</p></li></ul><h3 id="非重点"><a href="#非重点" class="headerlink" title="非重点"></a>非重点</h3><h4 id="面向对象的测试方法"><a href="#面向对象的测试方法" class="headerlink" title="面向对象的测试方法"></a>面向对象的测试方法</h4><h4 id="程序的静态分析方法"><a href="#程序的静态分析方法" class="headerlink" title="程序的静态分析方法"></a>程序的静态分析方法</h4><h4 id="软件调试方法"><a href="#软件调试方法" class="headerlink" title="软件调试方法"></a>软件调试方法</h4><h4 id="软件测试工具"><a href="#软件测试工具" class="headerlink" title="软件测试工具"></a>软件测试工具</h4><h4 id="软件的可靠性"><a href="#软件的可靠性" class="headerlink" title="软件的可靠性"></a>软件的可靠性</h4><hr><h1 id="第二门：编译原理"><a href="#第二门：编译原理" class="headerlink" title="第二门：编译原理"></a>第二门：编译原理</h1><h2 id="编译概述"><a href="#编译概述" class="headerlink" title="编译概述"></a>编译概述</h2><ol><li>编译、解释和翻译的概念</li></ol><ul><li>编译：<strong>把源程序转换成等价的目标程序的过程</strong>(高-&gt;低)</li><li>解释：<strong>解释执行源程序，不生成目标程序</strong>（python）</li><li>翻译：<strong>将用某种语言编写的程序转换成另一种语言形式的程序的程序</strong>（高-&gt;高、低-&gt;低）</li></ul><ol start="2"><li>编译的阶段、任务、典型结构<ol><li>分析阶段:<ul><li>词法分析：<strong>从左到右一个字符一个字符地读入源程序</strong></li><li>语法分析：<strong>将单词序列组合成各类语法短语</strong></li><li>语义分析:<strong>对结构上正确的源程序进行上下文有关性质的审查</strong></li></ul></li><li>综合阶段：<strong>得到与源程序等价的目标程序</strong><ul><li>中间代码生成：一种易于产生、翻译的抽象机器程序（三地址码等）</li><li>代码优化</li><li>目标代码生成：把中间代码变换成依赖具体机器的目标代码</li></ul></li><li>符号表的管理</li><li>错误诊断和处理</li></ol></li><li>编译程序的伙伴工具&amp;遍<ul><li>预处理器：第一遍找出所有标识符。</li><li>汇编程序：第二遍将操作码翻译为机器代码</li><li>连接装配程序</li></ul></li></ol><h2 id="词法分析"><a href="#词法分析" class="headerlink" title="词法分析"></a>词法分析</h2><h3 id="词法分析器的作用"><a href="#词法分析器的作用" class="headerlink" title="词法分析器的作用"></a>词法分析器的作用</h3><blockquote><p>词法分析期的作用：扫描源程序的字符流识别出单词符号</p></blockquote><h3 id="记号、模式"><a href="#记号、模式" class="headerlink" title="记号、模式"></a>记号、模式</h3><blockquote><p>记号：某一类单词符号的编码。（标识符为id,数字为num）<br>模式：某一类单词符号的构词规则。</p></blockquote><h3 id="词法分析器的状态转换图"><a href="#词法分析器的状态转换图" class="headerlink" title="词法分析器的状态转换图"></a>词法分析器的状态转换图</h3><h2 id="语法分析"><a href="#语法分析" class="headerlink" title="语法分析"></a>语法分析</h2><h3 id="语法分析程序-输入记号序列输出语法分析树"><a href="#语法分析程序-输入记号序列输出语法分析树" class="headerlink" title="语法分析程序:输入记号序列输出语法分析树"></a>语法分析程序:输入记号序列输出语法分析树</h3><h3 id="chomsky文法："><a href="#chomsky文法：" class="headerlink" title="chomsky文法："></a>chomsky文法：</h3><ul><li>0型文法：无限制文法（图灵机识别）</li><li>1型文法：上下文有关文法（线性界限自动机识别）</li><li>2型文法：上下文无关文法（下推自动机接受）</li><li>3型文法：正规文法（有限状态自动机）</li></ul><h3 id="推导与归约"><a href="#推导与归约" class="headerlink" title="推导与归约"></a>推导与归约</h3><p>最右推导为规范推导，最左规约为规范规约</p><h3 id="A-自顶向下分析方法-从树根到叶子来建立分析树"><a href="#A-自顶向下分析方法-从树根到叶子来建立分析树" class="headerlink" title="A.自顶向下分析方法:从树根到叶子来建立分析树"></a>A.自顶向下分析方法:从树根到叶子来建立分析树</h3><ol><li><p>要进行确定分析，则文法必须无左递归和回溯</p><ul><li>消除左递归：避免死循环</li><li>消除回溯：提取公共左因子，判断是否为LL(1)文法；提高分析效率</li></ul></li><li><p>LL(k)文法：</p><ul><li>最左推导</li><li>从左到右扫描源程序</li><li>每次向前查看k个字符。</li></ul></li><li><p>预测分析法：预测分析表的构造，反序入栈；</p></li></ol><h3 id="B-自底向上分析方法：从树叶到树根来分析树"><a href="#B-自底向上分析方法：从树叶到树根来分析树" class="headerlink" title="B.自底向上分析方法：从树叶到树根来分析树"></a>B.自底向上分析方法：从树叶到树根来分析树</h3><ol><li>可规约串在<strong>规范归约分析法</strong>中是句柄，在<strong>算符优先分析法</strong>中是最左素短语；</li><li><p>算符优先分析法</p><ul><li>First集和Follow集</li><li>短语：不同层的语法树中叶子节点组成的符号串</li><li>直接（素）短语：不同层的语法树中节点不在包含其他节点有子树</li><li>句柄：最左直接短语</li><li>句型：叶子节点大集合</li></ul></li><li><p>LR（k）分析技术:</p><ul><li>上下文无关文法：G(V,sigma,R,S)[非终结符，终结符，开始变量，规则/产生式]</li><li>L表示自左至右扫描输入符号串</li><li>R表示最右推导的逆过程</li><li>k表示输入符号的个数</li></ul></li><li>LR(0)分析<ul><li>指明对活前缀的识别状态，分为归约、移进、待约和接受项目</li><li>没有移进规约冲突和归约归约冲突则是LR（0）文法</li></ul></li><li>SLR（1）分析法<ul><li>在LR(0)分析法的基础上向前查看一个输入符号，避免无脑归约</li></ul></li><li>LR(1)分析法<br> 归约仅在输入符号是搜索符时进行</li></ol><h2 id="语法制导翻译技术"><a href="#语法制导翻译技术" class="headerlink" title="语法制导翻译技术"></a>语法制导翻译技术</h2><blockquote><p>输入符号串-&gt;分析树-&gt;依赖图-&gt;语义规则的计算顺序-&gt;计算结果</p></blockquote><ol><li>语义分析的任务：静态语义审查，执行真正的翻译（生成中间代码和目标代码）</li><li>常见中间代码：逆波兰式、三元式、四元式</li></ol><h3 id="语法制导定义"><a href="#语法制导定义" class="headerlink" title="语法制导定义"></a>语法制导定义</h3><ul><li>S-属性定义</li><li>L-属性定义（继承属性应满足的<strong>限制条件</strong>）</li></ul><h3 id="翻译方案"><a href="#翻译方案" class="headerlink" title="翻译方案"></a>翻译方案</h3><ul><li>构造S-属性定义的翻译方案（语义动作放在产生式右尾）</li><li>构造L-属性定义的翻译方案（语义动作插入产生式之中）</li></ul><h2 id="语义分析"><a href="#语义分析" class="headerlink" title="语义分析"></a>语义分析</h2><ol><li>语义分析的概念</li></ol><ul><li>编译的一个重要任务、检查语义的合法性</li><li>符号表的建立和管理</li><li>语义检查</li></ul><ol start="2"><li>符号表</li></ol><ul><li>操作：检索、插入、定位、重定位</li></ul><hr><h1 id="第三门：数据库原理"><a href="#第三门：数据库原理" class="headerlink" title="第三门：数据库原理"></a>第三门：数据库原理</h1><h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><h3 id="四个基本概念"><a href="#四个基本概念" class="headerlink" title="四个基本概念"></a>四个基本概念</h3><ul><li>数据：数据库中存储的基本对象</li><li>数据库：<strong>长期存储</strong>、<strong>有组织</strong>、<strong>可共享</strong>的大量数据集合</li><li>数据库管理系统：用户与操作系统之间的数据管理软件</li><li>数据库系统：包含数据库管理系统和数据库。</li></ul><h3 id="数据模型-数据结构-数据操作-完整性约束条件"><a href="#数据模型-数据结构-数据操作-完整性约束条件" class="headerlink" title="数据模型 = 数据结构 + 数据操作 + 完整性约束条件"></a>数据模型 = 数据结构 + 数据操作 + 完整性约束条件</h3><ul><li>概念模型</li><li>逻辑模型和物理模型</li></ul><h3 id="常用数据模型"><a href="#常用数据模型" class="headerlink" title="常用数据模型"></a>常用数据模型</h3><ul><li>格式化模型<ul><li>层次模型（树）</li><li>网状模型（图）</li></ul></li><li>关系模型（表）</li><li>面向对象模型</li><li>对象关系模型</li></ul><h3 id="数据库系统结构"><a href="#数据库系统结构" class="headerlink" title="数据库系统结构"></a>数据库系统结构</h3><ul><li>单用户DBS</li><li>主从式DBS</li><li>C/S结构DBS</li><li>分布式DBS</li></ul><h3 id="数据库系统的三级模式结构：（1-1-n）"><a href="#数据库系统的三级模式结构：（1-1-n）" class="headerlink" title="数据库系统的三级模式结构：（1:1:n）"></a>数据库系统的三级模式结构：（1:1:n）</h3><ul><li>模式：数据库中全体数据的<strong>逻辑</strong>结构和特征的描述(一个数据库只有一个模式)</li><li>外模式：数据库<strong>用户</strong>使用的局部数据的模式（一个数据库只有一个外模式）</li><li>内模式：数据<strong>物理</strong>结构和存储方式的描述</li></ul><h2 id="关系数据库"><a href="#关系数据库" class="headerlink" title="关系数据库"></a>关系数据库</h2><h3 id="关系数据结构及形式化定义"><a href="#关系数据结构及形式化定义" class="headerlink" title="关系数据结构及形式化定义"></a>关系数据结构及形式化定义</h3><ul><li>域：相同数据类型的值的集合</li><li>笛卡尔积：多个域中的交集。</li><li>关系：二维表</li><li>属性：二维表的一列</li><li>码：能唯一标识一个元组的属性组<ul><li>候选码：能唯一标识一个元组的属性组，且不含多余属性</li><li>主码：多个候选码之一</li><li>主属性：主码的属性</li><li>外码：不是表一主码，是表二的主码</li></ul></li></ul><h2 id="关系数据理论"><a href="#关系数据理论" class="headerlink" title="关系数据理论"></a>关系数据理论</h2><h3 id="关系模式的形式化定义"><a href="#关系模式的形式化定义" class="headerlink" title="关系模式的形式化定义"></a>关系模式的形式化定义</h3><blockquote><p>R(U, D, DOM, F) // R:关系名 U:属性名集合 D:属性来自的域 DOM:属性向域的映象集合 F:属性间数据的依赖关系集合</p></blockquote><h3 id="函数依赖"><a href="#函数依赖" class="headerlink" title="函数依赖"></a>函数依赖</h3><ul><li>函数依赖：x可以唯一确定y</li><li>完全函数依赖：x1或者x2不可以唯一确定y,但是（x1,x2）可以完全确定y</li><li>部分函数依赖：x1,x2其中之一可以唯一确定y；</li></ul><h3 id="范式"><a href="#范式" class="headerlink" title="范式"></a>范式</h3><ul><li>1NF:关系模式的所有属性都是不可分的基本数据项</li><li>2NF:每一个非主属性完全函数依赖于码（消去了非主属性对主码的部分依赖）</li><li>3NF:每一个非主属性既不部分依赖于码也不传递依赖于码（消去了非主属性对主码的传递依赖）</li><li>4NF:消除了任何属性对码的传递依赖与部分依赖</li></ul><h3 id="关系操作"><a href="#关系操作" class="headerlink" title="关系操作"></a>关系操作</h3><ul><li>查询：选择、投影、链接、除、并、交、差、笛卡尔积</li><li>更新：插入、删除、修改</li></ul><h3 id="关系代数"><a href="#关系代数" class="headerlink" title="关系代数"></a>关系代数</h3><ul><li>并：直观取并集</li><li>差：直观取前者的补集</li><li>交：直观取交集</li><li>笛卡尔积：两者各元组的并集</li><li>选择：<code>where</code></li><li>投影：从关系中去若干子关系组成新的关系（选多列）</li><li>连接：从两个关系的笛卡尔积中选择部分元组</li><li>除：获得满足关系组的属性组</li></ul><h3 id="关系的完整性"><a href="#关系的完整性" class="headerlink" title="关系的完整性"></a>关系的完整性</h3><ul><li>实体完整性：属性A是基本关系R的主属性，则属性A不能取空值</li><li>参照完整性：<ul><li>关系间的引用</li><li>外码：设F是基本关系R的一个或一组属性，但不是关系R的码。如果F与基本关系S的主码Ks相对应，则称F是基本关系R的外码</li><li>参照完整性规则</li></ul></li><li>用户定义的完整性：<code>NOT NULL</code>/<code>UNIQUE</code>/<code>CHECK</code></li></ul><h2 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h2><h3 id="数据查询"><a href="#数据查询" class="headerlink" title="数据查询"></a>数据查询</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查询指定列</span></span><br><span class="line">SELECT Sno,Sname</span><br><span class="line">FROM Student</span><br><span class="line">WHERE Sdept = <span class="string">'CS'</span></span><br><span class="line">ORDER BY Grade DESC;</span><br><span class="line"><span class="comment">#查询全部列</span></span><br><span class="line">SELECT *</span><br><span class="line">FROM Student</span><br><span class="line">WHERE Sage &lt; <span class="number">20</span></span><br><span class="line">ORDER BY Sdept ASC,Sage DESC;</span><br><span class="line"><span class="comment">#消除取值重复的行</span></span><br><span class="line">SELECT DISTINCT Sno</span><br><span class="line">FROM SC</span><br><span class="line">WHERE Grade &lt; <span class="number">60</span>;</span><br></pre></td></tr></table></figure><p>　聚合函数：</p><ul><li>where:过滤表中数据的条件；</li><li>group by:如何将上面过滤出的数据分组；- having:对上面已经分组的数据进行过滤的条件 ；</li><li>order by :按照什么样的顺序来查看返回的数据 </li></ul><h2 id="数据库保护"><a href="#数据库保护" class="headerlink" title="数据库保护"></a>数据库保护</h2><h3 id="授权与回收"><a href="#授权与回收" class="headerlink" title="授权与回收"></a>授权与回收</h3><ul><li>授权</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把查询Student表权限/全部权限给用户U1/所有用户</span></span><br><span class="line">GRANT SELECT/ALL PRIBILIGES</span><br><span class="line">ON TABLE Student</span><br><span class="line">TO U1/PUBLIC;</span><br></pre></td></tr></table></figure><ul><li>回收</li></ul><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#把用户U4修改学生学号的权限收回</span></span><br><span class="line">REVOKE UPDATE(Sno)</span><br><span class="line">ON TABLE Student</span><br><span class="line">FROM U4;</span><br></pre></td></tr></table></figure><ul><li>触发器：事件驱动</li></ul><h2 id="数据库恢复技术"><a href="#数据库恢复技术" class="headerlink" title="数据库恢复技术"></a>数据库恢复技术</h2><ul><li><strong>事务</strong><ul><li>原子性：事务中的所有操作要么全部执行要么不执行</li><li>一致性：执行事务前后数据库是一致的</li><li>隔离性：每个事务都感觉不到系统中有其他事务在执行</li><li>持续性：事务成功执行后对数据库的修改是永久的</li></ul></li><li>数据的锁定：<ul><li>导致数据不一致性包括：<strong>并发操作破坏了事务的隔离性</strong><ul><li>丢失修改</li><li>不可重复读</li><li>读“脏”数据</li></ul></li><li>封锁<ul><li>排它锁（X锁）：其他事务不能读取和修改A</li><li>共享锁（S锁）：其他事务只能读取A不能修改A</li></ul></li></ul></li></ul><hr><h1 id="第四门：计算机系统结构"><a href="#第四门：计算机系统结构" class="headerlink" title="第四门：计算机系统结构"></a>第四门：计算机系统结构</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><ul><li>虚拟机：抽象的计算机，由软件实现，都具有指令集并使用不同的存储区域。</li><li>透明性：本来存在的事物或属性，从某种角度看似乎不存在</li><li>系统结构发展的影响因素：<ul><li>程序访存的局部性：</li><li>数据访问的局部性：时间局部性&amp;空间局部性</li></ul></li><li>系统结构设计中最常用的方法：大概率事件优先原理</li><li>可移植性：<ul><li>采用系列机</li><li>模拟与仿真</li><li>统一高级语言</li></ul></li><li><p>提高并行性的技术途径：</p><ul><li>时间重叠</li><li>资源重复</li><li>资源共享</li></ul></li><li><p>流水线的性能指标</p><ul><li>吞吐率： $$P = \frac{n}{T_k}=\frac{n}{(k+n-1)\Delta T}$$</li><li>加速比： $$ S = \frac{T_0}{T_k} = \frac{k*n}{k+n-1}$$</li><li>效率：$$E = \frac{任务有效面积}{对应总面积}= \frac{n}{k+n-1} $$</li></ul></li></ul><h2 id="流水线技术"><a href="#流水线技术" class="headerlink" title="流水线技术"></a>流水线技术</h2><ul><li>静态流水线（同一时间，同一种功能）&amp;动态流水线（同一时间，不同的方式）</li><li>线性流水线（串行连接，没有反馈）&amp;非线性流水线（多加了反馈回路）</li></ul><h2 id="向量处理机器-互联网络-阵列机"><a href="#向量处理机器-互联网络-阵列机" class="headerlink" title="向量处理机器+互联网络+阵列机"></a>向量处理机器+互联网络+阵列机</h2><ol><li>向量处理机：在流水线处理机中，设置向量数据表示和相应的向量指令，成为向量处理机<ul><li>向量处理机的结构：<ul><li>存储器-存储器型：向量长度不受限</li><li>寄存器-寄存器型：</li></ul></li></ul></li><li>指令级别并行：<ul><li>Tomasulo算法：</li></ul></li></ol><h2 id="多处理机-后面的看不完了，请直接去刷13套题"><a href="#多处理机-后面的看不完了，请直接去刷13套题" class="headerlink" title="多处理机:(后面的看不完了，请直接去刷13套题)"></a>多处理机:(后面的看不完了，请直接去刷13套题)</h2>]]></content>
      
      <categories>
          
          <category> BUPT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> reexamine </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Tornado学习小结</title>
      <link href="/2018/02/14/tornado-usage/"/>
      <url>/2018/02/14/tornado-usage/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>它是非阻塞式服务器，而且性能十分优越，Tornado 每秒可以处理数以千计的连接，因此 Tornado 是实时 Web 服务的一个理想框架，专门解决C10K问题。</p><h2 id="模块"><a href="#模块" class="headerlink" title="模块"></a>模块</h2><h3 id="主要模块"><a href="#主要模块" class="headerlink" title="主要模块"></a>主要模块</h3><ul><li>tornado.web：包含了大多数重要的功能</li><li>tornado.escape: XHTML、JSON、URL的编码解码方法</li><li>database: 对Mysql的简单封装</li><li>template:web模板系统</li><li>httpclient:非阻塞式 HTTP 客户端，它被设计用来和 web 及 httpserver 协同工作</li><li>auth：第三方认证的实现（包括 Google OpenID/OAuth、Facebook Platform、Yahoo BBAuth、FriendFeed OpenID/OAuth、Twitter OAuth）</li><li>local:针对本地化和翻译的支持</li><li>options:命令行和配置文件解析工具，针对服务器环境做了优化</li></ul><h3 id="底层模块："><a href="#底层模块：" class="headerlink" title="底层模块："></a>底层模块：</h3><ul><li>httpserver:服务于 web 模块的一个非常简单的 HTTP 服务器的实现</li><li>iostream:对非阻塞式的 socket的简单封装，以方便常用读写操作</li><li>ioloop：核心的I/O循环</li></ul><h2 id="代码中学习Tornado的基本功能"><a href="#代码中学习Tornado的基本功能" class="headerlink" title="代码中学习Tornado的基本功能"></a>代码中学习Tornado的基本功能</h2><h3 id="helloTornado展示Tornado最频繁使用的功能"><a href="#helloTornado展示Tornado最频繁使用的功能" class="headerlink" title="helloTornado展示Tornado最频繁使用的功能"></a>helloTornado展示Tornado最频繁使用的功能</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tornado.httpserver</span><br><span class="line"><span class="keyword">import</span> tornado.ioloop</span><br><span class="line"><span class="keyword">import</span> tornado.options</span><br><span class="line"><span class="keyword">import</span> tornado.web</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tornado.options <span class="keyword">import</span> define, options</span><br><span class="line">define(<span class="string">"port"</span>, default=<span class="number">8000</span>, help=<span class="string">"run on the given port"</span>, type=int)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IndexHandler</span><span class="params">(tornado.web.RequestHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self)</span>:</span></span><br><span class="line">        greeting = self.get_argument(<span class="string">'greeting'</span>, <span class="string">'Hello'</span>)</span><br><span class="line">        self.write(greeting + <span class="string">', friendly user!'</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    tornado.options.parse_command_line()</span><br><span class="line">    app = tornado.web.Application(handlers=[(<span class="string">r"/"</span>, IndexHandler)])</span><br><span class="line">    http_server = tornado.httpserver.HTTPServer(app)</span><br><span class="line">    http_server.listen(options.port)</span><br><span class="line">    tornado.ioloop.IOLoop.instance().start()</span><br><span class="line"> </span><br><span class="line">$ curl http://localhost:<span class="number">8000</span>/</span><br><span class="line">Hello, friendly user!</span><br><span class="line">$ curl http://localhost:8000/?greeting=Salutations</span><br><span class="line">Salutations, friendly user!</span><br></pre></td></tr></table></figure><h3 id="除了get方法，来尝试一下post方法！"><a href="#除了get方法，来尝试一下post方法！" class="headerlink" title="除了get方法，来尝试一下post方法！"></a>除了get方法，来尝试一下post方法！</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> textwrap</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tornado.httpserver</span><br><span class="line"><span class="keyword">import</span> tornado.ioloop</span><br><span class="line"><span class="keyword">import</span> tornado.options</span><br><span class="line"><span class="keyword">import</span> tornado.web</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tornado.options <span class="keyword">import</span> define, options</span><br><span class="line">define(<span class="string">"port"</span>, default=<span class="number">8000</span>, help=<span class="string">"run on the given port"</span>, type=int)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReverseHandler</span><span class="params">(tornado.web.RequestHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, input)</span>:</span></span><br><span class="line">        self.write(input[::<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WrapHandler</span><span class="params">(tornado.web.RequestHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(self)</span>:</span></span><br><span class="line">        text = self.get_argument(<span class="string">'text'</span>)</span><br><span class="line">        width = self.get_argument(<span class="string">'width'</span>, <span class="number">40</span>)</span><br><span class="line">        self.write(textwrap.fill(text, int(width)))</span><br><span class="line">        </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    tornado.options.parse_command_line()</span><br><span class="line">    app = tornado.web.Application(</span><br><span class="line">        handlers=[</span><br><span class="line">            (<span class="string">r"/reverse/(\w+)"</span>, ReverseHandler),</span><br><span class="line">            (<span class="string">r"/wrap"</span>, WrapHandler)</span><br><span class="line">        ]</span><br><span class="line">    )</span><br><span class="line">    http_server = tornado.httpserver.HTTPServer(app)</span><br><span class="line">    http_server.listen(options.port)</span><br><span class="line">    tornado.ioloop.IOLoop.instance().start()</span><br><span class="line"></span><br><span class="line">$ http://localhost:<span class="number">8000</span>/reverse/slipup</span><br><span class="line">pupils</span><br><span class="line">$ http://localhost:<span class="number">8000</span>/wrap -d text=Lorem+ipsum+dolor+sit+amet,+consectetuer+adipiscing+elit. </span><br><span class="line">Lorem ipsum dolor sit amet, consectetuer adipiscing elit.</span><br></pre></td></tr></table></figure><h4 id="修改用户名代码示例："><a href="#修改用户名代码示例：" class="headerlink" title="修改用户名代码示例："></a>修改用户名代码示例：</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># matched with (r"/widget/(\d+)", WidgetHandler)</span></span><br><span class="line"><span class="comment"># widget：小机械，小部件</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WidgetHandler</span><span class="params">(tornado.web.RequestHandler)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(self, widget_id)</span>:</span></span><br><span class="line">        widget = retrieve_from_db(widget_id)</span><br><span class="line">        self.write(widget.serialize())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(self, widget_id)</span>:</span></span><br><span class="line">        widget = retrieve_from_db(widget_id)</span><br><span class="line">        widget[<span class="string">'foo'</span>] = self.get_argument(<span class="string">'foo'</span>)</span><br><span class="line">        save_to_db(widget)</span><br></pre></td></tr></table></figure><h4 id="HTTP的状态码"><a href="#HTTP的状态码" class="headerlink" title="HTTP的状态码"></a>HTTP的状态码</h4><ul><li>404 NOT Found:Tornado会在HTTP请求的路径无法匹配任何RequestHandler类相对应的模式时返回404（Not Found）响应码。</li><li>400 Bad Request:如果你调用了一个没有默认值的get_argument函数，并且没有发现给定名称的参数，Tornado将自动返回一个400（Bad Request）响应码。</li><li>405 Method Not Allowed:如果传入的请求使用了RequestHandler中没有定义的HTTP方法（比如，一个POST请求，但是处理函数中只有定义了get方法），Tornado将返回一个405（Methos Not Allowed）响应码。</li><li>500 Internal Server Error:当程序遇到任何不能让其退出的错误时，Tornado将返回500（Internal Server Error）响应码。你代码中任何没有捕获的异常也会导致500响应码。</li><li>200 OK:如果响应成功，并且没有其他返回码被设置，Tornado将默认返回一个200（OK）响应码。</li></ul>]]></content>
      
      <categories>
          
          <category> App </category>
          
      </categories>
      
      
        <tags>
            
            <tag> tornado </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>北邮机试打印资料</title>
      <link href="/2018/02/13/BUPT-OJ-experience/"/>
      <url>/2018/02/13/BUPT-OJ-experience/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>北邮复试的机试环节是可以带资料的。我整理了当时机试我准备的资料给需要的同学做参考。以下代码均可在机试环境中运行。</p></blockquote><h2 id="机试导入头文件"><a href="#机试导入头文件" class="headerlink" title="机试导入头文件"></a>机试导入头文件</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;iterator&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line">```    </span><br><span class="line">## 结构体</span><br><span class="line">``` c++</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">student</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">float</span> score;</span><br><span class="line">    <span class="keyword">int</span> id;</span><br><span class="line">&#125;a[<span class="number">101</span>];</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">comp</span><span class="params">(<span class="keyword">const</span> student &amp;a,<span class="keyword">const</span> student &amp;b)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a.score&gt;b.score;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n,k;<span class="comment">//n个人，求第k名的成绩</span></span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;k;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;++i)      </span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;a[i].id&gt;&gt;a[i].score;</span><br><span class="line">    sort(a+<span class="number">1</span>,a+n+<span class="number">1</span>,comp);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;a[k].id&lt;&lt;<span class="string">' '</span>&lt;&lt;a[k].score&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="scanf-amp-cin"><a href="#scanf-amp-cin" class="headerlink" title="scanf &amp; cin"></a>scanf &amp; cin</h2><ul><li><p>浮点数判定相等</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">fabs</span>(a-b)&lt;<span class="number">0.000001</span></span><br></pre></td></tr></table></figure></li><li><p>带逗号分隔的输入形式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">scanf</span>(<span class="string">"%d, %d"</span>,&amp;a, &amp;b);</span><br></pre></td></tr></table></figure></li><li><p><code>getchar()；</code>用来吃进空格，有奇用！ </p></li></ul><h2 id="补充：二维数组传参：尽量少用指针！"><a href="#补充：二维数组传参：尽量少用指针！" class="headerlink" title="补充：二维数组传参：尽量少用指针！"></a>补充：二维数组传参：尽量少用指针！</h2><ul><li><p>合法形式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">void Foo1(int array[30][30])；</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Foo2</span><span class="params">(<span class="keyword">int</span> <span class="built_in">array</span>[][<span class="number">30</span>])</span></span>;</span><br></pre></td></tr></table></figure></li><li><p>不能省略高维的大小！不合法形式：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Foo3</span><span class="params">(<span class="keyword">int</span> <span class="built_in">array</span>[][])</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Foo4</span><span class="params">(<span class="keyword">int</span> **<span class="built_in">array</span>)</span></span>;<span class="comment">//这种方式也是错误的</span></span><br></pre></td></tr></table></figure></li></ul><hr><h2 id="树与图"><a href="#树与图" class="headerlink" title="树与图"></a>树与图</h2><h3 id="二叉链表建树套路"><a href="#二叉链表建树套路" class="headerlink" title="二叉链表建树套路"></a>二叉链表建树套路</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//根据二叉排序树</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">    <span class="keyword">char</span> letter;</span><br><span class="line">    node *lchild,*rchild;<span class="comment">//</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="function">node *<span class="title">create</span><span class="params">(<span class="keyword">char</span> c)</span></span>&#123;</span><br><span class="line">    node *p = (node *)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(node));</span><br><span class="line">    (*p).letter = c;</span><br><span class="line">    (*p).lchild = (*p).rchild = <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">node *<span class="title">insert</span><span class="params">(node *t,<span class="keyword">char</span> x)</span></span>&#123;<span class="comment">//递归建树</span></span><br><span class="line">    <span class="keyword">if</span>(t==<span class="literal">NULL</span>)&#123;<span class="comment">//若树为空</span></span><br><span class="line">        t = create(x);</span><br><span class="line">        <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(x-<span class="string">'0'</span> &lt; t-&gt;letter-<span class="string">'0'</span>)&#123;<span class="comment">//插入左子树</span></span><br><span class="line">        t-&gt;lchild = insert(t-&gt;lchild, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(x-<span class="string">'0'</span> &gt; t-&gt;letter-<span class="string">'0'</span>)&#123;</span><br><span class="line">        t-&gt;rchild = insert(t-&gt;rchild, x);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//根据中序后序建树</span></span><br><span class="line"><span class="function">node *<span class="title">rebuild</span><span class="params">(<span class="keyword">char</span>* post,<span class="keyword">char</span>* in,<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(n==<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">char</span> ch = post[n<span class="number">-1</span>];</span><br><span class="line">    node *p = create(ch);</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i &lt; n &amp;&amp; in[i] != ch) i++;</span><br><span class="line">    <span class="keyword">int</span> l_len = i;</span><br><span class="line">    <span class="keyword">int</span> r_len = n-i<span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span>(l_len&gt;<span class="number">0</span>) (*p).lchild = rebuild(post,in,l_len);</span><br><span class="line">    <span class="keyword">if</span>(r_len&gt;<span class="number">0</span>) (*p).rchild = rebuild(post+l_len,in+l_len+<span class="number">1</span>,r_len);</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//前序、后序遍历</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">preorder</span><span class="params">(node *t)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ptr) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t%d"</span>, ptr-&gt;data);</span><br><span class="line">        preorder(ptr-&gt;left_child);</span><br><span class="line">        preorder(ptr-&gt;right_child);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//后序遍历</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">postorder</span><span class="params">(node *t)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ptr) &#123;</span><br><span class="line">        postorder(ptr-&gt;left_child);</span><br><span class="line">        postorder(ptr-&gt;right_child);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"\t%d"</span>, ptr-&gt;data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">char</span> tree[<span class="number">30</span>];</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%s"</span>,tree)!=EOF)&#123;</span><br><span class="line">        node *t = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; <span class="built_in">strlen</span>(tree);i++)&#123;</span><br><span class="line">            t = insert(t,in[i]);</span><br><span class="line">        &#125;</span><br><span class="line">        preorder(t);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="图套路之建图"><a href="#图套路之建图" class="headerlink" title="图套路之建图"></a>图套路之建图</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Edge</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> nextNode;<span class="comment">//下一个节点编号</span></span><br><span class="line">    <span class="keyword">int</span> cost;<span class="comment">//该边得权重</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;Edge&gt; edge[N];<span class="comment">//vector模拟单链表</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; N;i++)&#123;</span><br><span class="line">    edge[i].clear();<span class="comment">//清空单链表</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//向单链表添加信息</span></span><br><span class="line">Edge tmp;</span><br><span class="line">tmp.nextNode = <span class="number">3</span>;</span><br><span class="line">tmp.cost = <span class="number">38</span>;</span><br><span class="line">edge[<span class="number">1</span>].push_back(tmp)</span><br><span class="line"><span class="comment">//查询某个节点的所有邻接信息，对vector进行遍历</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; edge[<span class="number">2</span>].size();i++)&#123;<span class="comment">//对edge[2]进行遍历</span></span><br><span class="line">    <span class="keyword">int</span> nextNode = edge[<span class="number">2</span>][i].nextNode;</span><br><span class="line">    <span class="keyword">int</span> cost = edge[<span class="number">2</span>][i].cost;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//删除边</span></span><br><span class="line">edge[<span class="number">1</span>].erase(edge[<span class="number">1</span>].begin()+i,edge.begin()+i+<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h3 id="floyd算法"><a href="#floyd算法" class="headerlink" title="floyd算法"></a>floyd算法</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">1</span>;k &lt;=  N;k++)&#123;<span class="comment">//每次我们选取的中间节点,Floyd算法的核心。</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= N;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j &lt;= N;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(a[i][k] == N || a[k][j] == N) <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">if</span>(a[i][k]+a[k][j] &lt; a[i][j])   a[i][j] = a[i][k] + a[k][j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="dijstra算法"><a href="#dijstra算法" class="headerlink" title="dijstra算法"></a>dijstra算法</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">E</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> next;<span class="comment">// 临街的节点</span></span><br><span class="line">    <span class="keyword">int</span> c;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="built_in">vector</span>&lt;E&gt; edge[<span class="number">1005</span>];<span class="comment">//邻接链表</span></span><br><span class="line"><span class="keyword">int</span> Dis[<span class="number">1005</span>];</span><br><span class="line"><span class="keyword">bool</span> mark[<span class="number">1005</span>];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n,m,a,b,c;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m)&#123;<span class="comment">//n个节点，m条边</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">            edge[i].clear();<span class="comment">//邻接链表的初始化</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">            Dis[i] = <span class="number">-1</span>;</span><br><span class="line">            mark[i] = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(m--)&#123;</span><br><span class="line">            <span class="built_in">cin</span>&gt;&gt;a&gt;&gt;b&gt;&gt;c;<span class="comment">//a到b有一条权值c的路径</span></span><br><span class="line">            E tmp;</span><br><span class="line">            tmp.c = c;</span><br><span class="line">            tmp.next = b;</span><br><span class="line">            edge[a].push_back(tmp);<span class="comment">//把b加入a的邻接链表, 针对无向图</span></span><br><span class="line">            tmp.next = a;</span><br><span class="line">            edge[b].push_back(tmp);<span class="comment">//把a加入b的邻接链表</span></span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">int</span> newP = <span class="number">1</span>;<span class="comment">//起点</span></span><br><span class="line">        Dis[<span class="number">1</span>] = <span class="number">0</span>;</span><br><span class="line">        mark[<span class="number">1</span>] = <span class="literal">true</span>;<span class="comment">//求节点1到其他节点的最短路径 访问到了mark就要变为true.</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt; n;i++)&#123;<span class="comment">//要循环的次数 n-1次</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt; edge[newP].size();j++)&#123;<span class="comment">//更新距离数组</span></span><br><span class="line">                <span class="keyword">int</span> t = edge[newP][j].next;<span class="comment">//保存邻接节点</span></span><br><span class="line">                <span class="keyword">int</span> cost = edge[newP][j].c;</span><br><span class="line">                <span class="keyword">if</span>(mark[t]==<span class="literal">true</span>) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">if</span>(Dis[t] == <span class="number">-1</span> || Dis[t] &gt; Dis[newP] + cost)&#123;</span><br><span class="line">                    Dis[t] = Dis[newP]+cost;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> min = <span class="number">1000000</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">1</span>;j &lt;= n;j++)&#123;<span class="comment">//找到Dis数组中的最小值</span></span><br><span class="line">                <span class="keyword">if</span>(mark[j]==<span class="literal">true</span>) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">if</span>(Dis[j]==<span class="number">-1</span>) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="keyword">if</span>(Dis[j]&lt;min)&#123;</span><br><span class="line">                    min = Dis[j];</span><br><span class="line">                    newP = j;<span class="comment">//起点的更新 每次选完最小节点后 起点都要进行更新。</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            mark[newP] = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;Dis[i]&lt;&lt;<span class="string">" "</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="拓扑排序"><a href="#拓扑排序" class="headerlink" title="拓扑排序"></a>拓扑排序</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; edge[<span class="number">501</span>];</span><br><span class="line"><span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; Q;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> degree[<span class="number">501</span>];<span class="comment">//存储入度，拓扑排序判断的就是入度</span></span><br><span class="line">    <span class="keyword">int</span> n,m;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m)&#123;<span class="comment">//n是节点个数，m是边的个数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; <span class="number">501</span>;i++)&#123;<span class="comment">//</span></span><br><span class="line">            degree[i] = <span class="number">0</span>;</span><br><span class="line">            edge[i].clear();<span class="comment">//链表初始化</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(Q.empty()==<span class="literal">false</span>)&#123;<span class="comment">//初始化，弹出队列中的元素知道Q为空。</span></span><br><span class="line">            Q.pop();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(m--)&#123;<span class="comment">//输入数据</span></span><br><span class="line">            <span class="keyword">int</span> a,b;</span><br><span class="line">            <span class="built_in">cin</span>&gt;&gt;a&gt;&gt;b;<span class="comment">//输入a-&gt;b的一条边</span></span><br><span class="line">            degree[b]++;<span class="comment">//入度加一</span></span><br><span class="line">            edge[a].push_back(b);<span class="comment">//链表存b</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>;i &lt;= n;i++)&#123;<span class="comment">//拓扑排序，找入度为0的节点。</span></span><br><span class="line">            <span class="keyword">if</span>(degree[i]==<span class="number">0</span>)&#123;</span><br><span class="line">                Q.push(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(Q.empty()==<span class="literal">false</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> now = Q.front();<span class="comment">//访问队头元素</span></span><br><span class="line">            Q.pop();</span><br><span class="line">            <span class="built_in">cout</span>&lt;&lt;now&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> k = <span class="number">0</span>;k &lt; edge[now].size();k++)&#123;</span><br><span class="line">                degree[edge[now][k]]--;<span class="comment">//类似二维数组的访问 因此now节点已经入队，所以入度要减去1</span></span><br><span class="line">                <span class="keyword">if</span>(degree[edge[now][k][==<span class="number">0</span>) Q.push(edge[now][k]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><h3 id="最长公共子序列与最长公共子串"><a href="#最长公共子序列与最长公共子串" class="headerlink" title="最长公共子序列与最长公共子串"></a>最长公共子序列与最长公共子串</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//最长公共子序列：输出最长序列长度</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lcse</span><span class="params">(<span class="built_in">string</span> str1,<span class="built_in">string</span> str2,<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt;&amp; vec)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len1 = str1.size();</span><br><span class="line">    <span class="keyword">int</span> len2 = str2.size();</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; c(len1 + <span class="number">1</span>, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(len2 + <span class="number">1</span>,<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt;= len1;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt;= len2;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i==<span class="number">0</span> || j==<span class="number">0</span>)&#123;</span><br><span class="line">                c[i][j] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(str1[i<span class="number">-1</span>] == str2[j<span class="number">-1</span>])&#123;</span><br><span class="line">                c[i][j] = c[i<span class="number">-1</span>][j<span class="number">-1</span>] + <span class="number">1</span>;</span><br><span class="line">                vec[i][j] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(c[i<span class="number">-1</span>][j] &gt;= c[i][j<span class="number">-1</span>])&#123;</span><br><span class="line">                c[i][j] = c[i<span class="number">-1</span>][j];</span><br><span class="line">                vec[i][j] = <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                c[i][j] = c[i][j<span class="number">-1</span>];</span><br><span class="line">                vec[i][j] = <span class="number">2</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> c[len1][len2];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//最长公共子串：输出最长子串长度</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">lcst</span><span class="params">(<span class="built_in">string</span> str1,<span class="built_in">string</span> str2,<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span> &gt; &gt;&amp; vec)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len1 = str1.size();</span><br><span class="line">    <span class="keyword">int</span> len2 = str2.size();</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; c(len1+<span class="number">1</span>,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(len2+<span class="number">1</span>,<span class="number">0</span>));</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt;= len1;i++)&#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>;j &lt;= len2;j++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(i==<span class="number">0</span> || j==<span class="number">0</span>)&#123;</span><br><span class="line">                c[i][j] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(str1[i<span class="number">-1</span>] == str2[j<span class="number">-1</span>])&#123;</span><br><span class="line">                c[i][j] = c[i<span class="number">-1</span>][j<span class="number">-1</span>] + <span class="number">1</span>;</span><br><span class="line">                vec[i][j] = <span class="number">0</span>;</span><br><span class="line">                result = max(c[i][j],result);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                c[i][j] = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//打印公共子序列/子串</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print_lcs</span><span class="params">(<span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt;&amp; vec,<span class="built_in">string</span> str,<span class="keyword">int</span> i,<span class="keyword">int</span> j)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(i== <span class="number">0</span> || j == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> ;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(vec[i][j] == <span class="number">0</span>)&#123;</span><br><span class="line">        print_lcs(vec,str,i<span class="number">-1</span>,j<span class="number">-1</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%c"</span>,str[i<span class="number">-1</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(vec[i][j] == <span class="number">1</span>)&#123;</span><br><span class="line">        print_lcs(vec,str,i<span class="number">-1</span>,j);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        print_lcs(vec,str,i,j<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="built_in">string</span> str1,str2;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;str1&gt;&gt;str2;</span><br><span class="line">    <span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; vec(str1.size()+<span class="number">1</span>,<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(str2.size() +<span class="number">1</span>, <span class="number">-1</span>));</span><br><span class="line">    <span class="keyword">int</span> ans = lcse(str1, str2, vec);</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;ans&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    print_lcs(vec, str1, str1.size(), str2.size());</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="模板类和库函数"><a href="#模板类和库函数" class="headerlink" title="模板类和库函数"></a>模板类和库函数</h2><h3 id="模板类vector"><a href="#模板类vector" class="headerlink" title="模板类vector"></a>模板类vector</h3><ul><li><p>定义二维向量</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">vector</span>&lt;<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; &gt; p(m, <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;(n,<span class="number">0</span>)); <span class="comment">//m*n的二维向量，注意空格 所有元素初始化为0</span></span><br></pre></td></tr></table></figure></li><li><p>vector成员函数</p></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定义一维向量</span></span><br><span class="line"><span class="built_in">vector</span>&lt;type&gt; v;</span><br><span class="line"><span class="comment">// 末尾插入一个元素</span></span><br><span class="line">v.push_back(s);</span><br><span class="line"><span class="comment">// 任意位置插入元素</span></span><br><span class="line"><span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator it = v.begin()</span><br><span class="line">v.insert(it+pos,elem);<span class="comment">//插入一个</span></span><br><span class="line">v.insert(it+pos,<span class="number">4</span>,elem);<span class="comment">//插入四个</span></span><br><span class="line">v.insert(it+pos,起始，终止);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 删除一个元素</span></span><br><span class="line">v.erase(positon)</span><br><span class="line">v.erase(v.end()<span class="number">-1</span>)/v.erase(v.back());<span class="comment">//删除最后一个元素</span></span><br><span class="line"><span class="comment">// 求和:将vector中所有元素加到0上</span></span><br><span class="line">accumulate(v.begin(),v.end(),<span class="number">0</span>)</span><br><span class="line"><span class="comment">// 反转：</span></span><br><span class="line">reverse(v.begin(),v.end());</span><br><span class="line"><span class="comment">// 排序：</span></span><br><span class="line">sort(data.begin(),data.end(),::greater&lt;<span class="keyword">int</span>&gt;());</span><br><span class="line"><span class="comment">// iterator遍历</span></span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt;::iterator it = v.begin(); it != v.end(); ++it)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; *it &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">// 清空vector</span></span><br><span class="line">v.clear();</span><br><span class="line"><span class="comment">// 交换元素</span></span><br><span class="line">swap(sentence[<span class="number">0</span>],sentence[<span class="number">4</span>]);</span><br></pre></td></tr></table></figure><h3 id="模板类algrithom"><a href="#模板类algrithom" class="headerlink" title="模板类algrithom"></a>模板类algrithom</h3><ul><li><p>不修改内容的序列操作</p><ul><li><p>统计返回值个数</p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">count(v.begin(),v.end(),num)<span class="comment">//统计6的个数</span></span><br></pre></td></tr></table></figure></li><li><p>统计符合调剂返回值个数</p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">BigThan5</span><span class="params">(<span class="keyword">int</span> &amp;n)</span></span>&#123; <span class="keyword">return</span> n &gt; <span class="number">5</span>; &#125;</span><br><span class="line">count(v.begin(),v.end(),BigThan5)</span><br></pre></td></tr></table></figure></li><li><p>查找值/符合条件的值</p>  <figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">        find(v.begin(),v.end(),num)</span><br><span class="line">        find_if(v.begin(),v.end(),foo)</span><br><span class="line">        ``` </span><br><span class="line"></span><br><span class="line">### 模板类<span class="built_in">stack</span>&amp;<span class="built_in">queue</span>&amp;<span class="built_in">map</span></span><br><span class="line"></span><br><span class="line">- <span class="built_in">stack</span>&amp;<span class="built_in">queue</span></span><br><span class="line"></span><br><span class="line">    ``` c</span><br><span class="line">    # 定义</span><br><span class="line">    <span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s;</span><br><span class="line">    <span class="built_in">queue</span>&lt;<span class="keyword">int</span>&gt; q;</span><br><span class="line">    # 访问栈顶</span><br><span class="line">    s.top()/s.front()/s.back()</span><br><span class="line">    # 判断栈空/返回有效个数</span><br><span class="line">    s.empty()/s.size()</span><br><span class="line">    # 插入、删除、交换</span><br><span class="line">    s.push()/s.pop()/s.swap()</span><br></pre></td></tr></table></figure></li></ul></li><li><p>map</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">#初始化</span><br><span class="line"><span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">double</span>&gt; m</span><br><span class="line">#声明即插入</span><br><span class="line">m[<span class="string">"Li"</span>] = <span class="number">123.4</span>;</span><br><span class="line">#查找</span><br><span class="line">data_x = m.find(key);</span><br><span class="line">data_y = m[key];</span><br><span class="line"><span class="keyword">if</span>(m.find(key)==maplive.end())<span class="comment">//查找失败</span></span><br><span class="line">#遍历</span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">map</span>&lt;<span class="built_in">string</span>,<span class="keyword">double</span>&gt;::iterator it = m.begin(); it != m.end(); ++it)</span><br><span class="line">    &#123;</span><br><span class="line">            <span class="built_in">cout</span> &lt;&lt; it-&gt;first &lt;&lt; <span class="string">":"</span> &lt;&lt; it-&gt;second &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">#逆序遍历</span><br><span class="line"><span class="keyword">for</span>(<span class="built_in">map</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt;::reverse_iterator it = bag.rbegin();it!=bag.rend();it++)</span><br><span class="line">#删除</span><br><span class="line">m.erase(key);</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>multimap和multimap的排序</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">#初始化</span><br><span class="line"><span class="built_in">multimap</span>&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; bag;</span><br><span class="line">#插入数据</span><br><span class="line">bag.insert(make_pair(v,w));</span><br><span class="line">#排序</span><br><span class="line"><span class="built_in">vector</span>&lt;pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; &gt; BAG(bag.begin(),bag.end())</span><br><span class="line"><span class="comment">//按键升序</span></span><br><span class="line">sort(BAG.begin(),BAG.end());</span><br><span class="line"><span class="comment">//按值升序</span></span><br><span class="line">sort(BAG.begin(),BAG.end(),cmp_by_value);</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">cmp_by_value</span><span class="params">(<span class="keyword">const</span> pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; a,<span class="keyword">const</span> pair&lt;<span class="keyword">int</span>,<span class="keyword">int</span>&gt; b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a.first == b.first)&#123;</span><br><span class="line">        <span class="keyword">return</span> a.second&lt;b.second;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a.first&gt;b.first;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//遍历</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; BAG.size();i++)&#123;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;BAG[i].first&lt;&lt;<span class="string">" "</span>&lt;&lt;BAG[i].second&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="数学问题"><a href="#数学问题" class="headerlink" title="数学问题"></a>数学问题</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//浮点数判定相等</span></span><br><span class="line"><span class="built_in">fabs</span>(a-b)&lt;<span class="number">0.000001</span></span><br><span class="line"><span class="comment">//将M进制的大数X转换为N进制</span></span><br><span class="line"><span class="keyword">int</span> M,N;</span><br><span class="line"><span class="built_in">string</span> X;</span><br><span class="line"><span class="keyword">while</span>(<span class="built_in">cin</span>&gt;&gt;M&gt;&gt;N)&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;X;</span><br><span class="line">    <span class="keyword">int</span> data[<span class="number">1010</span>];<span class="comment">//保存M进制下的各个位数</span></span><br><span class="line">    <span class="keyword">int</span> output[<span class="number">1010</span>];<span class="comment">//保存N进制下的各个位数</span></span><br><span class="line">    <span class="built_in">memset</span>(output,<span class="number">0</span>,<span class="keyword">sizeof</span>(output));</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; X.length();i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">isalpha</span>(X[i]))&#123; data[i] = X[i]-<span class="string">'A'</span>+<span class="number">10</span>;&#125;</span><br><span class="line">        <span class="keyword">else</span>&#123; data[i] = X[i] - <span class="string">'0'</span>;&#125;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">1</span>,d = <span class="number">0</span>,len = X.length(),k = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(sum)&#123;</span><br><span class="line">            sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; len;i++)&#123;</span><br><span class="line">                d = data[i] / N;</span><br><span class="line">                sum += d;</span><br><span class="line">                <span class="keyword">if</span>(i == len - <span class="number">1</span>)&#123; output[k++] = data[i] % N;&#125;</span><br><span class="line">                <span class="keyword">else</span>&#123; data[i+<span class="number">1</span>] += (data[i] % N) * M;&#125;</span><br><span class="line">                data[i] = d;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">0</span>)&#123; output[k] = <span class="number">0</span>;k--;&#125;</span><br><span class="line">        <span class="keyword">if</span>(k == <span class="number">-1</span>)&#123; <span class="built_in">cout</span>&lt;&lt;<span class="number">0</span>&lt;&lt;<span class="built_in">endl</span>;&#125;</span><br><span class="line">        <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>;i &lt; k;i++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(output[k-i<span class="number">-1</span>] &gt; <span class="number">9</span>)&#123; <span class="built_in">cout</span>&lt;&lt;(<span class="keyword">char</span>)(output[k-i<span class="number">-1</span>]+<span class="string">'a'</span><span class="number">-10</span>);&#125;</span><br><span class="line">                <span class="keyword">else</span>&#123; <span class="built_in">cout</span>&lt;&lt;output[k-i<span class="number">-1</span>];&#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">cout</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//大数阶乘</span></span><br><span class="line"><span class="keyword">int</span> a[<span class="number">20001</span>];<span class="comment">//存储每一位的数字</span></span><br><span class="line"><span class="keyword">int</span> temp,digit,n,i,j = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">cin</span>&gt;&gt;n;</span><br><span class="line">a[<span class="number">0</span>] = <span class="number">1</span>;<span class="comment">//从1开始阶乘</span></span><br><span class="line">digit = <span class="number">1</span>;<span class="comment">//位数从第一位开始</span></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>;i &lt;= n;i++)&#123;</span><br><span class="line">    <span class="keyword">int</span> num = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(j = <span class="number">0</span>;j &lt; digit;j++)&#123;</span><br><span class="line">        temp = a[j]*i+num;<span class="comment">//将一个数字的每一位数都乘i</span></span><br><span class="line">        a[j] = temp % <span class="number">10</span>;</span><br><span class="line">        num = temp/<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span>(num)&#123;</span><br><span class="line">        a[digit] = num%<span class="number">10</span>;</span><br><span class="line">        num = num/<span class="number">10</span>;</span><br><span class="line">        digit++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = digit<span class="number">-1</span>;i&gt;=<span class="number">0</span>;i--)&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%d"</span>,a[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//判定素数</span></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">judge</span><span class="params">(<span class="keyword">int</span> x)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(x &lt;= <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">2</span>; i&lt;(<span class="keyword">int</span>)<span class="built_in">sqrt</span>(x)+<span class="number">1</span>;i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(x % i == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//求两个数字的公约数</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">gcd</span><span class="params">(<span class="keyword">int</span> a,<span class="keyword">int</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(b==<span class="number">0</span>) <span class="keyword">return</span> a;<span class="comment">// 递归的跳出条件是a mod b =5 ;0</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> gcd(b, a % b);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="库函数-string的增删查改"><a href="#库函数-string的增删查改" class="headerlink" title="库函数 string的增删查改"></a>库函数 string的增删查改</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">#获取带空格的字符串</span><br><span class="line">getchar();<span class="comment">//专门吃回车</span></span><br><span class="line">getline(<span class="built_in">cin</span>,mystr);</span><br><span class="line">#插入字符串</span><br><span class="line"><span class="built_in">string</span> s = <span class="string">"BUPT"</span>;</span><br><span class="line">s.insert(position,<span class="built_in">string</span>);</span><br><span class="line">#尾部插入字符串</span><br><span class="line">s.append(<span class="built_in">string</span>);</span><br><span class="line">s+=<span class="built_in">string</span>;</span><br><span class="line">#删除字符串</span><br><span class="line">s.erase(position,length);</span><br><span class="line">#比较字符串</span><br><span class="line"><span class="built_in">strcmp</span>(s1,s2);<span class="comment">//相同返回0,不相同返回1;</span></span><br><span class="line">#提取字符串</span><br><span class="line">s.substr(position,length);</span><br><span class="line">#查找字符串：str表示待查找的子串，position表示开始查找的下标/结束查找的下标</span><br><span class="line">res_pos = s.find(str,positon);</span><br><span class="line">res_pos = s.rfind(str,position)</span><br><span class="line"><span class="comment">//查找所有的bupt变成大写</span></span><br><span class="line"><span class="keyword">while</span> ((pos = s.find(<span class="string">"bupt"</span>,pos)) != <span class="built_in">string</span>::npos)&#123;</span><br><span class="line">    s.replace(pos, <span class="number">4</span>, <span class="string">"BUPT"</span>);</span><br><span class="line">&#125;</span><br><span class="line">#字符串转换成其他类型</span><br><span class="line"><span class="built_in">string</span> str = <span class="string">"12345.67"</span>;</span><br><span class="line">**atoi(str.c_str())**/atof(str)/atol(str)这个特别牛逼</span><br><span class="line">#将整形转换为字符串</span><br><span class="line"><span class="keyword">char</span>(<span class="number">101</span>)<span class="comment">//输出e</span></span><br><span class="line"><span class="comment">//另外一种形式的</span></span><br><span class="line"><span class="keyword">char</span> str[<span class="number">100</span>];</span><br><span class="line">itoa(num, str, <span class="number">10</span>)<span class="comment">//10为进制数</span></span><br><span class="line">#代替：第<span class="number">19</span>个字符串以及后面的<span class="number">5</span>个字符用str的第<span class="number">7</span>个字符以及后面的<span class="number">5</span>个字符代替</span><br><span class="line">s.replace(<span class="number">19</span>,<span class="number">6</span>,str3,<span class="number">7</span>,<span class="number">6</span>);<span class="comment">//7&amp;6可以选择</span></span><br><span class="line">#比较：s1&amp;s2是否相同</span><br><span class="line"><span class="built_in">string</span> s1=<span class="string">"123"</span>,s2=<span class="string">"123"</span>;</span><br><span class="line"><span class="built_in">cout</span>&lt;&lt;s1.compare(s2)&lt;&lt;<span class="built_in">endl</span>;<span class="comment">//0</span></span><br><span class="line">#大小写转换</span><br><span class="line"><span class="built_in">string</span> s = <span class="string">"Hello world"</span>;</span><br><span class="line">transform(s.begin(),s.end(),s.begin(),::<span class="built_in">toupper</span>);</span><br><span class="line">或者s[i] = <span class="built_in">toupper</span>(s[i]);</span><br><span class="line">#翻转字符串</span><br><span class="line"><span class="built_in">string</span> str = <span class="string">"song"</span>;</span><br><span class="line">reverse(str.begin(),str.end());</span><br></pre></td></tr></table></figure><ul><li><p>判定字符串是否结束</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a[i] == <span class="string">'\0'</span>;<span class="comment">//字符串最后一位的后面还有'\0'结束符</span></span><br></pre></td></tr></table></figure></li><li><p>字符串逆序套路：</p>  <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span>(left &lt; right)&#123;</span><br><span class="line">    temp = a[left];</span><br><span class="line">    a[left] = a[right];</span><br><span class="line">    a[right] = temp;</span><br><span class="line">    left++;</span><br><span class="line">    right--;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="ascii码对照表"><a href="#ascii码对照表" class="headerlink" title="ascii码对照表"></a>ascii码对照表</h2><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/BUPT_OJ_experience.png" alt=""></p>]]></content>
      
      <categories>
          
          <category> BUPT </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>colah对BP算法的详细讲解</title>
      <link href="/2018/01/24/colah-bp-algorithm/"/>
      <url>/2018/01/24/colah-bp-algorithm/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="引入计算图"><a href="#引入计算图" class="headerlink" title="引入计算图"></a>引入计算图</h2><p>如下计算图是为$e=(a+b)(b+1)$.我们可以为节点$a$&amp;节点$b$赋值来计算$e$<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-def.png" alt=""></p><h2 id="Factoring-Path（路径因式分解）"><a href="#Factoring-Path（路径因式分解）" class="headerlink" title="Factoring Path（路径因式分解）"></a>Factoring Path（路径因式分解）</h2><p>考虑对下图的链式法则：<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/chain-def-greek.png" alt=""><br>如果我们想要计算出$\frac{\partial Z}{\partial X}$，则必须要计算$3*3=9$条路径：</p><p>$$<br>\frac{\partial Z}{\partial X} = \alpha\delta + \alpha\epsilon + \alpha\zeta + \beta\delta + \beta\epsilon + \beta\zeta + \gamma\delta + \gamma\epsilon + \gamma\zeta（1）<br>$$</p><p>对上式进行因式分解则有：</p><p>$$<br>\frac{\partial Z}{\partial X} = (\alpha + \beta + \gamma)(\delta + \epsilon + \zeta) （2）<br>$$</p><p>公式（2）引出了“前向求导”和“反向求导”：它们都通过因式分解来高效计算偏导数。</p><h3 id="前向求导"><a href="#前向求导" class="headerlink" title="前向求导"></a>前向求导</h3><p>通过对每个节点上的路径的输入求和，我们可以得到总路径上的每个输入“影响”节点的偏导数。<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/chain-forward-greek.png" alt=""></p><h3 id="反向求导"><a href="#反向求导" class="headerlink" title="反向求导"></a>反向求导</h3><p>从计算图的输出节点出发，向初始节点移动并且在每个节点处合并从该节点引出的所有路径：<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/chain-backward-greek.png" alt=""></p><h3 id="前向求导和反向求导的对比"><a href="#前向求导和反向求导的对比" class="headerlink" title="前向求导和反向求导的对比"></a>前向求导和反向求导的对比</h3><ul><li>前向求导：<strong>跟踪每个输入如何影响所有节点</strong>,需要计算每个节点的$\frac{\partial}{\partial X}$。</li><li>反向求导：<strong>跟踪所有节点如何影响一个输出</strong>,需要计算每个节点的$\frac{\partial Z}{\partial}$。</li></ul><h2 id="计算速度的提升"><a href="#计算速度的提升" class="headerlink" title="计算速度的提升"></a>计算速度的提升</h2><p>如果对计算图的每条边添加偏导数则有：<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-eval-derivs.png" alt=""></p><ul><li><p>当我们使用前向求导来计算每个节点对$b$的偏导数则有：<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-forwradmode.png" alt=""><br>由上图可见计算出$\frac{\partial e}{\partial b}$的代价是需要计算很多“无用”的偏导数。[注：“无用”是因为在梯度下降的过程中，我们只关心输出对每个节点的偏导数]</p></li><li><p>当我们使用反向求导计算$e$对各个节点的偏导数有：<br><img src="https://colah.github.io/posts/2015-08-Backprop/img/tree-backprop.png" alt=""><br>对比两张图可以发现，反向求导“真正”的给出了我们想要的偏导数。在有百万级别的输入时的极端情况下，前向求导需要计算百万次才能得到输出结果对所有节点的偏导数。而反向求导只需要计算一次。<br>在我们训练神经网络的时候需要计算对所有参数的偏导数用以梯度下降，因此反向求导极大的提升了计算速度。</p></li></ul><p><strong>Once you’ve framed the question, the hardest work is already done</strong> </p><blockquote><p>参考与引用：<br><a href="https://colah.github.io/posts/2015-08-Backprop/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Backprop/</a></p></blockquote>]]></content>
      
      <categories>
          
          <category> MachineLearning </category>
          
      </categories>
      
      
        <tags>
            
            <tag> algorithm </tag>
            
            <tag> backpropagation </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>常见技术投资指标学习</title>
      <link href="/2018/01/23/quantitative-investment-index/"/>
      <url>/2018/01/23/quantitative-investment-index/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="DDX"><a href="#DDX" class="headerlink" title="DDX"></a>DDX</h2><blockquote><p>大单买入量 (以占流通盘比例的方式) ，目前主力造假较多(拆单软件)。<br>红色买入，绿色卖出。</p></blockquote><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>若股价大幅拉升&amp;高DDX值：主力疯狂拉动，介入风险极大。</li><li>安全介入点：DDX与DDY背离</li><li>换手率作为补充条件：以超过3%为标准</li></ul><h2 id="DDY"><a href="#DDY" class="headerlink" title="DDY"></a>DDY</h2><blockquote><p>当日卖出单数减去买入单数占散户人数(估算值)的比例。也即散户出货比例,红柱说明出的多，散户仓位下降，主力仓位相对增加。</p></blockquote><h3 id="注意事项-1"><a href="#注意事项-1" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>DDX与DDY的同向运动：既有大单而且主力加仓/主力偷偷用中小单加仓。</li></ul><h2 id="DDZ"><a href="#DDZ" class="headerlink" title="DDZ"></a>DDZ</h2><blockquote><p>行情启动力度：对DDX和DDY的重要辅助。</p></blockquote><h3 id="注意事项-2"><a href="#注意事项-2" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>入场必要条件：DDX和DDY同向运动。入场充分条件：DDZ大于20</li></ul><h2 id="MACD"><a href="#MACD" class="headerlink" title="MACD"></a>MACD</h2><blockquote><p>即指数平滑移动平均线。中长期分析手段，产生的交叉信号对短线操作反应相对滞后。</p></blockquote><h3 id="MACD的指标包含三个子指标"><a href="#MACD的指标包含三个子指标" class="headerlink" title="MACD的指标包含三个子指标:"></a>MACD的指标包含三个子指标:</h3><ul><li>$DIF=EMA(close，12）-EMA（close，26）$<br>其中：指数平滑移动平均线（EMA）</li><li>DEA=DIFF的M日的平均的指数平滑移动平均线，记为DEA</li><li>$ MACD=DIFF-DEA $</li></ul><h3 id="注意事项-3"><a href="#注意事项-3" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>当DIF和DEA处于0轴以上时，属于多头市场。</li><li>当DIF和DEA处于0轴以下时，属于空头市场。</li><li>长期！长期！长期！</li></ul><h2 id="KDJ"><a href="#KDJ" class="headerlink" title="KDJ"></a>KDJ</h2><blockquote><p>用于中短期趋势分析的随机指标</p></blockquote><h3 id="指标计算说明"><a href="#指标计算说明" class="headerlink" title="指标计算说明"></a>指标计算说明</h3><p>$$RSV_n = 100(\frac{C_n-L_n}{H_n-L_n})$$</p><p>其中$C_n$为第n日收盘价，$L_n$为n日内最低价，$H_n$为n日内最高价。</p><p>$$K_t = \frac23K_{t-1}+\frac13RSV_t$$<br>$$D_t = \frac23D_{t-1}+\frac13K_t$$<br>$$J_t = 3K_{t}-2D_t$$</p><h3 id="注意事项-4"><a href="#注意事项-4" class="headerlink" title="注意事项"></a>注意事项</h3><ul><li>D大于80时，行情呈现超买现象。D小于20时，行情呈现超卖现象。</li><li>上涨趋势中，K值大于D值，K线向上突破D线时，为买进信号。下跌趋势中，K值小于D值，K线向下跌破D线时，为卖出信号。</li><li>KD指标不适于发行量小、交易不活跃的股票，但是KD指标对大盘和热门大盘股有极高准确性。当随机指标与股价出现背离时，一般为转势的信号。</li></ul><h2 id="RSI"><a href="#RSI" class="headerlink" title="RSI"></a>RSI</h2><blockquote><p>通过测量某一个期间内股价上涨总幅度占股价变化总幅度平均值的百分比，来评估多空力量的强弱程度。</p></blockquote><h3 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h3><p>$$ RSI_n = \frac{100*收盘涨幅平均值_n}{(收盘涨幅平均值_n+收盘跌幅平均值_n)} $$</p><p>其中：上的力量较大，则计算出来的指标上升；若下的力量较大，则指标下降，由此测算出市场走势的强弱。</p><h3 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h3><p>: RSI值如果超过50,表明市场进入强市,可以考虑买入,但是如果继续进入”极强”区,就要考虑物极必反,准备卖出了。同理RSI值在50以下也是如此,如果进入了”极弱”区,则表示超卖,应该伺机买入。</p><h2 id="BOLL"><a href="#BOLL" class="headerlink" title="BOLL"></a>BOLL</h2><blockquote><p>标准差原理设计而来，核心概念是：“股价通道”。且BOLL线分为上轨线UP 、中轨线MB、下轨线DN和价格线。</p></blockquote><h3 id="计算公式-1"><a href="#计算公式-1" class="headerlink" title="计算公式"></a>计算公式</h3><p>$$中轨线=N日的移动平均线$$<br>$$上轨线=中轨线+两倍的标准差$$<br>$$下轨线=中轨线－两倍的标准差$$</p><h3 id="使用说明-1"><a href="#使用说明-1" class="headerlink" title="使用说明"></a>使用说明</h3><p>如果股价脱离股价信道运行，则意味着行情处于极端的状态下。</p><ul><li>当布林线的上、中、下轨线同时向上运行时，表明股价强势特征非常明显，股价短期内将继续上涨，投资者应坚决持股待涨或逢低买入。</li></ul><h2 id="WR"><a href="#WR" class="headerlink" title="WR"></a>WR</h2><blockquote><p>威廉指标：短线超买超卖指标。<br>$$WR_n = \frac{High_n-Close}{High_n-Low_n}$$</p></blockquote><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>反映过于灵敏，指标波动频率过快，引起信号频发现象，误差率也非常高，过多的信号和严重的误差率造成投资者不敢轻易使用它。应改动时间参数使之适合模型。</p><h2 id="OBV：能量潮指标"><a href="#OBV：能量潮指标" class="headerlink" title="OBV：能量潮指标"></a>OBV：能量潮指标</h2><blockquote><p>On Balance Volumn,结合成交量的指标！<strong>重要假设原理</strong>：通常股价上升所需的成交量总是较大；下跌时，则成交量可能放大，也可能较小。价格升降而成交量不相应升降，则市场价格的变动难以为继。</p></blockquote><h3 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h3><ul><li>当股价上升而OBV线下降，表示买盘无力，股价可能会回跌。</li><li>股价下降时而OBV线上升，表示买盘旺盛，逢低接手强股，股价可能会止跌回升。</li></ul><h2 id="BIAS"><a href="#BIAS" class="headerlink" title="BIAS"></a>BIAS</h2><blockquote><p>乖离率指标：用百分比表示价格与MA之间的偏离程度。</p></blockquote><h3 id="计算公式："><a href="#计算公式：" class="headerlink" title="计算公式："></a>计算公式：</h3><p>$$乖离率=\frac{(当日收盘价-N日平均价)}{N日平均价}*100%$$</p>]]></content>
      
      <categories>
          
          <category> QuantitativeInvestment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> index </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python语言学习</title>
      <link href="/2017/12/07/Python-language/"/>
      <url>/2017/12/07/Python-language/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h1 id="面向对象"><a href="#面向对象" class="headerlink" title="面向对象"></a>面向对象</h1><h2 id="静态函数，类函数，成员函数，属性函数的区别"><a href="#静态函数，类函数，成员函数，属性函数的区别" class="headerlink" title="静态函数，类函数，成员函数，属性函数的区别"></a>静态函数，类函数，成员函数，属性函数的区别</h2><h3 id="补充知识："><a href="#补充知识：" class="headerlink" title="补充知识："></a>补充知识：</h3><ul><li>实例变量：每个实例独有的变量</li><li><p>类变量：所有实例共享的变量</p><p>形象理解：哈士奇（类变量）是狗的一种，而每只狗都只会有一个主人给它取<strong>唯一</strong>的名字，例如“蛤蛤”（成员变量）。用代码来解释就是</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span>:</span></span><br><span class="line">    kind = <span class="string">"Husky"</span> <span class="comment"># 类变量</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name <span class="comment"># 实例变量</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="四类函数的定义"><a href="#四类函数的定义" class="headerlink" title="四类函数的定义"></a>四类函数的定义</h3><p>明确了实例变量和类变量之后，四类函数就很好理解了。先看官方定义：</p><ul><li>静态函数（@staticmethod）:即静态方法,不可以访问实例变量或类变量。</li><li>类函数（@classmethod）：只能访问类变量，不能访问实例变量。</li><li>成员函数：实例后使用的方法，且只能通过实例进行调用。</li><li>属性函数（@property）：通过装饰器@property把一个方法变成一个静态属性</li></ul><h3 id="四类函数的形象解释"><a href="#四类函数的形象解释" class="headerlink" title="四类函数的形象解释"></a>四类函数的形象解释</h3><p>再次请出“蛤蛤”，首先讲解静态函数:通俗的说静态方法就是函数的形参中没有<strong>self</strong>。也即，静态函数与类中的静态变量&amp;实例变量都没有半毛钱关系<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bark</span><span class="params">()</span>:</span></span><br><span class="line">        print(<span class="string">"my name is Haha"</span>)</span><br><span class="line"></span><br><span class="line">d1 = Dog()</span><br><span class="line">d1.bark()</span><br><span class="line"><span class="comment"># 使用静态方法，输出结果为my name is Haha</span></span><br></pre></td></tr></table></figure></p><p>那么类函数呢？<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line">    name = <span class="string">"Haha"</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bark</span><span class="params">(cls)</span>:</span></span><br><span class="line">        print(<span class="string">"my name is %s"</span> % cls.name)</span><br><span class="line"></span><br><span class="line">d2 = Dog()</span><br><span class="line">d2.bark()</span><br><span class="line"><span class="comment"># 使用类方法，输出结果为my name is Haha</span></span><br></pre></td></tr></table></figure></p><p>再看看成员函数<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(object)</span>:</span></span><br><span class="line">    name = <span class="string">"Haha"</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, nick_name)</span>:</span></span><br><span class="line">        self.nick_name = nick_name</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bark</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"my name is %s and my nick name is %s"</span> % (name,self.nick_name))</span><br><span class="line">d3 = Dog(<span class="string">"Heiha"</span>)</span><br><span class="line">d3.bark()</span><br><span class="line"><span class="comment"># 使用成员函数，输出结果为my name is Haha and my nick name is Heiha</span></span><br><span class="line">```    </span><br><span class="line">最后看看属性函数：</span><br><span class="line">```py</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span><span class="params">(obkect)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, name)</span>:</span></span><br><span class="line">        self.name = name</span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bark</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(<span class="string">"my name is %s"</span> % self.name)</span><br><span class="line"><span class="comment"># 使用属性函数的方式需要注意！此时bark函数已经是Dog类的一个属性。</span></span><br><span class="line">d4 = Dog(<span class="string">"Haha"</span>)</span><br><span class="line"><span class="comment"># 如此使用属性函数，输出结果为myname is Haha</span></span><br><span class="line">d4.talk</span><br></pre></td></tr></table></figure></p><h3 id="补充：-property的使用"><a href="#补充：-property的使用" class="headerlink" title="补充：@property的使用"></a>补充：@property的使用</h3><h4 id="为什么需要有-property装饰器？"><a href="#为什么需要有-property装饰器？" class="headerlink" title="为什么需要有@property装饰器？"></a>为什么需要有@property装饰器？</h4><blockquote><p>编程中出现的问题：绑定属性的时候无法检查参数！</p></blockquote><ul><li>解决方案一：在类中定义set()和get()方法来设置与获取成绩。这么写是OK的，但是当你把类进行实例化之后，就会懂得这个方案的麻烦程度了。</li></ul><h4 id="property把方法变成属性调用"><a href="#property把方法变成属性调用" class="headerlink" title="@property把方法变成属性调用"></a>@property把<strong>方法变成属性</strong>调用</h4><p>　使用方法：把你想要设置的属性变成一个getter方法，在加上<code>@property</code>装饰器，在setter方法里就可以检查参数的合法性了。<br>　实例化之后，就可以直接绑定属性而不用再去调用类方法！</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span><span class="params">(object)</span>:</span></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self._score</span><br><span class="line">    </span><br><span class="line"><span class="meta">    @score.setter</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, value)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> isinstance(value, int):</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'score must be an integer!'</span>)</span><br><span class="line">        <span class="keyword">if</span> value &lt; <span class="number">0</span> <span class="keyword">or</span> value &gt; <span class="number">100</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'scofre must between 0-100!'</span>)</span><br><span class="line">        self._score = value</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化</span></span><br><span class="line">s = Student()</span><br><span class="line">s.score = <span class="number">60</span> <span class="comment"># equal to s.set_score(60)</span></span><br><span class="line">s.score = <span class="number">101</span> </span><br><span class="line"><span class="comment"># Traceback (most recent call last):</span></span><br><span class="line">  ...</span><br><span class="line">ValueError: score must between <span class="number">0</span> ~ <span class="number">100</span>!</span><br></pre></td></tr></table></figure><h3 id="四类函数的小总结："><a href="#四类函数的小总结：" class="headerlink" title="四类函数的小总结："></a>四类函数的小总结：</h3><p>综上所述，其实我们可以四类函数当做一个逐渐释放权力的过程。当使用<strong>静态函数</strong>时，类的任何信息你都无权得到；当你使用<strong>类函数</strong>时，你只可以得到类变量里面的信息，而无法得到实例化之后的类的信息；只有当你使用<strong>成员函数</strong>，你的权力才得到完整的释放，你既可以使用类变量的信息又可以使用实例化后类的信息。而<strong>属性函数</strong>则是把一个函数当做属性来看待，这是最好理解的。</p><h3 id="我还是不懂何时使用它们怎么办？"><a href="#我还是不懂何时使用它们怎么办？" class="headerlink" title="我还是不懂何时使用它们怎么办？"></a>我还是不懂何时使用它们怎么办？</h3><p>记住核心思想：</p><ol><li>类函数主要用途是作为构造函数。</li><li>静态函数的形参没有self</li><li>成员函数用的最多</li></ol><h2 id="类的访问控制：单下划线-与双下划线"><a href="#类的访问控制：单下划线-与双下划线" class="headerlink" title="类的访问控制：单下划线_与双下划线__"></a>类的访问控制：单下划线_与双下划线__</h2><ol><li>“_”:单下划线表示只允许其本身与其子类进行访问</li><li>“__”:双下划线表示只允许这个类本身进行访问。</li></ol><h1 id="python语言特性"><a href="#python语言特性" class="headerlink" title="python语言特性"></a>python语言特性</h1><h2 id="python是动态类型语言"><a href="#python是动态类型语言" class="headerlink" title="python是动态类型语言"></a>python是动态类型语言</h2><blockquote><p>在编写代码的时候可以不指定变量的数据类型</p></blockquote><h2 id="with语句："><a href="#with语句：" class="headerlink" title="with语句："></a>with语句：</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. with语句的语法格式</span></span><br><span class="line"><span class="keyword">with</span> content_expression [<span class="keyword">as</span> targer(s)]:</span><br><span class="line">    <span class="keyword">with</span>-body</span><br><span class="line"><span class="comment"># 2. with语句操作文件对象</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">r'somefileName'</span>) <span class="keyword">as</span> somefile:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> somefile:</span><br><span class="line">        <span class="keyword">print</span> line</span><br><span class="line">        <span class="comment"># ... more code</span></span><br><span class="line"><span class="comment"># 3. 上文代码等价于下文代码：</span></span><br><span class="line">somefile = open(<span class="string">r'openfileName'</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> somefile:</span><br><span class="line">        <span class="keyword">print</span> line</span><br><span class="line">        <span class="comment"># ...more code</span></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    somefile.close()</span><br></pre></td></tr></table></figure><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><ol><li><p>一个简单易懂的例子:如果某些代码<strong>可能会出错</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    r = <span class="number">10</span> / <span class="number">0</span></span><br><span class="line"><span class="keyword">except</span> ZeroDivisonError, e:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"ZeroDivisionError"</span>, e</span><br><span class="line"><span class="keyword">except</span> ValueError, e:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"ValueError"</span>, e</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'finally'</span></span><br></pre></td></tr></table></figure></li><li><p>记录错误：打印错误信息，同时让程序继续执行</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">(s)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">10</span> / int(s)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        foo(<span class="string">'0'</span>)</span><br><span class="line">    <span class="keyword">except</span> StandardError, e:</span><br><span class="line">        logging.exception(e)</span><br><span class="line">main()</span><br><span class="line"><span class="keyword">print</span> <span class="string">"END"</span></span><br></pre></td></tr></table></figure></li></ol><p>　程序打印完错误信息后会继续执行，并且正常退出。</p><ol start="3"><li>抛出错误<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="number">10</span> / <span class="number">0</span></span><br><span class="line"><span class="keyword">except</span> ZeroDivisionError:</span><br><span class="line">    <span class="keyword">raise</span> ValueError(<span class="string">'input error!'</span>)</span><br></pre></td></tr></table></figure></li></ol><h1 id="代码trick"><a href="#代码trick" class="headerlink" title="代码trick"></a>代码trick</h1><h2 id="再见！中间变量"><a href="#再见！中间变量" class="headerlink" title="再见！中间变量"></a>再见！中间变量</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1</span></span><br><span class="line">b = <span class="number">2</span></span><br><span class="line"><span class="comment">#不使用中间变量交换两个变量的值</span></span><br><span class="line">a, b = b, a</span><br></pre></td></tr></table></figure><h2 id="字符串逆序"><a href="#字符串逆序" class="headerlink" title="字符串逆序"></a>字符串逆序</h2><p>实质是把字符串转换成列表进行操作<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="string">"python"</span></span><br><span class="line"><span class="comment"># 方法一:看起来很装逼的方法</span></span><br><span class="line"><span class="keyword">print</span> a[::<span class="number">-1</span>] <span class="comment"># "nohtyp" </span></span><br><span class="line"><span class="comment"># 方法二：可读性强的方法</span></span><br><span class="line"><span class="keyword">print</span> list(a).reverse()</span><br></pre></td></tr></table></figure></p><h2 id="python可以使用连续赋值-从左至右"><a href="#python可以使用连续赋值-从左至右" class="headerlink" title="python可以使用连续赋值, 从左至右"></a>python可以使用连续赋值, 从左至右</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">x = [<span class="number">0</span>, <span class="number">1</span>]</span><br><span class="line">i = <span class="number">0</span></span><br><span class="line"><span class="comment"># 当我们连续赋值的时候</span></span><br><span class="line">i, x[i] = <span class="number">1</span>, <span class="number">2</span></span><br><span class="line"><span class="comment"># print(x)的结果为[0, 2]:编译器先把1赋值给了i，那么x[i]即为x[1]，接下来把2赋值给了x[1]。</span></span><br></pre></td></tr></table></figure><h2 id="矩阵转置"><a href="#矩阵转置" class="headerlink" title="矩阵转置"></a>矩阵转置</h2><p>其原理为zip()函数：将对象中对应的元素打包成一个个元组，并且返回由元组组成的列表。这恰好符合矩阵转置的操作<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mat = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]</span><br><span class="line"><span class="comment"># *可以简单理解为解压</span></span><br><span class="line"><span class="keyword">print</span> zip(*mat)</span><br><span class="line"><span class="comment">#[(1, 4), (2, 5), (3, 6)]</span></span><br></pre></td></tr></table></figure></p><h2 id="列表转字符串"><a href="#列表转字符串" class="headerlink" title="列表转字符串"></a>列表转字符串</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = [<span class="string">"Code"</span>, <span class="string">"mentor"</span>, <span class="string">"Python"</span>, <span class="string">"Developer"</span>]</span><br><span class="line"><span class="keyword">print</span> <span class="string">" "</span>.join(a)</span><br><span class="line"><span class="comment"># Code mentor Python Developer</span></span><br></pre></td></tr></table></figure><h2 id="在一个for循环中遍历两个列表"><a href="#在一个for循环中遍历两个列表" class="headerlink" title="在一个for循环中遍历两个列表"></a>在一个for循环中遍历两个列表</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">list1 = [<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>]</span><br><span class="line">list2 = [<span class="string">'apple'</span>,<span class="string">'boy'</span>,<span class="string">'cat'</span>,<span class="string">'dog'</span>]</span><br><span class="line"><span class="keyword">for</span> x,y <span class="keyword">in</span> zip(list1, list2):</span><br><span class="line">    <span class="keyword">print</span> x <span class="string">'is'</span> y</span><br></pre></td></tr></table></figure><h2 id="同时处理多个文件"><a href="#同时处理多个文件" class="headerlink" title="同时处理多个文件"></a>同时处理多个文件</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> open(filename1) <span class="keyword">as</span> fp1, open(filename2) <span class="keyword">as</span> fp2, open(filename3) <span class="keyword">as</span> fp3:</span><br><span class="line"><span class="keyword">for</span> l1 <span class="keyword">in</span> fp1:</span><br><span class="line">    l2 = fp2.readline()</span><br><span class="line">    l3 = fp3.readline()</span><br><span class="line">    <span class="comment"># do something</span></span><br></pre></td></tr></table></figure><h2 id="给字符串前面补“0”"><a href="#给字符串前面补“0”" class="headerlink" title="给字符串前面补“0”"></a>给字符串前面补“0”</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num = <span class="string">"123"</span></span><br><span class="line"><span class="comment"># 向num前面填充0至总位数为5</span></span><br><span class="line">str_n = num.zfill(<span class="number">5</span>)</span><br></pre></td></tr></table></figure><h1 id="回调函数-callback"><a href="#回调函数-callback" class="headerlink" title="回调函数 callback()"></a>回调函数 callback()</h1><h2 id="官方解释："><a href="#官方解释：" class="headerlink" title="官方解释："></a>官方解释：</h2><blockquote><p>回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用来调用其所指向的函数时，我们就说这是回调函数。</p></blockquote><h2 id="形象解释："><a href="#形象解释：" class="headerlink" title="形象解释："></a>形象解释：</h2><blockquote><p><strong>吃饭、喝水、睡觉</strong>就是一个通过<strong>大脑</strong>调用的<strong>动作</strong>。如果你把<strong>这些动作</strong>作为参数传递给<strong>大脑</strong>，当<strong>这些动作</strong>被用来<strong>真正去执行</strong>时，我们就说这是<strong>回调函数</strong>。</p></blockquote><h2 id="代码解释："><a href="#代码解释：" class="headerlink" title="代码解释："></a>代码解释：</h2><pre><code class="py"><span class="function"><span class="keyword">def</span> <span class="title">eat</span><span class="params">(food)</span>:</span>    <span class="keyword">print</span> <span class="string">"I will eat "</span>, food<span class="function"><span class="keyword">def</span> <span class="title">drink</span><span class="params">(beverage)</span>:</span>    <span class="keyword">print</span> <span class="string">"I will drink "</span>, beverage<span class="function"><span class="keyword">def</span> <span class="title">brain</span><span class="params">(action, target)</span>:</span>    <span class="keyword">return</span> action(target)</code></pre><blockquote><p>参考与引用</p><ol><li><a href="https://m.baidu.com/?from=844b&amp;vit=fps&amp;nsukey=QL%2FYJKapoliD84rv4ROf08qlZJ83uWDoXzrVj" target="_blank" rel="noopener">https://m.baidu.com/?from=844b&amp;vit=fps&amp;nsukey=QL%2FYJKapoliD84rv4ROf08qlZJ83uWDoXzrVj</a></li><li><a href="https://www.cnblogs.com/scf141592/p/5726347.html" target="_blank" rel="noopener">https://www.cnblogs.com/scf141592/p/5726347.html</a></li><li><a href="https://www.cnblogs.com/crazyrunning/p/6945183.html" target="_blank" rel="noopener">https://www.cnblogs.com/crazyrunning/p/6945183.html</a></li><li><a href="https://www.cnblogs.com/polly333/p/8143672.html" target="_blank" rel="noopener">https://www.cnblogs.com/polly333/p/8143672.html</a></li><li><a href="https://www.cnblogs.com/crazyrunning/p/6945183.html" target="_blank" rel="noopener">https://www.cnblogs.com/crazyrunning/p/6945183.html</a></li><li><a href="https://www.cnblogs.com/imageSet/p/7473326.html" target="_blank" rel="noopener">https://www.cnblogs.com/imageSet/p/7473326.html</a></li><li><a href="https://www.jianshu.com/p/4bd8a1c93cbe" target="_blank" rel="noopener">https://www.jianshu.com/p/4bd8a1c93cbe</a></li><li><a href="https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386820062641f3bcc60a4b164f8d91df476445697b9e000" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386820062641f3bcc60a4b164f8d91df476445697b9e000</a></li><li><a href="https://www.liaoxuefeng.com/" target="_blank" rel="noopener">https://www.liaoxuefeng.com/</a></li><li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/" target="_blank" rel="noopener">https://www.ibm.com/developerworks/cn/opensource/os-cn-pythonwith/</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> language </tag>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Latex&amp;Mathjax使用</title>
      <link href="/2017/09/06/Latex-Mathjex-usage/"/>
      <url>/2017/09/06/Latex-Mathjex-usage/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h1 id="Latex"><a href="#Latex" class="headerlink" title="Latex"></a>Latex</h1><h2 id="环境配置："><a href="#环境配置：" class="headerlink" title="环境配置："></a>环境配置：</h2><p>在Mac上通过Sublime、Skim编辑LaTeX</p><h3 id="在Sublime-Text中安装Package-Control"><a href="#在Sublime-Text中安装Package-Control" class="headerlink" title="在Sublime Text中安装Package Control"></a>在Sublime Text中安装Package Control</h3><ul><li>进入<a href="https://packagecontrol.io/installation" target="_blank" rel="noopener">Package Control官网</a>复制灰色区块的代码。</li><li>打开Sublime Text。</li><li>使用快捷键“control+~”（~就在Esc键的下方）打开控制面板Console。你会在Sublime Text的底部看到弹出一个白色窗口。</li><li>将刚才复制的代码粘贴到控制面板。</li><li>按下“Enter”回车键。然后退出并重启Sublime Text。</li></ul><h3 id="安装LaTex-Tools"><a href="#安装LaTex-Tools" class="headerlink" title="安装LaTex Tools"></a>安装LaTex Tools</h3><ul><li>Sublime Text重启后，按下“Command+Shift+P”打开命令托盘Command pallet，这一步也可以通过Tools下拉菜单完成。</li><li>在命令托盘里输入“Install Package”，按下Enter回车建。</li><li>完成之后，输入“LaTeX Tools”，找到这一项并回车安装。</li><li>退出并重启Sublime Text。</li></ul><h3 id="安装Skim"><a href="#安装Skim" class="headerlink" title="安装Skim"></a>安装Skim</h3><ul><li>进<a href="https://skim-app.sourceforge.io/" target="_blank" rel="noopener">Skim</a>下载Skim并安装</li><li>打开Skim，在菜单栏中Skim &gt; Preference(选项) &gt; Sync(同步)</li><li>在预设菜单中选择Sublime Text<br>skim。</li><li>关闭上面这个窗口。</li></ul><h3 id="环境的基本使用"><a href="#环境的基本使用" class="headerlink" title="环境的基本使用"></a>环境的基本使用</h3><ol><li>打开Sublim Text, Command+N新建文件在里面编写LaTeX代码了。</li><li>完成编辑之后，Command+S保存文件。</li><li>Command+B编译并运行，这时就可以在Skim里面看到PDF预览了。</li></ol><hr><h2 id="命令与环境-对大小写敏感"><a href="#命令与环境-对大小写敏感" class="headerlink" title="命令与环境(对大小写敏感)"></a>命令与环境(对大小写敏感)</h2><ul><li>命令以\开头。 如<code>\LaTeX</code></li><li>源代码结构<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;...&#125; //使用文档类</span><br><span class="line">\usepackage&#123;...&#125; //调用宏包</span><br><span class="line">    \begin&#123;document&#125;</span><br><span class="line">    \end&#123;document&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="宏包和文档类"><a href="#宏包和文档类" class="headerlink" title="宏包和文档类"></a>宏包和文档类</h2><h3 id="文档类-documentclass-lt-options-gt-lt-class-name-gt"><a href="#文档类-documentclass-lt-options-gt-lt-class-name-gt" class="headerlink" title="文档类\documentclass[&lt;options&gt;]{&lt;class-name&gt;}"></a>文档类<code>\documentclass[&lt;options&gt;]{&lt;class-name&gt;}</code></h3><h4 id="lt-class-name-gt-包括："><a href="#lt-class-name-gt-包括：" class="headerlink" title="&lt;class-name&gt;包括："></a><code>&lt;class-name&gt;</code>包括：</h4><ul><li><strong>article</strong> 论文，报告，说明文档</li><li>report 长篇文档类</li><li>book 书籍文档类</li><li>proc 基于article文档类的学术文档</li><li>slides 幻灯格式的文档类</li><li>minimal 精简的文档类</li></ul><h4 id="lt-options-gt-包括："><a href="#lt-options-gt-包括：" class="headerlink" title="&lt;options&gt;包括："></a><code>&lt;options&gt;</code>包括：</h4><p>　例：纸张为A4,基本字号为11pt，双面排版<code>\documentclass[11pt,twoside,a4paper]{article}</code></p><ul><li>基本字号：10pt，11pt,12pt，缺省为10pt</li><li>纸张大小：a4paper,letterpaper,a5paper,b5pape</li><li>公式位置：fleqn 令行间公式左对齐（缺省为居中）</li></ul><h2 id="文件的组织方式"><a href="#文件的组织方式" class="headerlink" title="文件的组织方式"></a>文件的组织方式</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">\include&#123;&lt;filename&gt;&#125;</span><br><span class="line">\input&#123;&lt;filename&gt;&#125;</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">## 用LaTeX排版文字</span><br><span class="line">### UTF-8编码</span><br><span class="line">```latex</span><br><span class="line">\usepackage[utf-8]&#123;inputenc&#125;</span><br></pre></td></tr></table></figure><h3 id="排版中文"><a href="#排版中文" class="headerlink" title="排版中文"></a>排版中文</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">\documentclass&#123;ctexart&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">中文LaTeX排版</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><h3 id="LaTeX中的符号"><a href="#LaTeX中的符号" class="headerlink" title="LaTeX中的符号"></a>LaTeX中的符号</h3><ol><li><p>空格与分段<br>　一个与多个空格&amp;一个与多个回车效果相同</p></li><li><p>注释 %</p></li></ol><h2 id="文档元素"><a href="#文档元素" class="headerlink" title="文档元素"></a>文档元素</h2><h3 id="章节标题"><a href="#章节标题" class="headerlink" title="章节标题"></a>章节标题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\section&#123;&lt;title&gt;&#125; \subsection&#123;&lt;title&gt;&#125; \subsubsection&#123;&lt;title&gt;&#125; \paragraph&#123;&lt;title&gt;&#125; \subparagraph&#123;&lt;title&gt;&#125;</span><br></pre></td></tr></table></figure><h3 id="居中插入url"><a href="#居中插入url" class="headerlink" title="居中插入url"></a>居中插入url</h3><p>\begin{center}<br>  \url{<a href="https://cmt.research.microsoft.com/NIPS2018/}" target="_blank" rel="noopener">https://cmt.research.microsoft.com/NIPS2018/}</a><br>\end{center}</p><hr><h2 id="常见错误"><a href="#常见错误" class="headerlink" title="常见错误"></a>常见错误</h2><h3 id="Latex中文utf-8编码"><a href="#Latex中文utf-8编码" class="headerlink" title="Latex中文utf-8编码"></a>Latex中文utf-8编码</h3><p>使用CJKutf8解决问题<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;CJKutf8&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;&lt;font&gt;&#125;</span><br><span class="line"> ...</span><br><span class="line">\end&#123;CJK&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure></p><p>font为简体中文字体，CJK自带的utf-8简体字体有gbsn（宋体）和gkai（楷体）。以下代码是一个简单的例子（一定要将tex文件保存成utf-8格式）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">%test.tex</span><br><span class="line">\documentclass&#123;article&#125;</span><br><span class="line">\usepackage&#123;CJKutf8&#125;</span><br><span class="line">\begin&#123;document&#125;</span><br><span class="line">\begin&#123;CJK&#125;&#123;UTF8&#125;&#123;gbsn&#125;</span><br><span class="line">这是一个CJKutf8的例子，使用的字体是gbsn。</span><br><span class="line">\end&#123;CJK&#125;</span><br><span class="line">\end&#123;document&#125;</span><br></pre></td></tr></table></figure><hr><h1 id="MathJax的基本使用"><a href="#MathJax的基本使用" class="headerlink" title="MathJax的基本使用"></a>MathJax的基本使用</h1><ol><li>希腊字母</li></ol><p>　　　　名称：alpha,大写:$A$,Tex:A,小写:$\alpha$,Tex:\alpha</p><ol start="2"><li>括号</li></ol><ul><li>大括号：\lbrace,\rbrace </li><li>尖括号：\langle,\rangle</li><li>取整：\lceil,\lfloor,\rceil,\floor</li></ul><ol start="3"><li>求和积分累乘</li></ol><ul><li>求和与乘法：\sum，\cdot</li><li>积分：\int,\iint</li><li>累乘：\prod</li></ul><ol start="4"><li>特殊函数和符号</li></ol><ul><li>三角函数：\sin,\arctan,\lim</li><li>比较运算符：小于（\lt）、大于(\gt)、小于等于(\le)、大于等于(ge)、不等于(neq)</li><li>箭头：右箭头(\rightarrow)、左箭头(\leftarrow)、双重右箭头(\Rightarrow)、双重左箭头(\Leftarrow)</li><li>顶部符号：单字符估计(\hat)、多字符估计(\widehat)、均值(\overline)、向量(\vec)</li><li>其他运算符：无穷(\infty)，微分算子(\nabla)，偏导数(\partial)</li></ul><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><ul><li>Typewriter：\mathtt{A}呈现为𝙰, 𝙰𝙱𝙲𝙳𝙴𝙵𝙶𝙷𝙸𝙹𝙺𝙻𝙼𝙽𝙾𝙿𝚀𝚁𝚂𝚃𝚄𝚅𝚆𝚇𝚈𝚉</li><li>Blackboard Bold：\mathbb{A}呈现为𝔸, 𝔸𝔹ℂ𝔻𝔼𝔽𝔾ℍ𝕀𝕁𝕂𝕃𝕄ℕ𝕆ℙℚℝ𝕊𝕋𝕌𝕍𝕎𝕏𝕐ℤ</li><li>Sans Serif：\mathsf{A}呈现为𝖠, 𝖠𝖡𝖢𝖣𝖤𝖥𝖦𝖧𝖨𝖩𝖪𝖫𝖬𝖭𝖮𝖯𝖰𝖱𝖲𝖳𝖴𝖵𝖶𝖷𝖸𝖹</li></ul><h2 id="给公式添加序号"><a href="#给公式添加序号" class="headerlink" title="给公式添加序号"></a>给公式添加序号</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">数学公式\eqno编号</span><br></pre></td></tr></table></figure><h2 id="非常见错误"><a href="#非常见错误" class="headerlink" title="非常见错误"></a>非常见错误</h2><h3 id="无法识别公式内十分少用的符号"><a href="#无法识别公式内十分少用的符号" class="headerlink" title="无法识别公式内十分少用的符号"></a>无法识别公式内十分少用的符号</h3><p>尝试引入包：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\usepackage&#123;amssymb&#125;        % prevent bugs for formula symbol</span><br></pre></td></tr></table></figure></p><blockquote><p>参考与引用</p><ol><li><a href="https://www.cnblogs.com/linxd/p/4955530.html" target="_blank" rel="noopener">https://www.cnblogs.com/linxd/p/4955530.html</a></li><li><a href="https://blog.csdn.net/ethmery/article/details/50670297" target="_blank" rel="noopener">https://blog.csdn.net/ethmery/article/details/50670297</a></li><li><a href="https://www.cnblogs.com/gslyyq/p/5043848.html" target="_blank" rel="noopener">https://www.cnblogs.com/gslyyq/p/5043848.html</a></li><li><a href="https://www.cnblogs.com/dezheng/p/3874434.html" target="_blank" rel="noopener">https://www.cnblogs.com/dezheng/p/3874434.html</a></li><li><a href="https://blog.csdn.net/woniuxyy/article/details/80300322" target="_blank" rel="noopener">https://blog.csdn.net/woniuxyy/article/details/80300322</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Paper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> latex </tag>
            
            <tag> mathjex </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Python常用模块</title>
      <link href="/2017/06/10/Python-module/"/>
      <url>/2017/06/10/Python-module/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="python-logging模块"><a href="#python-logging模块" class="headerlink" title="python logging模块"></a>python logging模块</h2><blockquote><p>  Python引入了logging模块来记录用户想要查看的信息。</p></blockquote><h3 id="日志级别"><a href="#日志级别" class="headerlink" title="日志级别"></a>日志级别</h3><p>当我们执行如下代码：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging  <span class="comment"># 引入logging模块</span></span><br><span class="line"><span class="comment"># 将信息打印到控制台上</span></span><br><span class="line">logging.debug(<span class="string">u"A"</span>)</span><br><span class="line">logging.info(<span class="string">u"B"</span>)</span><br><span class="line">logging.warning(<span class="string">u"C"</span>)</span><br><span class="line">logging.error(<span class="string">u"D"</span>)</span><br><span class="line">logging.critical(<span class="string">u"E"</span>)</span><br></pre></td></tr></table></figure></p><p>控制台的输出结果为：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WARNING:root:C</span><br><span class="line">ERROR:root:D</span><br><span class="line">CRITICAL:root:E</span><br></pre></td></tr></table></figure></p><p>我们会发现控制台只输出了后三个日志，这是因为<strong>默认生成的root logger的level是logging.WARNING,低于该级别的就不输出了</strong>。因此在代码最上方需要<strong>改变日志级别为NOTSET</strong>：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging <span class="comment"># 引入logging模块</span></span><br><span class="line">logging.basciConfig(level=logging.NOTSET) <span class="comment"># 设置日志级别</span></span><br><span class="line">logging.debug(<span class="string">u"如果设置了日志级别为NOTSET,那么这里可以采取debug、info的级别的内容也可以显示在控制台上了"</span>)</span><br></pre></td></tr></table></figure></p><h3 id="控制台日志输出"><a href="#控制台日志输出" class="headerlink" title="控制台日志输出"></a>控制台日志输出</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging  <span class="comment"># 引入logging模块</span></span><br><span class="line">logging.basicConfig(level=logging.DEBUG,format=<span class="string">'%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s'</span>)  <span class="comment"># logging.basicConfig函数对日志的输出格式及方式做相关配置</span></span><br><span class="line"><span class="comment"># 由于日志基本配置中级别设置为DEBUG，所以一下打印信息将会全部显示在控制台上</span></span><br><span class="line">logging.info(<span class="string">'this is a loggging info message'</span>)</span><br><span class="line">logging.debug(<span class="string">'this is a loggging debug message'</span>)</span><br><span class="line">logging.warning(<span class="string">'this is loggging a warning message'</span>)</span><br><span class="line">logging.error(<span class="string">'this is an loggging error message'</span>)</span><br><span class="line">logging.critical(<span class="string">'this is a loggging critical message'</span>)</span><br></pre></td></tr></table></figure><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/python_model_1.png" alt=""></p><h3 id="日志文件输出"><a href="#日志文件输出" class="headerlink" title="日志文件输出"></a>日志文件输出</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> logging  <span class="comment"># 引入logging模块</span></span><br><span class="line"><span class="keyword">import</span> os.path</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="comment"># 第一步，创建一个logger</span></span><br><span class="line">logger = logging.getLogger()</span><br><span class="line">logger.setLevel(logging.INFO)  <span class="comment"># Log等级总开关</span></span><br><span class="line"><span class="comment"># 第二步，创建一个handler，用于写入日志文件</span></span><br><span class="line">rq = time.strftime(<span class="string">'%Y%m%d%H%M'</span>, time.localtime(time.time()))</span><br><span class="line">log_path = os.path.dirname(os.getcwd()) + <span class="string">'/Logs/'</span></span><br><span class="line">log_name = log_path + rq + <span class="string">'.log'</span></span><br><span class="line">logfile = log_name</span><br><span class="line">fh = logging.FileHandler(logfile, mode=<span class="string">'w'</span>)</span><br><span class="line">fh.setLevel(logging.DEBUG)  <span class="comment"># 输出到file的log等级的开关</span></span><br><span class="line"><span class="comment"># 第三步，定义handler的输出格式</span></span><br><span class="line">formatter = logging.Formatter(<span class="string">"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s"</span>)</span><br><span class="line">fh.setFormatter(formatter)</span><br><span class="line"><span class="comment"># 第四步，将logger添加到handler里面</span></span><br><span class="line">logger.addHandler(fh)</span><br><span class="line"><span class="comment"># 日志</span></span><br><span class="line">logger.debug(<span class="string">'this is a logger debug message'</span>)</span><br><span class="line">logger.info(<span class="string">'this is a logger info message'</span>)</span><br><span class="line">logger.warning(<span class="string">'this is a logger warning message'</span>)</span><br><span class="line">logger.error(<span class="string">'this is a logger error message'</span>)</span><br><span class="line">logger.critical(<span class="string">'this is a logger critical message'</span>)</span><br></pre></td></tr></table></figure><h2 id="python单元测试框架-unittest"><a href="#python单元测试框架-unittest" class="headerlink" title="python单元测试框架-unittest"></a>python单元测试框架-unittest</h2><h3 id="unittest最核心的原理"><a href="#unittest最核心的原理" class="headerlink" title="unittest最核心的原理"></a>unittest最核心的原理</h3><ul><li>TestCase:测试用例<ul><li>setUP:测试前准备环境的搭建</li><li>run:执行测试代码</li><li>tearDown:测试后环境的还原</li></ul></li><li>TestSuite：多个测试用例的集合</li><li>TestLoader：加载TestCase到TestSuite中</li><li>TextTestRunner：执行测试用例，并且把结果保存在TextTestResult之中</li><li>test fixture：对测试用例环境的搭建和销毁</li></ul><h3 id="基本使用方法"><a href="#基本使用方法" class="headerlink" title="基本使用方法"></a>基本使用方法</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> unnittest</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下定义四个函数进行单元测试</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a+b</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minus</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a-b</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a*b</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">divide</span><span class="params">(a, b)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> a/b</span><br><span class="line"><span class="comment"># 是时候展现真正的(unittest)技术了:单元测试主体部分</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestMathFunc</span><span class="params">(unittest.TestCase)</span>:</span></span><br><span class="line">    <span class="string">"""Test mathfuc.py"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_add</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Test method add(a, b)"""</span></span><br><span class="line">        self.assertEqual(<span class="number">3</span>, add(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        self.assertNotEqual(<span class="number">3</span>, add(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_minus</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Test method minus(a, b)"""</span></span><br><span class="line">        self.assertEqual(<span class="number">1</span>, minus(<span class="number">3</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_multi</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Test method multi(a, b)"""</span></span><br><span class="line">        self.assertEqual(<span class="number">6</span>, multi(<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">test_divide</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="string">"""Test method divide(a, b)"""</span></span><br><span class="line">        self.assertEqual(<span class="number">2</span>, divide(<span class="number">6</span>, <span class="number">3</span>))</span><br><span class="line">        self.assertEqual(<span class="number">2.5</span>, divide(<span class="number">5</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    unittest.main()</span><br><span class="line"><span class="string">"""执行结果为：</span></span><br><span class="line"><span class="string">.F..</span></span><br><span class="line"><span class="string">======================================================================</span></span><br><span class="line"><span class="string">FAIL: test_divide (__main__.TestMathFunc)</span></span><br><span class="line"><span class="string">Test method divide(a, b)</span></span><br><span class="line"><span class="string">----------------------------------------------------------------------</span></span><br><span class="line"><span class="string">Traceback (most recent call last):</span></span><br><span class="line"><span class="string">  File "D:/py/test_mathfunc.py", line 26, in test_divide</span></span><br><span class="line"><span class="string">    self.assertEqual(2.5, divide(5, 2))</span></span><br><span class="line"><span class="string">AssertionError: 2.5 != 2</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">----------------------------------------------------------------------</span></span><br><span class="line"><span class="string">Ran 4 tests in 0.000s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">FAILED (failures=1)</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure><ul><li>在第一行给出了每一个用例执行的结果的标识，成功是 .，失败是 F，出错是 E，跳过是 S。从上面也可以看出，测试的执行跟方法的顺序没有关系，test_divide写在了第4个，但是却是第2个执行的。</li><li>每个测试方法均以 test 开头，否则是不被unittest识别的。</li></ul><h3 id="进阶：TestSuite-组织测试"><a href="#进阶：TestSuite-组织测试" class="headerlink" title="进阶：TestSuite(组织测试)"></a>进阶：TestSuite(组织测试)</h3><blockquote><p>将程序按照添加的顺序来执行。此处只需针对上文的main函数进行改进</p></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    suite = unittest.TestSuite()</span><br><span class="line"></span><br><span class="line">    tests = [TestMathFunc(<span class="string">"test_add"</span>), TestMathFunc(<span class="string">"test_minus"</span>), TestMathFunc(<span class="string">"test_divide"</span>)]</span><br><span class="line">    suite.addTests(tests)</span><br><span class="line"></span><br><span class="line">    runner = unittest.TextTestRunner(verbosity=<span class="number">2</span>)</span><br><span class="line">    runner.run(suite)</span><br></pre></td></tr></table></figure><h3 id="进阶：准备测试环境"><a href="#进阶：准备测试环境" class="headerlink" title="进阶：准备测试环境"></a>进阶：准备测试环境</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TestMathFunc</span><span class="params">(unittest.TestCase)</span>:</span></span><br><span class="line">    <span class="string">"""Test mathfuc.py"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUp</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"do something before test.Prepare environment."</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tearDown</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"do something after test.Clean up."</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">setUpClass</span><span class="params">(cls)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"This setUpClass() method only called once."</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @classmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">tearDownClass</span><span class="params">(cls)</span>:</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"This tearDownClass() method only called once too."</span></span><br></pre></td></tr></table></figure><ul><li>这两个方法在每个测试方法执行前以及执行后执行一次，<code>setUp</code>用来为测试准备环境，<code>tearDown</code>用来清理环境，已备之后的测试。</li><li>如果想要在所有case执行之前准备一次环境，并在所有case执行结束之后再清理环境，我们可以用 <code>setUpClass()</code>与<code>tearDownClass()</code></li></ul><h2 id="os模块与sys的模块"><a href="#os模块与sys的模块" class="headerlink" title="os模块与sys的模块"></a>os模块与sys的模块</h2><h3 id="os模块与sys模块的区分"><a href="#os模块与sys模块的区分" class="headerlink" title="os模块与sys模块的区分"></a>os模块与sys模块的区分</h3><blockquote><p>os模块：提供了一种方便使用操作系统函数的方法</p></blockquote><blockquote><p>sys模块：提供访问由解释器使用或维护的变量和在与解释器交互使用到的函数 </p></blockquote><h3 id="os模块常用方法"><a href="#os模块常用方法" class="headerlink" title="os模块常用方法"></a>os模块常用方法</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">os.remove()删除文件  </span><br><span class="line">os.rename()重命名文件  </span><br><span class="line">os.walk()生成目录树下的所有文件名  </span><br><span class="line">os.chdir()改变目录  </span><br><span class="line">os.mkdir/makedirs创建目录/多层目录  </span><br><span class="line">os.rmdir/removedirs删除目录/多层目录  </span><br><span class="line">os.listdir()列出指定目录的文件  </span><br><span class="line">os.getcwd()取得当前工作目录  </span><br><span class="line">os.chmod()改变目录权限  </span><br><span class="line">os.path.basename()去掉目录路径，返回文件名  </span><br><span class="line">os.path.dirname()去掉文件名，返回目录路径  </span><br><span class="line">os.path.join()将分离的各部分组合成一个路径名  </span><br><span class="line">os.path.split()返回（dirname(),basename())元组  </span><br><span class="line">os.path.splitext()(返回filename,extension)元组  </span><br><span class="line">os.path.getatime\ctime\mtime分别返回最近访问、创建、修改时间  </span><br><span class="line">os.path.getsize()返回文件大小  </span><br><span class="line">os.path.exists()是否存在  </span><br><span class="line">os.path.isabs()是否为绝对路径  </span><br><span class="line">os.path.isdir()是否为目录  </span><br><span class="line">os.path.isfile()是否为文件</span><br></pre></td></tr></table></figure><h2 id="sys模块常用方法："><a href="#sys模块常用方法：" class="headerlink" title="sys模块常用方法："></a>sys模块常用方法：</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">sys.argv           命令行参数List，第一个元素是程序本身路径   </span><br><span class="line">sys.modules.keys() 返回所有已经导入的模块列表   </span><br><span class="line">sys.exc_info()     获取当前正在处理的异常类,exc_type、exc_value、exc_traceback当前处理的异常详细信息   </span><br><span class="line">sys.exit(n)        退出程序，正常退出时exit(<span class="number">0</span>)   </span><br><span class="line">sys.hexversion     获取Python解释程序的版本值，<span class="number">16</span>进制格式如：<span class="number">0x020403F0</span>   </span><br><span class="line">sys.version        获取Python解释程序的版本信息   </span><br><span class="line">sys.maxint         最大的Int值   </span><br><span class="line">sys.maxunicode     最大的Unicode值   </span><br><span class="line">sys.modules        返回系统导入的模块字段，key是模块名，value是模块   </span><br><span class="line">sys.path           返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值   </span><br><span class="line">sys.platform       返回操作系统平台名称   </span><br><span class="line">sys.stdout         标准输出  </span><br><span class="line">sys.stdin          标准输入  </span><br><span class="line">sys.stderr         错误输出  </span><br><span class="line">sys.exc_clear()    用来清除当前线程所出现的当前的或最近的错误信息  </span><br><span class="line">sys.exec_prefix    返回平台独立的python文件安装的位置  </span><br><span class="line">sys.byteorder      本地字节规则的指示器，big-endian平台的值是<span class="string">'big'</span>,little-endian平台的值是<span class="string">'little'</span>  </span><br><span class="line">sys.copyright      记录python版权相关的东西  </span><br><span class="line">sys.api_version    解释器的C的API版本  </span><br><span class="line">sys.version_info</span><br></pre></td></tr></table></figure><h2 id="关于时间的模块"><a href="#关于时间的模块" class="headerlink" title="关于时间的模块"></a>关于时间的模块</h2><h3 id="datetime模块获取当前时间"><a href="#datetime模块获取当前时间" class="headerlink" title="datetime模块获取当前时间"></a>datetime模块获取当前时间</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">nowTime = datatime.datatime.now().strftime(<span class="string">'%Y-%m-%d %H:%M:%S'</span>) <span class="comment"># 现在</span></span><br></pre></td></tr></table></figure><h2 id="retry模块"><a href="#retry模块" class="headerlink" title="retry模块"></a>retry模块</h2><p>使用场景通常是在网络情况不太稳定时，预防超时异常<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> retrying <span class="keyword">import</span> retry</span><br><span class="line"></span><br><span class="line"><span class="meta">@retry</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_something_unreliable</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">if</span> random.randint(<span class="number">0</span>, <span class="number">10</span>) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">raise</span> IOError(<span class="string">"Broken sauce, everything is hosed!!!111one"</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"Awesome sauce!"</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> do_something_unreliable()</span><br></pre></td></tr></table></figure></p><p>以上是官方文档的代码：给函数添加@retry装饰器后，只要有异常，那么函数会不断地重试，直到有返回值。<br>下面是几个常常传入装饰器的参数<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 最多尝试7次，这个最常用！</span></span><br><span class="line"><span class="meta">@retry(stop_max_attempt_number=7)</span></span><br><span class="line"><span class="comment"># 最长等待10秒</span></span><br><span class="line"><span class="meta">@retry(stop_max_delay=10000)</span></span><br></pre></td></tr></table></figure></p><h2 id="timeit"><a href="#timeit" class="headerlink" title="timeit"></a>timeit</h2><p>专门用来测试代码的运行时间，运行十分方便：<br>    实例化<code>Timer</code>类需要两个参数，第一个参数为你需要计算运行时间的函数，类型为字符串；第二个参数为构建环境的导入语句，类型也为字符串。</p><h3 id="例子1"><a href="#例子1" class="headerlink" title="例子1"></a>例子1</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用来计算运行时间的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test1</span><span class="params">()</span>:</span></span><br><span class="line">    n = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">101</span>):</span><br><span class="line">        n += i</span><br><span class="line">    <span class="keyword">return</span> n</span><br><span class="line"><span class="keyword">from</span> timeit <span class="keyword">import</span> Timer</span><br><span class="line"><span class="comment"># 实例化</span></span><br><span class="line">t = Timer(<span class="string">"test1()"</span>, <span class="string">"from __main__ import test1"</span>)</span><br><span class="line"><span class="keyword">print</span> t.timeit()</span><br><span class="line"><span class="keyword">print</span> t.repeat(<span class="number">3</span>, <span class="number">10000</span>) <span class="comment"># 执行测试三次</span></span><br></pre></td></tr></table></figure><h2 id="glob"><a href="#glob" class="headerlink" title="glob"></a>glob</h2><p>glob是python自己带的一个文件操作相关模块，用它可以查找符合自己目的的文件，支持<strong>通配符操作</strong>: <code></code> <code>?</code> <code>[]]</code>这三个通配符，<code></code>代表0个或多个字符，<code>?</code>代表一个字符，<code>[]</code>匹配指定范围内的字符，如[0-9]匹配数字。主要方法如下.</p><h3 id="glob方法：返回所有匹配的文件路径列表"><a href="#glob方法：返回所有匹配的文件路径列表" class="headerlink" title="glob方法：返回所有匹配的文件路径列表"></a>glob方法：返回所有匹配的文件路径列表</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">glob.glob(<span class="string">r'C:*.txt'</span>) <span class="comment"># 获取C盘下的所有txt文件</span></span><br><span class="line">glog.glob(<span class="string">r'../*.py'</span>) <span class="comment"># 获取相对路径下的python文件</span></span><br></pre></td></tr></table></figure><h2 id="PIL"><a href="#PIL" class="headerlink" title="PIL"></a>PIL</h2><p>PIL：Python Imaging Library，已经是Python平台事实上的图像处理标准库了。PIL功能非常强大，但API却非常简单易用。</p><h3 id="诡异的安装方式"><a href="#诡异的安装方式" class="headerlink" title="诡异的安装方式"></a>诡异的安装方式</h3><p><code>pip install pillow</code></p><h3 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a>基本操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im = Image.open(<span class="string">'path/to/Image.jpg'</span>) <span class="comment"># 打开图像文件</span></span><br><span class="line">w, h = im.size <span class="comment"># 获取图片尺寸</span></span><br><span class="line">im.thumbnail((w//<span class="number">2</span>, h//<span class="number">2</span>)) <span class="comment"># 缩放图片到50%</span></span><br><span class="line">im.save(<span class="string">'path/to/Image.jpg'</span>, <span class="string">'jpeg'</span>) <span class="comment"># 保存图片格式为jpeg</span></span><br></pre></td></tr></table></figure><h2 id="matplotlib"><a href="#matplotlib" class="headerlink" title="matplotlib"></a>matplotlib</h2><h1 id="在远端服务器利用matplotlib绘图"><a href="#在远端服务器利用matplotlib绘图" class="headerlink" title="在远端服务器利用matplotlib绘图"></a>在远端服务器利用matplotlib绘图</h1><p>在<code>import matplotlib.pyplot</code><strong>之前</strong>加上:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib <span class="keyword">as</span> mpl</span><br><span class="line">mpl.use(<span class="string">'Agg'</span>)</span><br></pre></td></tr></table></figure></p><p>在<code>plt.draw</code><strong>之后</strong>加上:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.savefig(<span class="string">"/path/to/pic.jpg"</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>引用与参考资料</p><ol><li>logging:<a href="https://www.cnblogs.com/CJOKER/p/8295272.html" target="_blank" rel="noopener">https://www.cnblogs.com/CJOKER/p/8295272.html</a></li><li>unittest:<a href="https://blog.csdn.net/huilan_same/article/details/52944782#t4" target="_blank" rel="noopener">https://blog.csdn.net/huilan_same/article/details/52944782#t4</a></li><li><a href="https://my.oschina.net/liuyuantao/blog/755907" target="_blank" rel="noopener">https://my.oschina.net/liuyuantao/blog/755907</a></li><li><a href="https://blog.csdn.net/u010472607/article/details/76857493/" target="_blank" rel="noopener">https://blog.csdn.net/u010472607/article/details/76857493/</a></li><li><a href="https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/00140767171357714f87a053a824ffd811d98a83b58ec13000" target="_blank" rel="noopener">https://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/00140767171357714f87a053a824ffd811d98a83b58ec13000</a></li><li><a href="https://blog.csdn.net/i_is_a_energy_man/article/details/77833040" target="_blank" rel="noopener">https://blog.csdn.net/i_is_a_energy_man/article/details/77833040</a></li><li><a href="https://blog.csdn.net/zzytmxk/article/details/53402257" target="_blank" rel="noopener">https://blog.csdn.net/zzytmxk/article/details/53402257</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Python </category>
          
      </categories>
      
      
        <tags>
            
            <tag> logging </tag>
            
            <tag> unittest </tag>
            
            <tag> datetime </tag>
            
            <tag> retry </tag>
            
            <tag> os </tag>
            
            <tag> timeit </tag>
            
            <tag> glob </tag>
            
            <tag> PIL </tag>
            
            <tag> pickle </tag>
            
            <tag> matplotlib </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Git使用备忘录</title>
      <link href="/2017/04/16/Git-usage/"/>
      <url>/2017/04/16/Git-usage/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="指令速查"><a href="#指令速查" class="headerlink" title="指令速查"></a>指令速查</h2><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/git_command_1.png" alt=""></p><h2 id="雷区勿踩"><a href="#雷区勿踩" class="headerlink" title="雷区勿踩"></a>雷区勿踩</h2><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/git_command_2.png" alt=""></p><hr><h2 id="常见错误和小技巧"><a href="#常见错误和小技巧" class="headerlink" title="常见错误和小技巧"></a>常见错误和小技巧</h2><h3 id="git-pull失败-提示：fatal-refusing-to-merge-unrelated-histories"><a href="#git-pull失败-提示：fatal-refusing-to-merge-unrelated-histories" class="headerlink" title="git pull失败,提示：fatal: refusing to merge unrelated histories"></a>git pull失败,提示：fatal: refusing to merge unrelated histories</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git pull origin master --allow-unrelated-histories</span><br><span class="line"><span class="meta">#</span>之后再</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure><h3 id="git-add-添加文件夹而非全部修改文件"><a href="#git-add-添加文件夹而非全部修改文件" class="headerlink" title="git add 添加文件夹而非全部修改文件"></a>git add 添加文件夹而非全部修改文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 添加整个文件夹及内容</span><br><span class="line">git add yourfile/</span><br><span class="line"><span class="meta">#</span> 添加目录中所有此文件类型的文件</span><br><span class="line">git add *.your_文件类型</span><br></pre></td></tr></table></figure><h3 id="与fork别人的仓库保持同步"><a href="#与fork别人的仓库保持同步" class="headerlink" title="与fork别人的仓库保持同步"></a>与fork别人的仓库保持同步</h3><ol><li><p>将fork的项目添加到remote中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git remote add your_forked_project_name(whatever you like) https://your_forked_project_url.git</span><br></pre></td></tr></table></figure></li><li><p>更新remote中所有远程repo</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git fetch --all</span><br></pre></td></tr></table></figure></li><li><p>进行同步</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git rebase your_forked_project_name/master</span><br></pre></td></tr></table></figure></li><li><p>将自己的远程仓库也同步</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin master</span><br></pre></td></tr></table></figure></li></ol><h3 id="处理-github-不允许上传超过-100MB-文件的问题"><a href="#处理-github-不允许上传超过-100MB-文件的问题" class="headerlink" title="处理 github 不允许上传超过 100MB 文件的问题"></a>处理 github 不允许上传超过 100MB 文件的问题</h3><h4 id="移除错误缓存"><a href="#移除错误缓存" class="headerlink" title="移除错误缓存"></a>移除错误缓存</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for file</span></span><br><span class="line">git rm --cached path_of_a_giant_file</span><br><span class="line"><span class="comment"># for document</span></span><br><span class="line">git rm --cached -r path_of_a_giant_file</span><br></pre></td></tr></table></figure><h4 id="重新提交后将大文件加入-Git-Large-File-Stroage"><a href="#重新提交后将大文件加入-Git-Large-File-Stroage" class="headerlink" title="重新提交后将大文件加入 Git Large File Stroage:"></a>重新提交后将大文件加入 Git Large File Stroage:</h4><ol><li>安装git-lfs: <code>brew install git-lfs</code></li><li>在repository的根目录初始化：<code>git lfs install</code></li><li>跟踪<strong>大文件名</strong>： <code>git lfs track &quot;name_of_your_giant_file_not_your_path!&quot;</code></li><li>正常提交推送：<code>git add your_giant_file_path</code></li><li>搜索大文件：<code>find ./ -size +100M</code></li></ol><h3 id="git-commit后想要撤销到上一个commit"><a href="#git-commit后想要撤销到上一个commit" class="headerlink" title="git commit后想要撤销到上一个commit"></a>git commit后想要撤销到上一个commit</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --soft HEAD^</span><br></pre></td></tr></table></figure><h3 id="git-push-提交代码时writing-objects特别慢解决方案"><a href="#git-push-提交代码时writing-objects特别慢解决方案" class="headerlink" title="git push 提交代码时writing objects特别慢解决方案"></a>git push 提交代码时writing objects特别慢解决方案</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.postBuffer 524288000</span><br></pre></td></tr></table></figure><blockquote><p>引用参考资料和版权说明</p><ol><li><a href="http://www.git-tower.com/blog/git-cheat-sheet-cn" target="_blank" rel="noopener">http://www.git-tower.com/blog/git-cheat-sheet-cn</a></li><li><a href="https://blog.csdn.net/wxs0124/article/details/50126953" target="_blank" rel="noopener">https://blog.csdn.net/wxs0124/article/details/50126953</a></li><li><a href="http://stackoverflow.com/questions/37937984/git-refusing-to-merge-unrelated-histories" target="_blank" rel="noopener">http://stackoverflow.com/questions/37937984/git-refusing-to-merge-unrelated-histories</a></li><li><a href="https://blog.csdn.net/xinqingwuji/article/details/79391453" target="_blank" rel="noopener">https://blog.csdn.net/xinqingwuji/article/details/79391453</a></li><li><a href="https://www.cnblogs.com/-walker/p/7278951.html" target="_blank" rel="noopener">https://www.cnblogs.com/-walker/p/7278951.html</a></li><li><a href="https://blog.csdn.net/smart_graphics/article/details/78475735" target="_blank" rel="noopener">https://blog.csdn.net/smart_graphics/article/details/78475735</a></li><li><a href="http://www.liuxiao.org/2017/02/git-%E5%A4%84%E7%90%86-github-%E4%B8%8D%E5%85%81%E8%AE%B8%E4%B8%8A%E4%BC%A0%E8%B6%85%E8%BF%87-100mb-%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener">http://www.liuxiao.org/2017/02/git-%E5%A4%84%E7%90%86-github-%E4%B8%8D%E5%85%81%E8%AE%B8%E4%B8%8A%E4%BC%A0%E8%B6%85%E8%BF%87-100mb-%E6%96%87%E4%BB%B6%E7%9A%84%E9%97%AE%E9%A2%98/</a></li><li><a href="https://blog.csdn.net/w958796636/article/details/53611133" target="_blank" rel="noopener">https://blog.csdn.net/w958796636/article/details/53611133</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> git </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用命令</title>
      <link href="/2017/04/03/Linux-command/"/>
      <url>/2017/04/03/Linux-command/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Linux基本命令"><a href="#Linux基本命令" class="headerlink" title="Linux基本命令"></a>Linux基本命令</h2><h3 id="cd命令"><a href="#cd命令" class="headerlink" title="cd命令"></a>cd命令</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据绝对路径，切换到目录/root/Docements  </span></span><br><span class="line">cd /root/Docements </span><br><span class="line"><span class="comment"># 根据相对路径，切换到当前目录下的path目录中，“.”表示当前目录 </span></span><br><span class="line">cd ./path</span><br><span class="line"><span class="comment"># 返回上一级目录</span></span><br><span class="line">cd ..</span><br></pre></td></tr></table></figure><h3 id="ls命令"><a href="#ls命令" class="headerlink" title="ls命令"></a>ls命令</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看文件与目录的命令</span></span><br><span class="line">ls</span><br><span class="line"><span class="comment"># 列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来</span></span><br><span class="line">ls -a</span><br><span class="line"><span class="comment"># 列出全部的文件，包含文件的属性与权限数据</span></span><br><span class="line">ls -l</span><br></pre></td></tr></table></figure><h3 id="grep命令"><a href="#grep命令" class="headerlink" title="grep命令"></a>grep命令</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 用于搜索过滤文件中的数据</span></span><br><span class="line">grep [-aciv] [--color=auto] <span class="string">'待查找字符串'</span> filename</span><br></pre></td></tr></table></figure><h4 id="常用参数解释："><a href="#常用参数解释：" class="headerlink" title="常用参数解释："></a>常用参数解释：</h4><ul><li>-a ：将binary文件以text文件的方式查找数据  </li><li>-c ：计算找到‘查找字符串’的次数  </li><li>-i ：忽略大小写的区别，即把大小写视为相同  </li><li>-v ：反向选择，即显示出没有‘查找字符串’内容的那一行  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 例如：  </span></span><br><span class="line"><span class="comment"># 取出文件/etc/man.config中包含MANPATH的行，并把找到的关键字加上颜色  </span></span><br><span class="line">grep --color=auto <span class="string">'MANPATH'</span> /etc/man.config  </span><br><span class="line"><span class="comment"># 把ls -l的输出中包含字母file（不区分大小写）的内容输出  </span></span><br><span class="line">ls -l | grep -i file</span><br></pre></td></tr></table></figure></li></ul><h3 id="cp命令"><a href="#cp命令" class="headerlink" title="cp命令"></a>cp命令</h3><blockquote><p>复制文件命令，常用参数如下</p><ul><li>-a ：将文件的特性一起复制  </li><li>-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份  </li><li>-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行  </li><li>-r ：递归持续复制，用于目录的复制行为  </li><li>-u ：目标文件与源文件有差异时才会复制 </li></ul></blockquote><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp -a file1 file2 <span class="comment">#连同文件的所有特性把文件file1复制成文件file2  </span></span><br><span class="line">cp -r file1 file2 file3 dir <span class="comment">#把文件file1、file2、file3递归复制到目录dir中</span></span><br></pre></td></tr></table></figure><h3 id="mv命令"><a href="#mv命令" class="headerlink" title="mv命令"></a>mv命令</h3><blockquote><p>重命名文件使用方式<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv file1 file2 <span class="comment"># 把文件file1重命名为file2</span></span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>把一个文件或者多个文件一次移动到一个文件夹中（最后一个目标文件一定是目录）<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv file1 file2 file3 dir <span class="comment"># 把文件file1、file2、file3移动到目录dir中</span></span><br></pre></td></tr></table></figure></p></blockquote><h3 id="rm命令（小心使用！！！！！！）"><a href="#rm命令（小心使用！！！！！！）" class="headerlink" title="rm命令（小心使用！！！！！！）"></a>rm命令（小心使用！！！！！！）</h3><blockquote><p>删除文件或者目录，常用参数</p><ul><li>-f ：就是force的意思，忽略不存在的文件，不会出现警告消息  </li><li>-i ：互动模式，在删除前会询问用户是否操作  </li><li>-r ：递归删除，最常用于目录删除，它是一个非常危险的参数  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -i file <span class="comment"># 删除文件file，在删除之前会询问是否进行该操作  </span></span><br><span class="line">rm -fr dir <span class="comment"># 强制删除目录dir中的所有文件</span></span><br></pre></td></tr></table></figure></li></ul></blockquote><h3 id="ps命令"><a href="#ps命令" class="headerlink" title="ps命令"></a>ps命令</h3><blockquote><p>查看进行巡行情况，该命令与其他命令的常用搭配如下<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ps aux <span class="comment"># 查看系统所有的进程数据  </span></span><br><span class="line">ps ax <span class="comment"># 查看不与terminal有关的所有进程  </span></span><br><span class="line">ps -lA <span class="comment"># 查看系统所有的进程数据  </span></span><br><span class="line">ps axjf <span class="comment"># 查看连同一部分进程树状态  </span></span><br><span class="line">ps aux| grep -ic python <span class="comment">#　查看系统中所有关于python的进程</span></span><br></pre></td></tr></table></figure></p></blockquote><h3 id="kill命令"><a href="#kill命令" class="headerlink" title="kill命令"></a>kill命令</h3><blockquote><p>对进程发送信号，常用signal如下（使用时可以用代号代替相应的信号）</p><ul><li>1：SIGHUP，启动被终止的进程  </li><li>2：SIGINT，相当于输入ctrl+c，中断一个程序的进行  </li><li>9：SIGKILL，强制中断一个进程的进行  </li><li>15：SIGTERM，以正常的结束进程方式来终止进程  </li><li>17：SIGSTOP，相当于输入ctrl+z，暂停一个进程的进行<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kill -signal PID</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以正常的结束进程方式来终于第一个后台工作，可用jobs命令查看后台中的第一个工作进程 </span></span><br><span class="line">kill -SIGTERM %<span class="number">1</span>   </span><br><span class="line"><span class="comment"># 重新改动进程ID为PID的进程，PID可用ps命令通过管道命令加上grep命令进行筛选获得  </span></span><br><span class="line">kill -SIGHUP PID</span><br></pre></td></tr></table></figure></li></ul></blockquote><h3 id="tar命令"><a href="#tar命令" class="headerlink" title="tar命令"></a>tar命令</h3><blockquote><p>对文件进行打包默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压。它的常用参数如下：</p><ul><li>-c ：新建打包文件  </li><li>-t ：查看打包文件的内容含有哪些文件名  </li><li>-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中  </li><li>-j ：通过bzip2的支持进行压缩/解压缩  </li><li>-z ：通过gzip的支持进行压缩/解压缩  </li><li>-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来  </li><li>-f filename ：filename为要处理的文件  </li><li>-C dir ：指定压缩/解压缩的目录dir <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通常我们只需要使用如下三条命令：</span></span><br><span class="line">压缩：tar -jcv -f filename 要被处理的文件或目录名称  </span><br><span class="line">查询：tar -jtv -f filename</span><br><span class="line">解压：tar -jxv -f filename -C 欲解压缩的目录</span><br></pre></td></tr></table></figure></li></ul></blockquote><h3 id="cat命令"><a href="#cat命令" class="headerlink" title="cat命令"></a>cat命令</h3><blockquote><p>查看文本文件内容<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat test|less <span class="comment"># 查看text文件中的内容</span></span><br></pre></td></tr></table></figure></p></blockquote><h3 id="chgrp-chown命令"><a href="#chgrp-chown命令" class="headerlink" title="chgrp/chown命令"></a>chgrp/chown命令</h3><blockquote><p>改变用户所述用户组/改变文件的所有者<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chgrp/chown users -R ./dir <span class="comment"># 递归地把dir目录下中的所有文件和子目录下所有文件的用户组修改为users</span></span><br></pre></td></tr></table></figure></p></blockquote><h3 id="chmod命令"><a href="#chmod命令" class="headerlink" title="chmod命令"></a>chmod命令</h3><blockquote><p>改变文件的权限<br>常用权限表示形式:</p><ul><li>-rw——- (600)      只有拥有者有读写权限。</li><li>-rw-r–r– (644)      只有拥有者有读写权限；而属组用户和其他用户只有读权限。</li><li>-rwx—— (700)     只有拥有者有读、写、执行权限。</li><li>-rwxr-xr-x (755)    拥有者有读、写、执行权限；而属组用户和其他用户只有读、执行权限。</li><li>-rwx–x–x (711)    拥有者有读、写、执行权限；而属组用户和其他用户只有执行权限。</li><li>-rw-rw-rw- (666)   所有用户都有文件读、写权限。</li><li>-rwxrwxrwx (777)  所有用户都有读、写、执行权限。<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod -R <span class="number">777</span> file <span class="comment">#　将file设置为最高权限</span></span><br></pre></td></tr></table></figure></li></ul></blockquote><h3 id="查看系统的配置"><a href="#查看系统的配置" class="headerlink" title="查看系统的配置"></a>查看系统的配置</h3><blockquote><p>打开/proc目录查看系统硬件配置<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 查看cpu信息</span></span><br><span class="line">cat /proc/cpuinfo</span><br><span class="line"><span class="comment">// 查看内存</span></span><br><span class="line"><span class="built_in">free</span> -m</span><br><span class="line"><span class="comment">// 查看硬盘空间</span></span><br><span class="line">df -h</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="Linux更高层命令"><a href="#Linux更高层命令" class="headerlink" title="Linux更高层命令"></a>Linux更高层命令</h2><h3 id="curl命令"><a href="#curl命令" class="headerlink" title="curl命令"></a>curl命令</h3><blockquote><p>http命令行工具，支持文件的上传与下载。</p></blockquote><h4 id="其基本语法为："><a href="#其基本语法为：" class="headerlink" title="其基本语法为："></a>其基本语法为：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl [option] [url]</span><br></pre></td></tr></table></figure><h4 id="其常用使用方法为："><a href="#其常用使用方法为：" class="headerlink" title="其常用使用方法为："></a>其常用使用方法为：</h4><ol><li><p>测试</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://www.linux.com // 测试服务器与网站的连通性</span><br></pre></td></tr></table></figure></li><li><p>下载</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -o filename http_url // 下载url的文件并保存名为filename</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -O -u user_name:password ftp_url // 根据user_name和password下载ftp_url的文件</span><br></pre></td></tr></table></figure><ol start="3"><li><p>上传文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -T upload_file -u user_name:password ftp_url // 根据user_name和password上传file到url</span><br></pre></td></tr></table></figure></li><li><p>查看公网ip</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl ifconfig.me 或者 curl cip.cc</span><br></pre></td></tr></table></figure></li></ol><h3 id="查看当前GPU使用情况"><a href="#查看当前GPU使用情况" class="headerlink" title="查看当前GPU使用情况"></a>查看当前GPU使用情况</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvdia-smi</span><br></pre></td></tr></table></figure><h4 id="使用指定GPU运行程序"><a href="#使用指定GPU运行程序" class="headerlink" title="使用指定GPU运行程序"></a>使用指定GPU运行程序</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CUDA_VISIBLE_DEVICES=&#123;&#123;number of interface&#125;&#125; python &#123;&#123;file&#125;&#125;.py</span><br><span class="line"> ```   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 服务器间文件的传输（scp命令）</span></span><br><span class="line">&gt; 服务器其实就是电脑的意思，两个可以等价替换；&#123;&#123;&#125;&#125;代表你需要修改的参数</span><br><span class="line"><span class="comment">#### 复制远程服务器的文件到本地服务器</span></span><br><span class="line">```py</span><br><span class="line">scp -r &#123;&#123;远程服务器名称&#125;&#125;@&#123;&#123;远程服务器ip&#125;&#125;:&#123;&#123;远程服务器目录&#125;&#125; &#123;&#123;本地服务器目录&#125;&#125;</span><br></pre></td></tr></table></figure><h4 id="将本地服务器的文件上传到远端服务器"><a href="#将本地服务器的文件上传到远端服务器" class="headerlink" title="将本地服务器的文件上传到远端服务器"></a>将本地服务器的文件上传到远端服务器</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp -r &#123;&#123;本地服务器目录&#125;&#125; &#123;&#123;远程服务器名称&#125;&#125;@&#123;&#123;远程服务器ip&#125;&#125;:&#123;&#123;远程服务器目录&#125;&#125;</span><br></pre></td></tr></table></figure><h4 id="备注：scp常用命令参数"><a href="#备注：scp常用命令参数" class="headerlink" title="备注：scp常用命令参数"></a>备注：scp常用命令参数</h4><ul><li>-r  递归复制整个目录。</li><li>-P port  注意是大写的P,port是指定数据传输用到的端口号</li></ul><h4 id="scp命令常见问题"><a href="#scp命令常见问题" class="headerlink" title="scp命令常见问题"></a>scp命令常见问题</h4><blockquote><p>WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED解决方法</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.ssh/known_hosts</span><br><span class="line">删除与无法识别的服务器的相关rsa的信息即可.</span><br></pre></td></tr></table></figure><h3 id="ssh命令"><a href="#ssh命令" class="headerlink" title="ssh命令"></a>ssh命令</h3><blockquote><p>远程登录Linux主机</p></blockquote><p>最常用命令<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ssh -p port user_name@hostname <span class="comment">// 在port端口指定用户登录host</span></span><br><span class="line"></span><br><span class="line">servive sshd restart <span class="comment">// 重启sshd服务</span></span><br><span class="line"></span><br><span class="line">vim /etc/ssh/sshd_config <span class="comment">//修改配置文件的端口号和其他配置</span></span><br></pre></td></tr></table></figure></p><h3 id="用户相关命令"><a href="#用户相关命令" class="headerlink" title="用户相关命令"></a>用户相关命令</h3><h4 id="在root账户下："><a href="#在root账户下：" class="headerlink" title="在root账户下："></a>在root账户下：</h4><ul><li>useradd user_name 创建用户user_name</li><li>passwd user_name 给用户user_name设置密码</li><li>userdel user_name 删除用户user_name</li><li>su user_name 切换到（<strong>switch user</strong>）用户user_name</li></ul><blockquote><p>参考与引用</p><ol><li><a href="https://blog.csdn.net/ljianhui/article/details/11100625/" target="_blank" rel="noopener">https://blog.csdn.net/ljianhui/article/details/11100625/</a></li><li><a href="https://www.cnblogs.com/ksguai/p/6090115.html" target="_blank" rel="noopener">https://www.cnblogs.com/ksguai/p/6090115.html</a></li><li><a href="https://blog.csdn.net/kwu_ganymede/article/details/61199067" target="_blank" rel="noopener">https://blog.csdn.net/kwu_ganymede/article/details/61199067</a></li><li><a href="http://blog.51cto.com/linuxme/375752" target="_blank" rel="noopener">http://blog.51cto.com/linuxme/375752</a></li><li><a href="https://www.linuxidc.com/Linux/2017-06/144916.htm" target="_blank" rel="noopener">https://www.linuxidc.com/Linux/2017-06/144916.htm</a></li><li><a href="https://zhidao.baidu.com/question/584292009.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/584292009.html</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> command </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux常用软件</title>
      <link href="/2017/03/01/Linux-softwares/"/>
      <url>/2017/03/01/Linux-softwares/</url>
      <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="vim最常用：-常用度从高至低"><a href="#vim最常用：-常用度从高至低" class="headerlink" title="vim最常用： 常用度从高至低"></a>vim最常用： 常用度从高至低</h2><h3 id="A-level"><a href="#A-level" class="headerlink" title="A level"></a>A level</h3><ul><li><strong>i</strong>:insert模式</li><li><strong>:wq</strong>:存盘退出</li><li><strong>yy</strong>:复制一整行</li><li><strong>dd</strong>:删除当前行，并且添加至剪贴板</li><li><strong>p</strong>:粘贴剪贴板</li><li><strong>o</strong>:当前行后插入行</li><li><strong>0</strong>:移动光标到行头</li><li><strong>$</strong>:移动光标到行尾</li><li><strong>gg</strong>:移动光标到第一行</li><li><strong>G</strong>:移动光标到最后一行</li><li><strong>u</strong>: undo</li><li><strong>C-r</strong>: redo</li><li><strong>搜索str1并且替换为str2</strong>：%s/str1/str2/g (这个比较好用)</li></ul><h3 id="B-level"><a href="#B-level" class="headerlink" title="B level"></a>B level</h3><ul><li><strong>gg</strong>:光标移动到页面顶部</li><li><strong>:e</strong>:打开一个文件</li><li><strong>:saveas</strong>:存盘</li><li><strong>:q!</strong>:退出不保存</li><li>多行复制</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">按v进入可视模式;按y复制;按p粘贴</span><br><span class="line"></span><br><span class="line">将第9行至第15行的数据，复制到第16行 </span><br><span class="line">：9，15 copy 16</span><br></pre></td></tr></table></figure><h3 id="vimium篇（浏览器工具）"><a href="#vimium篇（浏览器工具）" class="headerlink" title="vimium篇（浏览器工具）"></a>vimium篇（浏览器工具）</h3><p>gg:到页面顶部<br>G:到页面底部<br>d:向下滑动一页<br>u:向上滑动一页<br>f:在当前网页打开链接<br>F:在新页面打开链接</p><h2 id="多窗口管理工具-Screen"><a href="#多窗口管理工具-Screen" class="headerlink" title="多窗口管理工具 Screen"></a>多窗口管理工具 Screen</h2><h3 id="最常用命令"><a href="#最常用命令" class="headerlink" title="最常用命令"></a>最常用命令</h3><ul><li><p>创建新的窗口会话 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen 或者 screen -S yourname</span><br></pre></td></tr></table></figure></li><li><p>重新连接会话</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -r &lt;screen_pid&gt;</span><br></pre></td></tr></table></figure></li><li><p>补充：若意外断开后无法进入会话，则需要：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -D -r &lt;screen_pid&gt;</span><br></pre></td></tr></table></figure></li><li><p>查看所有screen会话 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -ls</span><br></pre></td></tr></table></figure></li><li><p>暂时断开会话 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">control+A d</span><br></pre></td></tr></table></figure></li><li><p>停止当前窗口 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">control+A k</span><br></pre></td></tr></table></figure></li><li><p>清除dead会话：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">screen -wipe</span><br></pre></td></tr></table></figure></li></ul><h2 id="virtualenv环境管理"><a href="#virtualenv环境管理" class="headerlink" title="virtualenv环境管理"></a>virtualenv环境管理</h2><ol><li><p>安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install virtualenv</span><br></pre></td></tr></table></figure></li><li><p>为工程创建虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> cd project_dir</span><br><span class="line"><span class="meta">$</span> virtualenv venv_name</span><br><span class="line">为环境选择python解释器：</span><br><span class="line"><span class="meta">$</span> virtualenv -p /usr/bin/python2.7 venv_name</span><br></pre></td></tr></table></figure></li><li><p>使用虚拟环境：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> source venv_name/bin/activate</span><br></pre></td></tr></table></figure></li><li><p>停用虚拟环境</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> . venv_name/bin/deactivate</span><br></pre></td></tr></table></figure></li></ol><h2 id="anaconda"><a href="#anaconda" class="headerlink" title="anaconda"></a>anaconda</h2><ol><li><p>下载anaconda</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> wget anaconda_latest_version_url</span><br></pre></td></tr></table></figure></li><li><p>安装anaconda</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> bash anaconda_latest_version</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'export PATH="~/your_anaconda_version/bin:$PATH"' &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure></li><li><p>Conda环境管理</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 创建环境</span><br><span class="line">conda create --name your_env_name python=your_python_version</span><br><span class="line"><span class="meta">#</span> 激活环境</span><br><span class="line">source activate your_env_name</span><br><span class="line"><span class="meta">#</span> 停用环境</span><br><span class="line">deactivate your_env_name</span><br><span class="line"><span class="meta">#</span> 删除环境</span><br><span class="line">conda remove -name your_env_name --all</span><br><span class="line"><span class="meta">#</span> 查看已安装的环境</span><br><span class="line">conda info -e</span><br></pre></td></tr></table></figure></li></ol><h2 id="JupyterNotebook"><a href="#JupyterNotebook" class="headerlink" title="JupyterNotebook"></a>JupyterNotebook</h2><p>大名鼎鼎的软件。<br>我平时使用Pycharm作为IDE。然而最近学习Yjango的代码发现：演示教学方面JupyterNotebook有着得天独厚的优势（cell功能）。</p><h3 id="命令模式常用指令"><a href="#命令模式常用指令" class="headerlink" title="命令模式常用指令"></a>命令模式常用指令</h3><ul><li><code>jupyter notebook</code>: 从控制台打开jupyternotebook</li><li><code>Enter</code>: 进入编辑模式</li><li><code>Shift-Enter</code>: 运行cell，自动跳转下一个cell</li><li><code>Ctrl-Enter</code>: 运行cell</li><li><code>y</code>: cell进入代码状态</li><li><code>m</code>: cell进入markdown状态</li><li><code>a</code>: 上方插入cell</li><li><code>b</code>: 下方插入cell</li><li><code>z</code>: 恢复删除的最后一个cell</li><li><code>dd</code>: 删除选中的cell</li><li><code>s</code>: 保存文件</li></ul><h3 id="matplotlib集成"><a href="#matplotlib集成" class="headerlink" title="matplotlib集成"></a>matplotlib集成</h3><p>文件头加上如下代码可以在代码中显示图片。这个操作省去了一次性关闭一堆图片的麻烦。<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure></p><h2 id="Commitizen"><a href="#Commitizen" class="headerlink" title="Commitizen"></a>Commitizen</h2><p>这个小工具专门负责减少<code>commit -m</code>时候的词穷感与code review时的无助感。</p><h3 id="1-安装-mac环境下"><a href="#1-安装-mac环境下" class="headerlink" title="1. 安装(mac环境下)"></a>1. 安装(mac环境下)</h3><ul><li><code>brew install node</code> 安装nodeJS</li><li><code>cnpm install -g commitizen</code> 使用cnpm全局安装commitizen</li><li><code>cnpm install -g</code></li></ul><h3 id="2-使用"><a href="#2-使用" class="headerlink" title="2. 使用"></a>2. 使用</h3><ul><li><code>cnpm install -g cz-conventional-changelog</code> 加载Angular规范模板文件</li><li><code>echo &#39;{ &quot;path&quot;: &quot;cz-conventional-changelog&quot; }&#39; &gt; ~/.czrc</code> 使用Angular规范模板文件</li><li><code>git cz</code> 相当于 <code>git commit -m</code>了</li></ul><h3 id="3-使用进阶"><a href="#3-使用进阶" class="headerlink" title="3. 使用进阶"></a>3. 使用进阶</h3><ol><li>第一步填写<code>type</code><ul><li>feat :新功能 </li><li>fix :修复bug  </li><li>doc : 文档改变</li><li>style : 代码格式改变</li><li>refactor :某个已有功能重构</li><li>perf :性能优化</li><li>test :增加测试</li></ul></li></ol><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsm760ekg7j20vg0g6wky.jpg" alt="实际使用效果图"></p><ol start="2"><li>第二步填写<code>scope</code>：此项为作用域，建议选项如下<ul><li>$all ：表示影响面大 ，如修改了项目框架会对整个程序产生影响。又或者全局文件</li><li>$loation： 表示影响小，某个小小的功能</li><li>$module：表示会影响某个模块 如登录模块、首页模块 、用户管理模块等等</li><li>自定义也是一个可选项，但要以<code>$</code>作为开头</li></ul></li></ol><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsm7crl46cj20ve0biwia.jpg" alt="实际使用效果图"></p><ol><li>第三步填写其他信息：<ul><li><code>subject</code>:用来简要描述本次改动</li><li><code>body</code>:具体的修改信息 应该尽量详细</li><li><code>footer</code>:放置写备注啥的，如果是 bug ，可以把bug id放入</li></ul></li></ol><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsm7i9aeztj20vi0h6ahg.jpg" alt="实际使用效果图"></p><h3 id="4-使用终阶"><a href="#4-使用终阶" class="headerlink" title="4. 使用终阶"></a>4. 使用终阶</h3><p>生成Change log:</p><ul><li><code>cnpm install -g conventional-changelog-cli</code> 首先安装客户端</li><li><code>conventional-changelog -p angular -i CHANGELOG.md -s -r 0</code> 直接生成log文件</li></ul><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsmapxnl79j20va0eq0wt.jpg" alt="实际使用效果图"></p><h2 id="Linux数据库常用命令"><a href="#Linux数据库常用命令" class="headerlink" title="Linux数据库常用命令"></a>Linux数据库常用命令</h2><h3 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h3><ul><li>启动mysql服务<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mysql.server start</span><br><span class="line">```        </span><br><span class="line">- 打开mysql</span><br><span class="line">```    </span><br><span class="line">mysql -u root -p</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>参考与引用</p><ol><li><a href="https://www.cnblogs.com/technologylife/p/6635631.html" target="_blank" rel="noopener">https://www.cnblogs.com/technologylife/p/6635631.html</a></li><li><a href="https://www.wangjingxian.cn/linux/41.html" target="_blank" rel="noopener">https://www.wangjingxian.cn/linux/41.html</a></li><li><a href="https://www.cnblogs.com/ctaodream/p/6066694.html" target="_blank" rel="noopener">https://www.cnblogs.com/ctaodream/p/6066694.html</a></li><li><a href="http://www.ruanyifeng.com/blog/2016/01/commit_message_change_log.html" target="_blank" rel="noopener">http://www.ruanyifeng.com/blog/2016/01/commit_message_change_log.html</a></li></ol></blockquote>]]></content>
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> vim </tag>
            
            <tag> screen </tag>
            
            <tag> virtualenv </tag>
            
            <tag> anaconda </tag>
            
            <tag> jupyterNoteBook </tag>
            
            <tag> commitizen </tag>
            
            <tag> mysql </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>

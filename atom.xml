<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Zzy824</title>
  
  <subtitle>Player of AI</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://824zzy.github.io/"/>
  <updated>2018-08-27T05:12:07.688Z</updated>
  <id>https://824zzy.github.io/</id>
  
  <author>
    <name>ZZY</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>demo驱动学习：Image_Caption</title>
    <link href="https://824zzy.github.io/2018/08/26/Image-Caption-demo-by-tensorflow/"/>
    <id>https://824zzy.github.io/2018/08/26/Image-Caption-demo-by-tensorflow/</id>
    <published>2018-08-25T16:00:00.000Z</published>
    <updated>2018-08-27T05:12:07.688Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Introduction-to-demo"><a href="#Introduction-to-demo" class="headerlink" title="Introduction to demo"></a>Introduction to demo</h2><p>Source Code:<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb" target="_blank" rel="noopener">image_captioning_with_attention</a></p><h3 id="Related-Papers"><a href="#Related-Papers" class="headerlink" title="Related Papers"></a>Related Papers</h3><p><a href="https://arxiv.org/pdf/1502.03044.pdf" target="_blank" rel="noopener">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention.</a></p><h3 id="Goal-of-this-end2end-model"><a href="#Goal-of-this-end2end-model" class="headerlink" title="Goal of this end2end model"></a>Goal of this end2end model</h3><ol><li>Generate a caption, such as “a surfer riding on a wave”, according to an image.<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fun2xxvjt8j20hs0buamq.jpg" alt=""></li><li>Use an attention based model that enables us to see which parts of the image the model focuses on as it generates a caption.<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fun2yatwwhj20zz0ehk1c.jpg" alt=""></li></ol><h3 id="Dateset"><a href="#Dateset" class="headerlink" title="Dateset"></a>Dateset</h3><p><strong>MS-COCO</strong>:This dataset contains &gt;82,000 images, each of which has been annotated with at least 5 different captions.</p><h2 id="Frame-work-of-demo"><a href="#Frame-work-of-demo" class="headerlink" title="Frame work of demo:"></a>Frame work of demo:</h2><ol><li>Download and prepare the MS-COCO dataset</li><li>Limit the size of the training set for faster training</li><li><p>Preprocess the images using InceptionV3: extract features from the last convolutional layer.</p><ol><li>Initialize InceptionV3 and load the pretrained Imagenet weights</li><li>Caching the features extracted from InceptionV3</li></ol></li><li><p>Preprocess and tokenize the captions</p><ol><li>First, tokenize the captions will give us a vocabulary of all the unique words in the data (e.g., “surfing”, “football”, etc).</li><li>Next, limit the vocabulary size to the top 5,000 words to save memory. We’ll replace all other words with the token “UNK” (for unknown).</li><li>Finally, we create a word –&gt; index mapping and vice-versa.</li><li>We will then pad all sequences to the be same length as the longest one.</li></ol></li><li><p>create a tf.data dataset to use for training our model.</p></li></ol><ol start="6"><li><p>Model</p><ol><li>extract the features from the lower convolutional layer of InceptionV3 giving us a vector of shape (8, 8, 2048).</li><li>This vector is then passed through the CNN Encoder(which consists of a single Fully connected layer).</li><li>The RNN(here GRU) attends over the image to predict the next word.</li></ol></li><li><p>Training</p><ol><li>We extract the features stored in the respective .npy files and then pass those features through the encoder.</li><li>The encoder output, hidden state(initialized to 0) and the decoder input (which is the start token) is passed to the decoder.</li><li>The decoder returns the predictions and the decoder hidden state.</li><li>The decoder hidden state is then passed back into the model and the predictions are used to calculate the loss.</li><li>Use teacher forcing to decide the next input to the decoder.</li><li>Teacher forcing is the technique where the target word is passed as the next input to the decoder.</li><li>The final step is to calculate the gradients and apply it to the optimizer and backpropagate.</li></ol></li><li><p>Caption</p><ol><li>The evaluate function is similar to the training loop, except we don’t use teacher forcing here. The input to the decoder at each time step is its previous predictions along with the hidden state and the encoder output.</li><li>Stop predicting when the model predicts the end token.</li><li>And store the attention weights for every time step.</li></ol></li></ol><h2 id="Problems-undesirable"><a href="#Problems-undesirable" class="headerlink" title="Problems undesirable"></a>Problems undesirable</h2><h3 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h3><ul><li>The code requires TensorFlow version <strong>&gt;=1.9</strong>. 1.10.0 is better.</li><li><code>cudatoolkit</code></li></ul><h3 id="GPU-lose-connect"><a href="#GPU-lose-connect" class="headerlink" title="GPU lose connect"></a>GPU lose connect</h3><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb" target="_blank" rel="noopener">https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/generative_examples/image_captioning_with_attention.ipynb</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;Introduction-to-demo&quot;&gt;&lt;a href=&quot;#Introduction-to-demo&quot; class=&quot;headerlink&quot; title=&quot;In
      
    
    </summary>
    
      <category term="Demo" scheme="https://824zzy.github.io/categories/Demo/"/>
    
    
      <category term="imageCaption" scheme="https://824zzy.github.io/tags/imageCaption/"/>
    
  </entry>
  
  <entry>
    <title>Visual-Question-Learning</title>
    <link href="https://824zzy.github.io/2018/08/23/Visual-Question-Learning/"/>
    <id>https://824zzy.github.io/2018/08/23/Visual-Question-Learning/</id>
    <published>2018-08-23T05:01:47.000Z</published>
    <updated>2018-08-25T12:57:40.302Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><blockquote><p>Visual Question Answering(VQA): A VQS system takes as input an image and free-form, open-ended, natural-language question about the image and produces a</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>深度学习模块文档备忘录</title>
    <link href="https://824zzy.github.io/2018/08/23/colab-tensorflow-usage/"/>
    <id>https://824zzy.github.io/2018/08/23/colab-tensorflow-usage/</id>
    <published>2018-08-22T16:00:00.000Z</published>
    <updated>2018-08-26T08:09:36.225Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Colab-study-notes"><a href="#Colab-study-notes" class="headerlink" title="Colab study notes"></a>Colab study notes</h2><h3 id="Install-commonly-used-packages"><a href="#Install-commonly-used-packages" class="headerlink" title="Install commonly used packages"></a>Install commonly used packages</h3><p>Although Colab has already installed some packages such as Tensorflow Matplotlib .etc, there are lots of commonly ised packages:</p><ul><li>Keras:<code>pip install keras</code></li><li>OpenCV:<code>!apt-get -qq install -y libsm6 libxext6 &amp;&amp; pip install -q -U opencv-python</code></li><li>Pytorch:<code>!pip install -q http://download.pytorch.org/whl/cu75/torch-0.2.0.post3-cp27-cp27mu-manylinux1_x86_64.whl torchvision</code></li><li>tqdm:<code>!pip install tqdm</code><h3 id="Authorized-to-log-in"><a href="#Authorized-to-log-in" class="headerlink" title="Authorized to log in"></a>Authorized to log in</h3><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 PyDrive 操作库，该操作每个 notebook 只需要执行一次</span></span><br><span class="line">!pip install -U -q PyDrive</span><br><span class="line"><span class="keyword">from</span> pydrive.auth <span class="keyword">import</span> GoogleAuth</span><br><span class="line"><span class="keyword">from</span> pydrive.drive <span class="keyword">import</span> GoogleDrive</span><br><span class="line"><span class="keyword">from</span> google.colab <span class="keyword">import</span> auth</span><br><span class="line"><span class="keyword">from</span> oauth2client.client <span class="keyword">import</span> GoogleCredentials</span><br><span class="line"></span><br><span class="line"><span class="comment"># 授权登录，仅第一次的时候会鉴权</span></span><br><span class="line">auth.authenticate_user()</span><br><span class="line">gauth = GoogleAuth()</span><br><span class="line">gauth.credentials = GoogleCredentials.get_application_default()</span><br><span class="line">drive = GoogleDrive(gauth)</span><br></pre></td></tr></table></figure></li></ul><h3 id="File-IO"><a href="#File-IO" class="headerlink" title="File IO"></a>File IO</h3><h4 id="Read-file-from-Google-Drive"><a href="#Read-file-from-Google-Drive" class="headerlink" title="Read file from Google Drive"></a>Read file from Google Drive</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get the file by id</span></span><br><span class="line">downloaded = drive.CreateFile(&#123;<span class="string">'id'</span>:<span class="string">'yourfileID'</span>&#125;) <span class="comment"># replace the id with id of file you want to access</span></span><br><span class="line"><span class="comment"># Download file to colab</span></span><br><span class="line">downloaded.GetContentFile(<span class="string">'yourfileName'</span>)  </span><br><span class="line"><span class="comment"># Read file as panda dataframe</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line">xyz = pd.read_csv(<span class="string">'yourfileName'</span>)</span><br></pre></td></tr></table></figure><h4 id="Write-file-to-Google-Drive"><a href="#Write-file-to-Google-Drive" class="headerlink" title="Write file to Google Drive"></a>Write file to Google Drive</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create a Content file as Cache</span></span><br><span class="line">xyz.to_csv(<span class="string">'over.csv'</span>)</span><br><span class="line"><span class="comment"># Create &amp; upload a text file.</span></span><br><span class="line">uploaded = drive.CreateFile(&#123;<span class="string">'title'</span>: <span class="string">'OK.csv'</span>&#125;)</span><br><span class="line"><span class="comment"># You will have a file named 'OK.csv' which has content of 'over.csv'</span></span><br><span class="line">uploaded.SetContentFile(<span class="string">'over.csv'</span>)</span><br><span class="line">uploaded.Upload()</span><br><span class="line"><span class="comment"># checkout your upload file's ID</span></span><br><span class="line">print(<span class="string">'Uploaded file with ID &#123;&#125;'</span>.format(uploaded.get(<span class="string">'id'</span>)))</span><br></pre></td></tr></table></figure><h2 id="Tensorflow-commonly-used"><a href="#Tensorflow-commonly-used" class="headerlink" title="Tensorflow commonly used"></a>Tensorflow commonly used</h2><h3 id="tf"><a href="#tf" class="headerlink" title="tf"></a>tf</h3><h4 id="read-file"><a href="#read-file" class="headerlink" title="read_file"></a>read_file</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.read_file(</span><br><span class="line">    filename,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="device"><a href="#device" class="headerlink" title="device"></a>device</h4><ol><li>manual mode<ul><li><code>with tf.device(&#39;/cpu:0&#39;)</code>: cpu</li><li><code>with tf.device(&#39;/gpu:0&#39;)</code>or<code>with tf.device(&#39;/device:GPU:0&#39;)</code>   </li></ul></li><li>GPU config<ul><li><code>import os</code></li><li><code>os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;]=&#39;0, 1&#39;</code><h4 id="random-normal"><a href="#random-normal" class="headerlink" title="random_normal"></a>random_normal</h4>Outputs random values from a normal distribution.<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tf.random_normal(</span><br><span class="line">    shape,</span><br><span class="line">    mean=<span class="number">0.0</span>,</span><br><span class="line">    stddev=<span class="number">1.0</span>,</span><br><span class="line">    dtype=tf.float32,</span><br><span class="line">    seed=<span class="keyword">None</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br><span class="line">tf.random_normal((<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="ConfigProto"><a href="#ConfigProto" class="headerlink" title="ConfigProto"></a>ConfigProto</h4><p>allowing GPU memory growth by the process.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">config = tf.ConfigProto()</span><br><span class="line">config.gpu_options.allow_growth = <span class="keyword">True</span></span><br><span class="line">sess = tf.Session(config=config)</span><br></pre></td></tr></table></figure></p><h4 id="reduce-sum"><a href="#reduce-sum" class="headerlink" title="reduce_sum"></a>reduce_sum</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_sum(</span><br><span class="line">    input_tensor,</span><br><span class="line">    axis=<span class="keyword">None</span>,</span><br><span class="line">    keepdims=<span class="keyword">None</span>,</span><br><span class="line">    name=<span class="keyword">None</span>,</span><br><span class="line">    reduction_indices=<span class="keyword">None</span>,</span><br><span class="line">    keep_dims=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>Returns: The reduced tensor</p><h4 id="device-1"><a href="#device-1" class="headerlink" title="device"></a>device</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tf.device(device_name_or_function)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/cpu:0'</span>):</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">'/gpu:0'</span>):</span><br></pre></td></tr></table></figure><h3 id="tf-image"><a href="#tf-image" class="headerlink" title="tf.image"></a>tf.image</h3><h4 id="decode-jpeg"><a href="#decode-jpeg" class="headerlink" title="decode_jpeg"></a>decode_jpeg</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tf.image.decode_jpeg(</span><br><span class="line">    contents,</span><br><span class="line">    channels=<span class="number">0</span>, <span class="comment"># 3: output an RGB image.</span></span><br><span class="line">    ratio=<span class="number">1</span>,</span><br><span class="line">    fancy_upscaling=<span class="keyword">True</span>,</span><br><span class="line">    try_recover_truncated=<span class="keyword">False</span>,</span><br><span class="line">    acceptable_fraction=<span class="number">1</span>,</span><br><span class="line">    dct_method=<span class="string">''</span>,</span><br><span class="line">    name=<span class="keyword">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><h4 id="resize-images"><a href="#resize-images" class="headerlink" title="resize_images"></a>resize_images</h4><h3 id="tf-layers"><a href="#tf-layers" class="headerlink" title="tf.layers"></a>tf.layers</h3><h4 id="conv2d"><a href="#conv2d" class="headerlink" title="conv2d"></a>conv2d</h4><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">tf.layers.conv2d(</span><br><span class="line">    inputs,</span><br><span class="line">    filters,</span><br><span class="line">    kernel_size,</span><br><span class="line">    strides=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    padding=<span class="string">'valid'</span>,</span><br><span class="line">    data_format=<span class="string">'channels_last'</span>,</span><br><span class="line">    dilation_rate=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">    activation=<span class="keyword">None</span>,</span><br><span class="line">    use_bias=<span class="keyword">True</span>,</span><br><span class="line">    kernel_initializer=<span class="keyword">None</span>,</span><br><span class="line">    bias_initializer=tf.zeros_initializer(),</span><br><span class="line">    kernel_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    bias_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    activity_regularizer=<span class="keyword">None</span>,</span><br><span class="line">    kernel_constraint=<span class="keyword">None</span>,</span><br><span class="line">    bias_constraint=<span class="keyword">None</span>,</span><br><span class="line">    trainable=<span class="keyword">True</span>,</span><br><span class="line">    name=<span class="keyword">None</span>,</span><br><span class="line">    reuse=<span class="keyword">None</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">random_image_gpu = tf.random_normal((<span class="number">100</span>, <span class="number">100</span>, <span class="number">100</span>, <span class="number">3</span>))</span><br><span class="line">net_gpu = tf.layers.conv2d(random_image_gpu, <span class="number">32</span>, <span class="number">7</span>)</span><br></pre></td></tr></table></figure><p>Returns: Output tensor.</p><h3 id="tf-test"><a href="#tf-test" class="headerlink" title="tf.test"></a>tf.test</h3><ul><li>gpu_device_name(): Check out GPU whether can be found.</li></ul><h2 id="scikit-learn-sklearn"><a href="#scikit-learn-sklearn" class="headerlink" title="scikit-learn(sklearn)"></a>scikit-learn(sklearn)</h2><h3 id="utils"><a href="#utils" class="headerlink" title="utils"></a>utils</h3><ul><li>shuffle(*array):Shuffle arrays or sparse matrices in a consistent way<h3 id="model-selection"><a href="#model-selection" class="headerlink" title="model_selection"></a>model_selection</h3></li><li>train_test_split(*array): Split arrays or matrices into random train and test subsets</li></ul><h2 id="Keras"><a href="#Keras" class="headerlink" title="Keras"></a>Keras</h2><p>A high-API to build and train deep learning models.</p><h3 id="applications"><a href="#applications" class="headerlink" title="applications"></a>applications</h3><h4 id="inception-v3"><a href="#inception-v3" class="headerlink" title="inception_v3"></a>inception_v3</h4><ul><li><p>InceptionV3(…): Instantiates the Inception v3 architecture.</p>  <figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tf.keras.applications.InceptionV3(</span><br><span class="line">include_top=<span class="keyword">True</span>, <span class="comment"># whether to include the fully-connected layer at the top of the network.</span></span><br><span class="line">weights=<span class="string">'imagenet'</span>,</span><br><span class="line">input_tensor=<span class="keyword">None</span>,</span><br><span class="line">input_shape=<span class="keyword">None</span>,</span><br><span class="line">pooling=<span class="keyword">None</span>,</span><br><span class="line">classes=<span class="number">1000</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></li><li><p>decode_predictions(…): Decodes the prediction of an ImageNet model.</p></li><li>preprocess_input(…): Preprocesses a numpy array encoding a batch of images.</li></ul><h3 id="utils-1"><a href="#utils-1" class="headerlink" title="utils"></a>utils</h3><ul><li>get_file: Downloads a file from a URL if it not already in the cache.</li></ul><blockquote><p>Reference:</p><ol><li><a href="https://segmentfault.com/a/1190000012731724" target="_blank" rel="noopener">https://segmentfault.com/a/1190000012731724</a></li><li><a href="https://tensorflow.google.cn/api_docs/" target="_blank" rel="noopener">https://tensorflow.google.cn/api_docs/</a></li><li><a href="https://www.jianshu.com/p/d7283bc427b1" target="_blank" rel="noopener">https://www.jianshu.com/p/d7283bc427b1</a></li><li><a href="http://scikit-learn.org/stable/modules" target="_blank" rel="noopener">http://scikit-learn.org/stable/modules</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;Colab-study-notes&quot;&gt;&lt;a href=&quot;#Colab-study-notes&quot; class=&quot;headerlink&quot; title=&quot;Colab st
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://824zzy.github.io/categories/DeepLearning/"/>
    
    
      <category term="colab" scheme="https://824zzy.github.io/tags/colab/"/>
    
      <category term="tensorflow" scheme="https://824zzy.github.io/tags/tensorflow/"/>
    
      <category term="sklearn" scheme="https://824zzy.github.io/tags/sklearn/"/>
    
      <category term="Keras" scheme="https://824zzy.github.io/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>Zero-shot Learning</title>
    <link href="https://824zzy.github.io/2018/08/22/zero-shot-learning/"/>
    <id>https://824zzy.github.io/2018/08/22/zero-shot-learning/</id>
    <published>2018-08-22T06:32:41.000Z</published>
    <updated>2018-08-22T12:57:52.965Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Zero-shot Learning is a concept from Transfer-Learning. In traditional machine learning method, Generalization is difficult since big data and time-consuming training are needed in general. Therefore more and more researchers pay attention to <strong>Zero-shot Learning</strong>/<strong>One-shot Learning</strong>/<strong>Few-shot Learning</strong></p><h3 id="types-of-Learning"><a href="#types-of-Learning" class="headerlink" title="types of Learning"></a>types of Learning</h3><h4 id="Zero-shot-Learning"><a href="#Zero-shot-Learning" class="headerlink" title="Zero-shot Learning"></a>Zero-shot Learning</h4><p>A model can create a map $X\rightarrowY$ automatically for the categories which have not appeared in a training set.</p><h4 id="One-shot-Learning"><a href="#One-shot-Learning" class="headerlink" title="One-shot Learning"></a>One-shot Learning</h4><p>One-shot learning is an object categorization problem in computer vision. Whereas most machine learning based object categorization algorithms require training on hundreds or thousands of images and very large datasets, one-shot learning aims to learn information about object categories from one, or only a few, training images.</p><h4 id="Few-shot-Leaning"><a href="#Few-shot-Leaning" class="headerlink" title="Few-shot Leaning"></a>Few-shot Leaning</h4><h2 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h2><h3 id="DeVise-A-Deep-Visual-Semantic-Embedding-Model"><a href="#DeVise-A-Deep-Visual-Semantic-Embedding-Model" class="headerlink" title="DeVise: A Deep Visual-Semantic Embedding Model"></a>DeVise: A Deep Visual-Semantic Embedding Model</h3><h4 id="Core-idea"><a href="#Core-idea" class="headerlink" title="Core idea"></a>Core idea</h4><p>Combine <strong>feature vector</strong> from Computer Vision and <strong>semantic vector</strong> from NLP to realize zero-shot learning.</p><h3 id="Zero-shot-Learning-by-Convex-Combination-of-Semantic-Embeddings"><a href="#Zero-shot-Learning-by-Convex-Combination-of-Semantic-Embeddings" class="headerlink" title="Zero-shot Learning by Convex Combination of Semantic Embeddings"></a>Zero-shot Learning by Convex Combination of Semantic Embeddings</h3><h3 id="Objects2action-Classifying-and-localizing-actions-without-any-video-example"><a href="#Objects2action-Classifying-and-localizing-actions-without-any-video-example" class="headerlink" title="Objects2action: Classifying and localizing actions without any video example"></a>Objects2action: Classifying and localizing actions without any video example</h3><blockquote><p>Reference:</p><ol><li><a href="https://en.wikipedia.org/wiki/One-shot_learning" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/One-shot_learning</a></li><li><a href="https://blog.csdn.net/jningwei/article/details/79235019" target="_blank" rel="noopener">https://blog.csdn.net/jningwei/article/details/79235019</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>论文笔记：Deep Reinforcement Learning for Dialogue Generation</title>
    <link href="https://824zzy.github.io/2018/08/18/paper-note-deep-reinfocement-learning-for-Dialogue-Generation/"/>
    <id>https://824zzy.github.io/2018/08/18/paper-note-deep-reinfocement-learning-for-Dialogue-Generation/</id>
    <published>2018-08-17T16:00:00.000Z</published>
    <updated>2018-08-26T07:39:27.326Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="论文基本信息"><a href="#论文基本信息" class="headerlink" title="论文基本信息"></a>论文基本信息</h2><ol><li>论文名：Deep Reinforcement Learning for Dialogue Generation</li><li>论文链接：<a href="https://arxiv.org/abs/1606.01541" target="_blank" rel="noopener">https://arxiv.org/abs/1606.01541</a></li><li>论文源码：<ul><li><a href="https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow" target="_blank" rel="noopener">https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow</a></li><li><a href="https://github.com/agsarthak/Goal-oriented-Dialogue-Systems" target="_blank" rel="noopener">https://github.com/agsarthak/Goal-oriented-Dialogue-Systems</a></li><li><a href="https://github.com/jiweil/Neural-Dialogue-Generation" target="_blank" rel="noopener">https://github.com/jiweil/Neural-Dialogue-Generation</a></li></ul></li><li>关于作者：<ul><li>Jiwei Li：斯坦福大学博士毕业生，截至发稿被引次数：2156</li><li>Will Monroe：斯坦福大学博士在读，截至发稿被引次数：562</li><li>Alan Ritter：俄亥俄州立大学教授，截至发稿被引次数：4608</li><li>Michel Galley：微软高级研究员，截至发稿被引次数：4529</li><li>Jianfeng Gao：雷德蒙德微软研究院（总部），截至发稿被引次数：11944</li><li>Dan Jurafsky：，斯坦福大学教授，截至发稿被引次数：32973</li></ul></li><li>关于笔记作者：<ul><li>朱正源,北京邮电大学研究生，研究方向为多模态与认知计算。</li></ul></li></ol><h2 id="论文推荐理由与摘要"><a href="#论文推荐理由与摘要" class="headerlink" title="论文推荐理由与摘要"></a>论文推荐理由与摘要</h2><p>最近对话生成的神经模型为会话Agent生成响应提供了很大的帮助，但其结果往往是短视的：一次预测一个话语会忽略它们对未来结果的影响。对未来的对话方向进行建模，这对于产生连贯，有趣的对话至关重要。这种对话需要在传统的NLP对话模式的技术上使用强化学习。在本文中，我们将展示如何整合这些目标，应用深度强化学习来模拟聊天机器人对话中的未来奖励。该模型模拟两个虚拟代理之间的对话，使用策略梯度方法来奖励显示三个有用会话属性的序列：信息性，连贯性和易于回答（与前瞻性功能相关）。我们在多样性，长度以及人类评判方面评估我们的模型，表明所提出的算法产生了更多的交互式响应，并设法在对话模拟中促进更持久的对话。这项工作标志着基于对话的长期成功学习神经对话模型的第一步。</p><h2 id="对话系统的缺点不再致命：深度强化学习带来的曙光"><a href="#对话系统的缺点不再致命：深度强化学习带来的曙光" class="headerlink" title="对话系统的缺点不再致命：深度强化学习带来的曙光"></a>对话系统的缺点不再致命：深度强化学习带来的曙光</h2><h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><h4 id="论文的写作动机"><a href="#论文的写作动机" class="headerlink" title="论文的写作动机"></a>论文的写作动机</h4><blockquote><p>Seq2Seq Model：将一个领域的序列(如英文句子)转换为另一个领域（如中文句子）的序列。在论文中是一种神经生成模型，它能最大限度地根据在前面的对话，生成回复的概率。</p></blockquote><p>Seq2Seq模型用于对话生成系统虽然已经取得一些成功，但是还存在两个问题：</p><ol><li><p>SEQ2SEQ模型是通过使用最大似然估计(MLE)目标函数,预测给定上下文中的下一个会话来训练的。SEQ2SEQ模型倾向于生成高度通用的响应，例如“我不知道”等。然而，“我不知道”显然不是一个好的回复。</p></li><li><p>基于最大似然估计的Seq2Seq模型无法结局重复的问题，因此对话系统通常会陷入重复性应答的无限循环之中。</p></li></ol><p>以上问题如下图所示：</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf3bujstcj20b509zgmm.jpg" alt=""></p><h4 id="论文思路的亮点"><a href="#论文思路的亮点" class="headerlink" title="论文思路的亮点"></a>论文思路的亮点</h4><p>首先提出对话系统应当具备的两种能力：</p><ol><li>结合开发人员定义的奖励函数，更好地模拟聊天机器人开发的真正目标。</li><li>在正在进行的对话中,对生成应答的长期影响进行建模。</li></ol><p>紧接着提出利用强化学习的生成方法来改进对话系统：</p><blockquote><p>encoder-decoder architecture:一种标准的神经机器翻译方法，用于解决seq2seq问题的递归神经网络。<br>Policy Gradient 策略梯度:</p></blockquote><p>该模型以encoder-decoder结构为骨干，模拟两个Agent之间的对话，在学习最大化预期回报的同时，探索可能的活动空间(回复的可能性)。Agent通过从正在进行的对话中优化长期Reward函数来学习策略。学习方式则使用策略梯度而非最大似然。</p><p>改进后的模型如下图所示：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf47elgdkj20af09yjse.jpg" alt=""></p><h3 id="论文模型的细节"><a href="#论文模型的细节" class="headerlink" title="论文模型的细节"></a>论文模型的细节</h3><h4 id="符号以及定义"><a href="#符号以及定义" class="headerlink" title="符号以及定义"></a>符号以及定义</h4><ol><li>$p$: 第一个Agent生成的句子</li><li>$q$: 第二个Agent生成的句子</li><li>$p_1,q_1,p_2,q_2,…,p_i,q_i$: 一段对话，或者称之为上下文.</li><li>$[p_i,q_i]$: Agent所处的状态，也即Agent的前两轮对话。</li><li>$p_{RL}(p_{i+1}|p_i,q_i)$: 策略(policy),论文中以LSTM encoder-decoder的形式出现。</li><li>$r$: 每个动作（每轮对话）的奖励函数。</li><li>$\mathbb{S}$: 人工构建的”迟钝回复”，例如“我不知道你在说什么”。</li><li>$N_{\mathbb{S}}$: 表示$N_{\mathbb{S}}$的基数</li><li>$N_{s}$: 表示“迟钝回复”$s$的符号数量。</li><li>$p_{seq2seq}$: 表示SEQ2SEQ模型的似然输出</li><li>$h_{p_i}$和$h_{p_{i+1}}$: 从encoder中获取的，代表Agent两轮连续对话$p_i$和$p_{i+1}$的表示。</li></ol><h4 id="Reward的定义和作用："><a href="#Reward的定义和作用：" class="headerlink" title="Reward的定义和作用："></a>Reward的定义和作用：</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug2dvizhhj209o01wdfq.jpg" alt=""></p><blockquote><p>$N_{\mathbb{S}}$:表示$N_{\mathbb{S}}$的基数<br>$N_{s}$: 表示“迟钝回复”$s$的符号数量<br>$p_{seq2seq}$: 表示SEQ2SEQ模型的似然输出</p><ul><li>$r_1$是为了降低回复的困难程度。这个奖励函数的灵感来自于前瞻性函数：计算当模型产生的响应$a$作为输入时模型输出$s$的概率，在对$\mathbb{S}$集合中的每一句话进行求和。因为$p_seq2seq}可定小于1，所以log项大于零，则r1小于零。通过r1的奖励机制，模型最终产生的action会慢慢的远离dull response，而且也会一定程度上估计到下一个人的回复，让对方可以更容易回复。</li></ul></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug5a6naokj20b302d747.jpg" alt=""></p><blockquote><p>$h_{p_i}$和$h_{p_{i+1}}$: 从encoder中获取的，代表Agent两轮连续对话$p_i$和$p_{i+1}$的表示。</p><ul><li>$r_2$是为了增加信息流的丰富程度，避免两次回复之间相似程度很高的情况。所以r2使用余弦相似度来计算两个句子之间的语义相似程度，很容易发现r2也是一个小于零的数，用来惩罚相似的句子。</li></ul></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug5av9bkgj20bp028mx4.jpg" alt=""></p><blockquote><p>$p_{seq2seq}(a|p_i, q_i)$: 表示在给定对话上文$[p_i,q_i]$的情况下生成回复a的概率<br>$p^{backward}_{seq2seq}(q_i|a)$: 表示基于响应$a$来生成之前的对话$q_i$的概率。</p><ul><li>$r_3$是为了增强语义连贯性，避免模型只产生那些高reward的响应，而丧失回答的充分性和连贯性。为了解决这个问题模型采用互信息来实现。反向的seq2seq是使用source和target反过来训练的另外一个模型，这样做的目的是为了提高q和a之间的相互关系，让对话更具有可持续性。可以看出来，$r_3$的两项都是正值。</li></ul></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fug5beurspj209y01dt8k.jpg" alt=""></p><ul><li>最终的奖励函数式对$r_1，r_2，r_3$进行加权求和,论文中设定$\lambda_1=0.25, \lambda_2=0.25, \lambda3=0.5$。最后总模型在训练的时候也是先使用Seq2Seq模型先预训练一个基础模型，然后在其基础上在使用reward进行policy gradient的训练来优化模型的效果。</li></ul><h4 id="强化学习模型细节"><a href="#强化学习模型细节" class="headerlink" title="强化学习模型细节"></a>强化学习模型细节</h4><blockquote><p>完全监督环境（fully supervised setting）: 一个预先训练的SEQ2SEQ模型，用作初始化强化学习模型。<br>注意力模型（Attention）: 模型在产生输出的时候，还会产生一个“注意力范围”表示接下来输出的时候要重点关注输入序列中的哪些部分，然后根据关注的区域来产生下一个输出，如此往复。</p></blockquote><p>论文采用了AlphaGo风格的模型：通过一个完全监督的环境下的一般响应生成策略来初始化强化学习模型。其中，SEQ2SEQ模型加入了Attention机制并且该模型在<strong>OpenSubtitles dataset</strong>数据集上训练。</p><p>论文并未采用预训练的Seq2Seq模型来初始化强化学习策略模型，而是使用了第一作者本人在2016年提出的生成最大互信息响应的encoder-decoder模型: 使用$p_{SEQ2SEQ}(a|p_i, q_i)$来初始化$p_{RL}$。从生成的候选集$A={\hat{a}|\hat{a}~p_{RL}}$中的$\hat{a}$获取互信息的得分$m(\hat{a}, [p_i, q_i])$，那么对一个sequence的期望奖励函数为：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuhd5cu9doj208j01ddfo.jpg" alt=""></p><p>通过似然率估计的梯度为：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuhd6s09lyj20ax01awed.jpg" alt=""></p><p>通过随机梯度下降就可以更新encoder-decoder的参数。论文中通过借鉴curriculum learning strategy对梯度进行了改进。</p><p>最终的梯度为：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuhdbxz4kij20b401tjra.jpg" alt=""></p><p>优化模型过程中则使用策略梯度来寻找可以最大化奖励函数的参数：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuief5dqqxj209j01n0sn.jpg" alt=""></p><h3 id="仿真实验细节"><a href="#仿真实验细节" class="headerlink" title="仿真实验细节"></a>仿真实验细节</h3><h4 id="对话仿真流程："><a href="#对话仿真流程：" class="headerlink" title="对话仿真流程："></a>对话仿真流程：</h4><ol><li>从训练集中挑选一个message给Agent-A</li><li>Agent-A对message进行编码并解码出一个响应作为输出。</li><li>Agent-B以Agent-A的输出作为输入，并且通过encoder-decoder来</li></ol><p>而策略policy就是Seq2Seq模型生成的相应的概率分布。我们可以把这个问题看成是上下文的对话历史输入到神经网络中，然后输出是一个response的概率分布：$pRL(pi+1|pi,qi)$。所谓策略就是进行随机采样，选择要进行的回答。最后使用policy gradient进行网络参数的训练。</p><p>两个agent互相对话最终得到的reward来调整base model的参数。</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf4u98teyj20lv0aatav.jpg" alt=""></p><h3 id="实验结果分析"><a href="#实验结果分析" class="headerlink" title="实验结果分析"></a>实验结果分析</h3><h4 id="评估指标"><a href="#评估指标" class="headerlink" title="评估指标"></a>评估指标</h4><blockquote><p>BLEU: bilingual evaluation understudy，一个评估机器翻译准确度的算法。<br>论文并没有使用 广泛应用的BLEU作为评价标准。</p></blockquote><ol><li><p>对话的长度，作者认为当对话出现dull response的时候就算做对话结束，所以使用对话的轮次来作为了评价指标：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0a67z3dj20fi051q3c.jpg" alt=""></p></li><li><p>不同unigrams、bigrams元组的数量和多样性，用于评测模型产生回答的丰富程度：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0boign2j20e104a3z0.jpg" alt=""></p></li><li><p>人类评分：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0gegq71j20gc03sgm9.jpg" alt=""></p></li><li><p>最终对话效果<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fuf0hq4jzaj20g203k3z5.jpg" alt=""></p></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>作者使用深度强化学习的方法来改善多轮对话的效果，并提出了三种reward的定义方式。可以算是DRL与NLP结合的一个比较不错的例子。但是从最后的结果部分也可以看得出，作者无论是在reward的定义、还是最后的评价指标都没有采用使用比较广泛的BLUE指标。这种手工定义的reward函数不可能涵盖一段理想对话所具有特点的的方方面面。</p><h3 id="引用与参考"><a href="#引用与参考" class="headerlink" title="引用与参考"></a>引用与参考</h3><ol><li><a href="https://www.paperweekly.site/papers/notes/221" target="_blank" rel="noopener">https://www.paperweekly.site/papers/notes/221</a></li><li><a href="https://scholar.google.com/" target="_blank" rel="noopener">https://scholar.google.com/</a></li><li><a href="https://blog.csdn.net/u014595019/article/details/52826423" target="_blank" rel="noopener">https://blog.csdn.net/u014595019/article/details/52826423</a></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;论文基本信息&quot;&gt;&lt;a href=&quot;#论文基本信息&quot; class=&quot;headerlink&quot; title=&quot;论文基本信息&quot;&gt;&lt;/a&gt;论文基本信息&lt;/h2&gt;&lt;ol&gt;
&lt;l
      
    
    </summary>
    
      <category term="Paper" scheme="https://824zzy.github.io/categories/Paper/"/>
    
    
      <category term="note" scheme="https://824zzy.github.io/tags/note/"/>
    
  </entry>
  
  <entry>
    <title>对话AI的论文列表</title>
    <link href="https://824zzy.github.io/2018/08/09/convAI-paper-list/"/>
    <id>https://824zzy.github.io/2018/08/09/convAI-paper-list/</id>
    <published>2018-08-09T04:31:31.000Z</published>
    <updated>2018-08-15T01:38:44.002Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>论文列表格式<br>&emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校/机构），代码链接</p></blockquote><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="Existing-Models-of-Dialog-System"><a href="#Existing-Models-of-Dialog-System" class="headerlink" title="Existing Models of Dialog System"></a>Existing Models of Dialog System</h3><h4 id="Task-Oriented-Dialog"><a href="#Task-Oriented-Dialog" class="headerlink" title="Task-Oriented Dialog"></a>Task-Oriented Dialog</h4><ul><li>13: <a href="https://ieeexplore.ieee.org/document/6407655/" target="_blank" rel="noopener"><strong>POMDP-Based Statistical Spoken Dialog Systems: A Review</strong></a>: Steve Young(Cambridge University)</li><li>11: <a href="https://www.wiley.com/en-us/Spoken+Language+Understanding:+Systems+for+Extracting+Semantic+Information+from+Speech-p-9780470688243" target="_blank" rel="noopener"><strong>Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</strong></a>: Book!</li><li>11:<a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener"><strong>Data-Driven Response Generation in Social Media</strong></a>: Alan Ritter(University of Washington Seattle)</li><li><p>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener"><strong>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</strong></a>: Alessandro Sordoni(Universite de Montreal)</p></li><li><p>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener"><strong>A Neural Conversational Model</strong></a>: Oriol Vinyals(Google), <a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</p></li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener"><strong>Neural Responding Machine for Short-Text Conversation</strong></a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener"><strong>code</strong></a> via theano and tensorflow</li></ul><h3 id="Traditional-NLP-component-stack"><a href="#Traditional-NLP-component-stack" class="headerlink" title="Traditional NLP component stack"></a>Traditional NLP component stack</h3><h4 id="Challenge-of-NLP"><a href="#Challenge-of-NLP" class="headerlink" title="Challenge of NLP"></a>Challenge of NLP</h4><ul><li>09: <a href="https://www.cs.colorado.edu/~martin/slp.html" target="_blank" rel="noopener"><strong>SPEECH and LANGUAGE PROCESSING An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Second Edition</strong></a>: book </li></ul><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h4 id="application-scenarios"><a href="#application-scenarios" class="headerlink" title="application scenarios"></a>application scenarios</h4><ol><li>Web search<ul><li>13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), <a href="https://github.com/wangtianqi1993/DL-WebSearch" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</li><li>14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li></ul></li><li>Entity linking<ul><li>14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Image captioning<ul><li>15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul></li><li>Machine Translation<ul><li><a href="http://aclweb.org/anthology/P/P14/P14-1066.pdf" target="_blank" rel="noopener"><strong>Learning Continuous Phrase Representations for Translation Modeling</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Online recommendation<ul><li>[<strong>duplicate</strong>] 14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfneg Gao(Microsoft Research)</li></ul></li></ol><h4 id="Framework-of-Model"><a href="#Framework-of-Model" class="headerlink" title="Framework of Model"></a>Framework of Model</h4><ul><li>[<strong>duplicate</strong>] 13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), [<strong>code</strong>]<ul><li>[<strong>duplicate</strong>] 14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li></ul></li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li><li><a href="http://aka.ms/sent2vec" target="_blank" rel="noopener">Sent2Vec</a>: software by microsoft</li></ul><h4 id="Go-beyound-DSSM"><a href="#Go-beyound-DSSM" class="headerlink" title="Go beyound DSSM"></a>Go beyound DSSM</h4><ul><li>[<strong>duplicate</strong>] 15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul><hr><h2 id="Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC"><a href="#Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC" class="headerlink" title="Question answeriing(QA) and Machine Readiing Comprehension(MRC)"></a>Question answeriing(QA) and Machine Readiing Comprehension(MRC)</h2><h3 id="Open-Domain-Question-Answering"><a href="#Open-Domain-Question-Answering" class="headerlink" title="Open-Domain Question Answering"></a>Open-Domain Question Answering</h3><h4 id="Knowledge-Base-QA"><a href="#Knowledge-Base-QA" class="headerlink" title="Knowledge Base-QA"></a>Knowledge Base-QA</h4><ol><li>Symbolic approach via Large-scale knowledge graphs<ul><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>: Stephen D.Richardson(Microsoft Research)</li><li>13: <a href="http://www.aclweb.org/anthology/D13-1160" target="_blank" rel="noopener">Semantic Parsing on Freebase from Question-Answer Pairs</a>: Jonathan Berant(Stanford University)</li><li>15: <a href="https://arxiv.org/pdf/1510.08565.pdf" target="_blank" rel="noopener">Attention with Intention for a Neural Network Conversation Model</a>: Kaisheng Yao(Microsoft Research)</li><li>14: <a href="http://www.aclweb.org/anthology/P14-1091" target="_blank" rel="noopener">Knowledge-Based Question Answering as Machine Translation</a>: Junwei Bao(Harbin Institute of Technology)</li><li>15: <a href="http://aclweb.org/anthology/P15-1128" target="_blank" rel="noopener">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</a>:Wen-tau Yih(Microsoft Research)</li></ul></li><li><p><strong>ReasoNet</strong> with Shared Memory</p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Search Controller in <strong>ReasoNet</strong> </p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li></ul></li><li><strong>ReasoNet</strong> in symbolic vs neural space<ul><li>Symbolic is comprehensible but not robust<ul><li>11: <a href="http://www.cs.cmu.edu/~tom/pubs/lao-emnlp11.pdf" target="_blank" rel="noopener">Random Walk Inference and Learning in A Large Scale Knowledge Base</a>:Ni Lao(Carnegie Mellon University)</li><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>:Stephen D.Richardson(Microsoft Research)</li></ul></li><li>Neural is robust but not comprehensible<ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>15: <a href="https://arxiv.org/abs/1412.6575" target="_blank" rel="noopener">EMBEDDING ENTITIES AND RELATIONS FOR LEARNING AND INFERENCE IN KNOWLEDGE BASES</a>:Bishan Yang(Cornell University)</li></ul></li><li>Hybrid is robust and  comprehensible<ul><li>18: <a href="https://arxiv.org/pdf/1802.04394.pdf" target="_blank" rel="noopener">M-Walk: Learning to Walk in Graph with Monte Carlo Tree Search</a>:Yelong Shen(Microsoft Research&amp;Tecent AI Lab)</li><li>18: <a href="https://arxiv.org/abs/1707.06690" target="_blank" rel="noopener">DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning</a>:Wenhan Xiong(University of California,Santa Barbara), <a href="https://github.com/xwhan/DeepPath" target="_blank" rel="noopener">code1</a> <a href="https://github.com/arunarn2/DeepPathwithTensorforce" target="_blank" rel="noopener">code2</a></li><li>18: <a href="https://arxiv.org/abs/1711.05851" target="_blank" rel="noopener">GO FOR A WALK AND ARRIVE AT THE ANSWER: REASONING OVER PATHS IN KNOWLEDGE BASES USING REINFORCEMENT LEARNING</a>:Rajarshi Das(University of Massachusetts,Amherst), </li></ul></li></ul></li><li>Multi-turn KB-QA<ul><li>Programmed Dialogue policy<ul><li>15: <a href="https://arxiv.org/pdf/1504.07182.pdf" target="_blank" rel="noopener">A Probabilistic Framework for Representing Dialog Systems and Entropy-Based Dialog Management through Dynamic Stochastic State Evolution</a>:Ji Wu(IEEE)</li></ul></li><li>Trained via RL Dialogue policy<ul><li>16: <a href="https://arxiv.org/abs/1604.04562" target="_blank" rel="noopener">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>:Tsung-Hsien Wen(Cambridge University)</li><li>17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)</li></ul></li></ul></li></ol><h4 id="Text-QA"><a href="#Text-QA" class="headerlink" title="Text-QA"></a>Text-QA</h4><ol><li>MS MARCO<ul><li>16: <a href="https://arxiv.org/abs/1611.09268" target="_blank" rel="noopener">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</a>:Tri Nguyan(Microsoft AI&amp;Research)</li></ul></li><li>SQuAD<ul><li>16: <a href="https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf" target="_blank" rel="noopener">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a>:Pranav Rajpurkar(Stanford University)</li></ul></li></ol><h3 id="Neural-MRC-Models"><a href="#Neural-MRC-Models" class="headerlink" title="Neural MRC Models"></a>Neural MRC Models</h3><h4 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h4><ul><li>16: <a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION</a>:Minjoon Seo(University of Washington)<ul><li><a href="https://github.com/imraviagrawal/ReadingComprehension" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/bentrevett/bidaf" target="_blank" rel="noopener">code2</a> </li><li><a href="https://github.com/akhil-vader/MachineComprehension_SQuAD" target="_blank" rel="noopener">code3</a> </li><li><a href="https://github.com/RamkishanPanthena/Machine-Comprehension-using-SQuAD-Dataset" target="_blank" rel="noopener">code4</a></li></ul></li></ul><h4 id="SAN"><a href="#SAN" class="headerlink" title="SAN"></a>SAN</h4><ul><li>18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul><h4 id="Neural-MRC-Models-on-SQuAD"><a href="#Neural-MRC-Models-on-SQuAD" class="headerlink" title="Neural MRC Models on SQuAD"></a><strong>Neural MRC Models on SQuAD</strong></h4><ol><li><p>Encoding: map each text span to a semantic vector</p><ul><li>Word Embedding<ul><li>14: <a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a>:Jeffrey Pennington(Stanford University)<ul><li><a href="https://github.com/brangerbriz/midi-glove" target="_blank" rel="noopener">code:midi-glove</a></li><li><a href="https://github.com/fdurant/wiki_glove" target="_blank" rel="noopener">code:wiki-glove</a></li></ul></li><li>13: <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a>:Tomas Mikolov(Google Inc.)<ul><li><a href="https://github.com/brijml/mikolov_word2vec" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/shuuchen/keras_word2vec" target="_blank" rel="noopener">code2</a><ul><li>Context Embedding</li></ul></li></ul></li></ul></li></ul><ol><li>capture context info for each word<ul><li>16: <a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li><li>18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li><li>Context Embedding via BiLSTM/ELmo<ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>17: <a href="https://arxiv.org/abs/1708.00107" target="_blank" rel="noopener">Learned in Translation: Contextualized Word Vectors</a>:Bryan McCann(SalesForce)</li><li>16: [duplicate]<a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li></ul></li><li>Context Embedding<ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li></ol><ul><li>Query-context/Content-query attention</li></ul></li><li><p>Reasoning: rank and re-rank semantic vectors</p><ul><li><p>Multi-step reasoning for Text-QA</p><ul><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Stochastic Answer Net</p><ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul></li></ul></li></ol><hr><h2 id="Task-oriented-dialogues"><a href="#Task-oriented-dialogues" class="headerlink" title="Task-oriented dialogues"></a>Task-oriented dialogues</h2><h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><h4 id="A-Example-Dialogue-with-Movie-Bot"><a href="#A-Example-Dialogue-with-Movie-Bot" class="headerlink" title="A Example Dialogue with Movie-Bot"></a>A Example Dialogue with Movie-Bot</h4><ul><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a><h4 id="Conversation-as-Reinforcement-Learning"><a href="#Conversation-as-Reinforcement-Learning" class="headerlink" title="Conversation as Reinforcement Learning"></a>Conversation as Reinforcement Learning</h4></li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)<h4 id="Dialogue-System-Evaluation-Simulated-Users"><a href="#Dialogue-System-Evaluation-Simulated-Users" class="headerlink" title="Dialogue System Evaluation(Simulated Users)"></a>Dialogue System Evaluation(Simulated Users)</h4></li></ul><ol><li>Agenda based<ul><li>09: <a href="https://ieeexplore.ieee.org/document/4806280/" target="_blank" rel="noopener">The Hidden Agenda User Simulation Model</a>:Jost Schatzmann(IEEE)</li><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a> </li></ul></li><li>Model based<ul><li>16: <a href="https://arxiv.org/abs/1607.00070" target="_blank" rel="noopener">A Sequence-to-Sequence Model for User Simulation in Spoken Dialogue Systems</a>: Layla El Asri(Maluuba Research)</li><li>17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul></li></ol><h3 id="traditional-approache"><a href="#traditional-approache" class="headerlink" title="traditional approache"></a>traditional approache</h3><h4 id="Decison-theoretic-View-of-Dialogue-Management"><a href="#Decison-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decison-theoretic View of Dialogue Management"></a>Decison-theoretic View of Dialogue Management</h4><ul><li>[<strong>duplicate</strong>] 00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System</a>:Satinder Singh(AT&amp;T Labs)</li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>00: <a href="http://www.aclweb.org/anthology/P98-2219" target="_blank" rel="noopener">Learning Optimal Dialogue Strategies: A Case Study of a Spoken Dialogue Agent for Email</a>: Marilyn A.Walker(ATT Labs Research)</li><li>02: <a href="https://dl.acm.org/citation.cfm?id=1289246" target="_blank" rel="noopener">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li></ul><h4 id="Language-Understanding-Uncertainty-POMDP-as-a-principled-framework"><a href="#Language-Understanding-Uncertainty-POMDP-as-a-principled-framework" class="headerlink" title="Language Understanding Uncertainty: POMDP as a principled framework"></a>Language Understanding Uncertainty: POMDP as a principled framework</h4><ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">Spoken Dialogue Management Using Probabilistic Reasoning</a>: Nicholas Roy(Carnegie Mellon University)</li><li>01: <a href="http://www.wytsg.org:88/reslib/400/180/110/020/010/130/L000000000233767.pdf" target="_blank" rel="noopener">Spoken Dialogue Management as Planning and Acting under Uncertainty</a>:Bo Zhang(Tech. of China)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul><h4 id="scaling-up-Dialogue-Optimization"><a href="#scaling-up-Dialogue-Optimization" class="headerlink" title="scaling up Dialogue Optimization"></a>scaling up Dialogue Optimization</h4><ol><li>Use approxmiate POMDP algorithms leveraging problem-specific structure<ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning</a>:Konrad Scheffler(Cambridge University)</li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">Partially observable Markov decision processes for spoken dialog systems</a>:Jason D.Williams(AT&amp;T Labs)</li></ul></li><li>Use Reinforcement Learning algorithms with function approximation<ul><li>08: <a href="http://www.aclweb.org/anthology/J08-4002" target="_blank" rel="noopener">Hybrid Reinforcement/Supervised Learning of Dialogue Policies from Fixed Data Sets</a>: James Henderson</li><li>09: <a href="https://pdfs.semanticscholar.org/a950/d7836e101e7d649791714d8383a804a6f671.pdf" target="_blank" rel="noopener">Reinforcement Learning for Dialog Management using Least-Squares Policy Iteration and Fast Feature Selection</a>: Lihong Li(Rutgers University)</li><li>14: <a href="http://mi.eng.cam.ac.uk/~sjy/papers/gktb14.pdf" target="_blank" rel="noopener">Incremental on-line adaptation of POMDP-based dialogue managers to extended domains</a>:M.Gasic[Cambridge University]</li></ul></li></ol><h3 id="Natural-language-understanding-and-dialogue-state-tracking"><a href="#Natural-language-understanding-and-dialogue-state-tracking" class="headerlink" title="Natural language understanding and dialogue state tracking"></a>Natural language understanding and dialogue state tracking</h3><h4 id="Language-Understanding"><a href="#Language-Understanding" class="headerlink" title="Language Understanding"></a>Language Understanding</h4><ol><li><p>DNN for Domain/Intent Classification</p><ul><li>15:  <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RNNLM_addressee.pdf" target="_blank" rel="noopener">Recurrent Neural Network and LSTM Models for Lexical Utterance Classification</a>: Suman Raviuri(University of California,Berkeley)</li></ul></li><li><p>Slot filling</p><ul><li>16: <a href="https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_MultiJoint.pdf" target="_blank" rel="noopener">Multi-Domain Joint Semantic Frame Parsing using Bi-directional RNN-LSTM</a>: Dilek Hakkani-Tur(Microsoft Research)</li></ul></li><li><p>Further details on NLU</p><ul><li><a href="https://www.csie.ntu.edu.tw/~yvchen/doc/OpenDialogue_Tutorial_IJCNLP.pdf" target="_blank" rel="noopener">ppt</a></li><li>E2E MemNN for Contectual LU: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/IS16_ContextualSLU.pdf" target="_blank" rel="noopener">End-to-End Memory Networks with Knowledge Carryover for Multi-Turn Spoken Language Understanding</a>: Yun-Nung Chen(National Taiwan University )</li><li>[<strong>duplicate</strong>] LU Importance: 17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul></li></ol><h4 id="Dialogue-State-Tracking-DST"><a href="#Dialogue-State-Tracking-DST" class="headerlink" title="Dialogue State Tracking(DST)"></a>Dialogue State Tracking(DST)</h4><ol><li>DSTC(Dialog State Tracking Challenge)<ul><li><a href="https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/" target="_blank" rel="noopener">DSTC1 official website</a></li><li><a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="noopener">DSTC2&amp;3 official website</a></li><li><a href="http://www.colips.org/workshop/dstc4/" target="_blank" rel="noopener">DSTC4 official website</a></li><li><a href="http://workshop.colips.org/dstc5/" target="_blank" rel="noopener">DSTC5 official website</a></li></ul></li><li><p>Neural Belief Tracker</p><ul><li>16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li></ul></li><li><p>NN-Based DST</p><ul><li>13: <a href="http://www.anthology.aclweb.org/W/W13/W13-4073.pdf" target="_blank" rel="noopener">Deep Neural Network Approach for the Dialog State Tracking Challenge</a>: Matthew Henderson(University of Cambridge)</li><li>15: <a href="https://arxiv.org/abs/1506.07190" target="_blank" rel="noopener">Multi-domain Dialog State Tracking using Recurrent Neural Networks</a>: Nikola Mrksic(University of Cambridge)</li><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">Neural Belief Tracker: Data-Driven Dialogue State Tracking</a>: Nikola Mrksic(University of Cambridge)</li></ul></li></ol><h3 id="Deep-RL-for-dialogue-policy-learning"><a href="#Deep-RL-for-dialogue-policy-learning" class="headerlink" title="Deep RL for dialogue policy learning"></a>Deep RL for dialogue policy learning</h3><h4 id="Two-main-classed-of-RL-algorithms"><a href="#Two-main-classed-of-RL-algorithms" class="headerlink" title="Two main classed of RL algorithms"></a>Two main classed of RL algorithms</h4><ol><li>Value function based:<ul><li>15: <a href="https://www.nature.com/articles/nature14236" target="_blank" rel="noopener">Human-level control through deep reinforcement learning</a>: Volodymyr Minh<ul><li><a href="https://github.com/devsisters/DQN-tensorflow" target="_blank" rel="noopener">code1</a> by tensorflow</li><li><a href="https://github.com/pianomania/DQN-pytorch" target="_blank" rel="noopener">code2</a> by pytorch</li></ul></li><li>16: <a href="https://arxiv.org/pdf/1606.02560.pdf" target="_blank" rel="noopener">Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning</a>: Tiancheng Zhao(Carnegie Mellon University)</li></ul></li><li>Policy based:<ul><li>92: <a href="https://doi.org/10.1007/BF00992696" target="_blank" rel="noopener">Simple statistical gradient-following algorithms for connectionist reinforcement learning</a>: Ronald J.Williams</li><li>17: <a href="http://www.aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="noopener">On-line Active Reward Learning for Policy Optimisation in Spoken Dialogue Systems</a>: Pei-Hao Su(University of Cambridge)<h4 id="Domain-Extension-and-Exploration-BBQ-network"><a href="#Domain-Extension-and-Exploration-BBQ-network" class="headerlink" title="Domain Extension and Exploration(BBQ network)"></a>Domain Extension and Exploration(BBQ network)</h4></li></ul></li></ol><ul><li>18: <a href="https://arxiv.org/pdf/1608.05081.pdf" target="_blank" rel="noopener">BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems</a>: Zachary Lipton(Carnegir Mellon University)</li></ul><h4 id="Composite-task-Dialogues"><a href="#Composite-task-Dialogues" class="headerlink" title="Composite-task Dialogues"></a>Composite-task Dialogues</h4><ol><li>A Hierarchical Policy Learner<ul><li>98: <a href="http://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines.pdf" target="_blank" rel="noopener">Reinforcement Learning with Hierarchies of Machines</a>: Ronald Parr(UC Berkeley)</li><li>17: <a href="https://arxiv.org/abs/1704.03084" target="_blank" rel="noopener">Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning</a>: Baolin Peng(Microsoft Research)</li></ul></li><li>Integrating Planning for Dialogue Policy Learning<ul><li>18: <a href="https://arxiv.org/abs/1801.06176" target="_blank" rel="noopener">Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning</a>: Baolin Peng(Microsoft Research) , <a href="https://github.com/MiuLab/DDQ" target="_blank" rel="noopener">code</a></li></ul></li></ol><h3 id="Decision-theoretic-View-of-Dialogue-Management"><a href="#Decision-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decision-theoretic View of Dialogue Management"></a>Decision-theoretic View of Dialogue Management</h3><h4 id="Hybrid-Code-Networks"><a href="#Hybrid-Code-Networks" class="headerlink" title="Hybrid Code Networks"></a>Hybrid Code Networks</h4><ul><li>17: <a href="https://arxiv.org/abs/1702.03274" target="_blank" rel="noopener">Hybrid Code Networks: practical and efficient end-to-end dialog control with supervised and reinforcement learning</a>: Jason D. Williams(Microsoft Research)<h4 id="Differentiating-KB-Accesses"><a href="#Differentiating-KB-Accesses" class="headerlink" title="Differentiating KB Accesses"></a>Differentiating KB Accesses</h4></li><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)<h4 id="An-E2E-Neural-Dialogue-System"><a href="#An-E2E-Neural-Dialogue-System" class="headerlink" title="An E2E Neural Dialogue System"></a>An E2E Neural Dialogue System</h4></li><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">End-to-End Task-Completion Neural Dialogue Systems</a>:Xiujun Li(Microsoft Research&amp;National Taiwan University)</li></ul><hr><h2 id="Fully-data-driven-conversation-models-and-chatbots"><a href="#Fully-data-driven-conversation-models-and-chatbots" class="headerlink" title="Fully data-driven conversation models and chatbots"></a>Fully data-driven conversation models and chatbots</h2><h3 id="Historical-overview"><a href="#Historical-overview" class="headerlink" title="Historical overview"></a>Historical overview</h3><h4 id="Response-retrival-system"><a href="#Response-retrival-system" class="headerlink" title="Response retrival system"></a>Response retrival system</h4><ul><li>10: <a href="https://aritter.github.io/chat.pdf" target="_blank" rel="noopener">Filter, Rank, and Transfer the Knowledge: Learning to Chat</a>:<br>Alan Ritter(University of Washington)</li></ul><h4 id="Response-generation-using-Statistical-Machine-Translation"><a href="#Response-generation-using-Statistical-Machine-Translation" class="headerlink" title="Response generation using Statistical Machine Translation"></a>Response generation using Statistical Machine Translation</h4><ul><li>11:  <a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener">Data-Driven Response Generation in Social Media</a>: Alan Ritter(University of Washington)</li></ul><h4 id="First-neural-response-generation-systems"><a href="#First-neural-response-generation-systems" class="headerlink" title="First neural response generation systems"></a>First neural response generation systems</h4><ol><li>Neural Models for Response Generation<ul><li>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener">A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</a>: Alessandro Sordoni(University de Montreal)</li><li>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener">A Neural Conversational Model</a>: Oriol Vinyals(Google .Inc)</li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener">Neural Responding Machine for Short-Text Conversation</a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener">code</a></li></ul></li><li>Neural conversation engine: <ul><li>16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)</li></ul></li></ol><h3 id="challenges-and-remedies"><a href="#challenges-and-remedies" class="headerlink" title="challenges and remedies"></a>challenges and remedies</h3><h4 id="Challenge-The-blandness-problem"><a href="#Challenge-The-blandness-problem" class="headerlink" title="Challenge: The blandness problem"></a>Challenge: The blandness problem</h4><ul><li>[<strong>duplicate</strong>] 16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">A Diversity-Promoting Objective Function for Neural Conversation Models</a>: Jiwei Li(Stanford University)<h4 id="Challenge-The-consistency-problem"><a href="#Challenge-The-consistency-problem" class="headerlink" title="Challenge: The consistency problem"></a>Challenge: The consistency problem</h4></li></ul><ol><li>Solution: Personalized Response Generation<ul><li>Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li></ul></li><li>Personal modeling as multi-task learning<ul><li>17: <a href="https://arxiv.org/abs/1710.07388" target="_blank" rel="noopener">Multi-Task Learning for Speaker-Role Adaptation in Neural Conversation Models</a>: Yi Luan(University of Washington)</li></ul></li><li>Improving personalization with multiple losses<ul><li>16: <a href="https://arxiv.org/pdf/1606.00372.pdf" target="_blank" rel="noopener">Conversational Contextual Cues: The Case of Personalization and History for Response Ranking</a>: Rami Al-Rfou(Google .Inc)<h4 id="Challenge-Long-conversational-context"><a href="#Challenge-Long-conversational-context" class="headerlink" title="Challenge: Long conversational context"></a>Challenge: Long conversational context</h4></li></ul></li><li>It can be challenging for LSTM/GRU to encode very long context<ul><li>18: <a href="https://arxiv.org/abs/1805.04623" target="_blank" rel="noopener">Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context</a>: Urvashi Khadelwal(Stanford University)</li></ul></li><li>Hierarchical Encoder-Decoder(HRED), <a href="https://github.com/urvashik/lm-context-analysis" target="_blank" rel="noopener">code</a><ul><li>16: <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160" target="_blank" rel="noopener">Building End-to-End Dialogue Systems Using Generative Hierarchical Neural Network Models</a>: Iulian V.Serban(University de Montreal), <a href="https://github.com/hsgodhia/hred" target="_blank" rel="noopener">code</a></li></ul></li><li>Hierarchical Latent Variable Encoder-Decoder(VHRED)<ul><li>17: <a href="http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf" target="_blank" rel="noopener">A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</a>: Iulian V. Serban</li></ul></li></ol><h3 id="Grounded-conversation-models"><a href="#Grounded-conversation-models" class="headerlink" title="Grounded conversation models"></a>Grounded conversation models</h3><h4 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a>A Knowledge-Grounded Neural Conversation Model</h4><ul><li>15: <a href="https://arxiv.org/pdf/1503.08895.pdf" target="_blank" rel="noopener">End-To-End Memory Networks</a>: Sainbayar Sukhbaatar(New York University)<ul><li><a href="https://github.com/carpedm20/MemN2N-tensorflow" target="_blank" rel="noopener">code1</a> via Tensorflow</li><li><a href="https://github.com/domluna/memn2n" target="_blank" rel="noopener">code2</a> via Tensorflow</li><li><a href="https://github.com/vinhkhuc/MemN2N-babi-python" target="_blank" rel="noopener">code3</a> for bAbI QA tasks</li></ul></li><li>17: <a href="https://arxiv.org/abs/1702.01932" target="_blank" rel="noopener">A Knowledge-Grounded Neural Conversation Model</a>: Marjan Gahzvininejad(USC)<h4 id="Grounded-E2E-Dialogue-Systems"><a href="#Grounded-E2E-Dialogue-Systems" class="headerlink" title="Grounded E2E Dialogue Systems"></a>Grounded E2E Dialogue Systems</h4></li><li>16: <a href="https://arxiv.org/abs/1611.08669" target="_blank" rel="noopener">Visual Dialog</a>: Abhishek Das(Georgia Institute of Tehhnology)<ul><li><a href="https://github.com/batra-mlp-lab/visdial" target="_blank" rel="noopener">code1</a> via Lua</li><li><a href="https://github.com/jiasenlu/visDial.pytorch" target="_blank" rel="noopener">code2</a> via Pytorch</li></ul></li><li>17: <a href="https://arxiv.org/abs/1701.08251" target="_blank" rel="noopener">Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation</a>: Nasrin Mostafazadeh(University of Rochster)</li><li>18: <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/04/huber2018chi.small_.pdf" target="_blank" rel="noopener">Emotional Dialogue Generation using Image-Grounded Language Models</a>:Bernd Huber(Harvard University)</li></ul><h3 id="Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue"><a href="#Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue" class="headerlink" title="Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)"></a>Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)</h3><ul><li>16: <a href="https://arxiv.org/abs/1606.01541" target="_blank" rel="noopener">Deep Reinforcement Learning for Dialogue Generation</a>:Jiwei Li(Stanford University)<ul><li><a href="https://github.com/liuyuemaicha/Deep-Reinforcement-Learning-for-Dialogue-Generation-in-tensorflow" target="_blank" rel="noopener">code1</a> via Tensorflow</li><li><a href="https://github.com/agsarthak/Goal-oriented-Dialogue-Systems" target="_blank" rel="noopener">code2</a> via keras</li><li><a href="https://github.com/jiweil/Neural-Dialogue-Generation" target="_blank" rel="noopener">code3</a> by Jiwei Li</li></ul></li></ul><h3 id="Data-and-evaluation"><a href="#Data-and-evaluation" class="headerlink" title="Data and evaluation"></a>Data and evaluation</h3><h4 id="Conversational-datasets-for-social-bots-E2E-dialogue-research"><a href="#Conversational-datasets-for-social-bots-E2E-dialogue-research" class="headerlink" title="Conversational datasets(for social bots, E2E dialogue research)"></a>Conversational datasets(for social bots, E2E dialogue research)</h4><ul><li>15: <a href="https://arxiv.org/abs/1512.05742" target="_blank" rel="noopener">A Survey of Available Corpora for Building Data-Driven Dialogue Systems</a>: Iulian Vlad Serban(Universite de Montreal)<h4 id="Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation"><a href="#Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation" class="headerlink" title="Evaluating E2E Dialogue Systems via Autumatic evaluation"></a>Evaluating E2E Dialogue Systems via Autumatic evaluation</h4></li></ul><ol><li>Machine-Translation-Based Metric<ul><li>02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>02: <a href="http://www.mt-archive.info/HLT-2002-Doddington.pdf" target="_blank" rel="noopener">Automatic Evaluation of Machine Translation Quality Using N-gram Co-Occurrence Statistics</a>: George Doddington</li></ul></li><li>Sentence-level correlation of MT metrics:<ul><li>16: <a href="https://aclweb.org/anthology/D16-1230" target="_blank" rel="noopener">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</a>: Chia-Wei Liu(McGill University)</li><li>15: <a href="http://www.aclweb.org/anthology/N15-1124" target="_blank" rel="noopener">Accurate Evaluation of Segment-level Machine Translation Metrics</a>: Yvette Graham(The University of Melbourne)</li></ul></li></ol><h4 id="The-importance-of-sample-size"><a href="#The-importance-of-sample-size" class="headerlink" title="The importance of sample size"></a>The importance of sample size</h4><ul><li>[<strong>duplicate</strong>] 02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>06: <a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf" target="_blank" rel="noopener">Statistical Significance Tests for Machine Translation Evaluation</a>: Philipp Kowehn(MIT)</li></ul><h4 id="Corpus-level-Correlation"><a href="#Corpus-level-Correlation" class="headerlink" title="Corpus-level Correlation"></a>Corpus-level Correlation</h4><ul><li>[<strong>duplicate</strong>] 02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">BLEU: a Method for Automatic Evaluation of Machine Translation</a>: Kishore Papineni(IBM), <a href="https://github.com/abidasari/NLPHW4" target="_blank" rel="noopener">code</a></li><li>[<strong>duplicate</strong>] 06: <a href="http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf" target="_blank" rel="noopener">Statistical Significance Tests for Machine Translation Evaluation</a>: </li></ul><h3 id="Chatbot-in-public"><a href="#Chatbot-in-public" class="headerlink" title="Chatbot in public"></a>Chatbot in public</h3><h4 id="Social-Bots-commercial-systems"><a href="#Social-Bots-commercial-systems" class="headerlink" title="Social Bots: commercial systems"></a>Social Bots: commercial systems</h4><ol><li>For end users<ul><li>Replika.ai system description: <a href="https://github.com/lukalabs/replika-research/blob/master/scai2017/replika_ai.pdf" target="_blank" rel="noopener">replika_ai</a>: Slides</li><li>XiaoIce:<br>15:<a href="https://www.nytimes.com/interactive/2015/07/27/science/chatting-with-xiaoice.html" target="_blank" rel="noopener">Chatting With Xiaoice</a>: News</li></ul></li><li>For bot developers<ul><li>[<strong>duplicate</strong>] Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li><li>Microsoft Personality chat’s API: <a href="https://labs.cognitive.microsoft.com/en-us/project-personality-chat" target="_blank" rel="noopener">Project Personality Chat’s url</a> </li></ul></li></ol><h4 id="Open-Benchmarks"><a href="#Open-Benchmarks" class="headerlink" title="Open Benchmarks"></a>Open Benchmarks</h4><ol><li><p>Alexa Challenge</p><ul><li>website: <a href="https://developer.amazon.com/alexaprize/proceedings" target="_blank" rel="noopener">Alexa Prize Proceedings</a></li></ul></li><li><p>Dialogue System Technology Challenge(DSTC)</p><ul><li><a href="http://workshop.colips.org/dstc7" target="_blank" rel="noopener">DSTC7</a></li><li>Visual-Scene: <a href="https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge" target="_blank" rel="noopener">DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge 2018</a></li><li>background article:<br><a href="https://github.com/DSTC-MSR-NLP/DSTC7-End-to-End-Conversation-Modeling" target="_blank" rel="noopener">DSTC7-End-to-End-Conversation-Modeling 2018</a></li><li>Registration Link:<br><a href="http://workshop.colips.org/dstc7/call.html" target="_blank" rel="noopener">DSTC7 Registration</a></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;blockquote&gt;
&lt;p&gt;论文列表格式&lt;br&gt;&amp;emsp;论文发表年份： 论文题目&amp;amp;论文链接：第一作者（第一作者所属学校/机构），代码链接&lt;/p&gt;
&lt;/blockqu
      
    
    </summary>
    
      <category term="AI" scheme="https://824zzy.github.io/categories/AI/"/>
    
    
      <category term="chatbot" scheme="https://824zzy.github.io/tags/chatbot/"/>
    
      <category term="conversationalAI" scheme="https://824zzy.github.io/tags/conversationalAI/"/>
    
      <category term="nlp" scheme="https://824zzy.github.io/tags/nlp/"/>
    
      <category term="paper" scheme="https://824zzy.github.io/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>对话AI的术语和学习地图</title>
    <link href="https://824zzy.github.io/2018/08/08/convAI-map-and-term/"/>
    <id>https://824zzy.github.io/2018/08/08/convAI-map-and-term/</id>
    <published>2018-08-08T15:25:39.000Z</published>
    <updated>2018-08-24T06:59:54.094Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="chatbot基本篇"><a href="#chatbot基本篇" class="headerlink" title="chatbot基本篇"></a>chatbot基本篇</h2><ul><li><p>Natural language processing(自然语言处理/NLP)<br>自然语言处理是人工智能的一个子集领域。自然语言处理是一项包罗万象且相当复杂的技术，它包含许多子集，如自然语言理解。<br>NLP指的是机器理解人类输入的所有东西。为此，NLP引擎将使用许多工具，如NLU，总结算法，情绪分析，标记化等等。</p></li><li><p>Natural language understanding (自然语言理解/NLU)<br>自然语言理解是自然语言处理的一个子集。NLU和NLP经常被混淆，因为它们的意思非常接近。<br>NLU是NLP引擎中非常具体的部分，它检查话语并提取其实体和意图。用更通俗的话说，NLU允许机器理解用户在说什么。<br>说到聊天机器人，可以把NLU想象成阅读人类语言并识别文本不同部分的过程，把它分解成正确的意图和实体</p></li><li><p>Chatbot(聊天机器人)<br><code>chatbot</code>是一个可对话的计算机程序。但是<strong>对话agent</strong>可能是形容这个程序更好的词汇。</p></li><li><p>Utterance(表达)<br>用户对chatbot说的任何话，也可以看做是用户输入。例如，如果用户输入“给我看昨天的财经新闻”，整个句子就是<code>Utterance</code>。</p></li><li><p>Intent(意图))<br><code>Intent</code>代表了用户<code>Utterance</code>的意义。Chatbot将会根据用户一系列的<code>Intent</code>和对<code>Intent</code>的理解来回应用户。例如，如果用户输入“show me yesterday’s financial news”，用户的意图是检索金融标题列表。<code>Intent</code>通常是一个动词和一个名词，如“showNews”。</p></li><li><p>Entity(实体)<br><code>Entity</code>通常修饰<code>Intent</code>。例如，如果用户输入“show me yesterday’s financial news”，那么<code>Entity</code>是“yesterday”和“financial”。<code>Entity</code>会被赋予一个名称，例如“dateTime”和“newsType”。<code>Entity</code>有时也被称为<code>Slots</code>。</p></li></ul><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fu2otnnx3oj21r60x246f.jpg" alt=""></p><ul><li><p>Broadcast(广播)<br><code>Broadcast</code>是预先发送给用户的消息。它不是对用户输入的响应。<code>Broadcast</code>也被称为“订阅消息”，它相当于聊天机器人中的移动应用程序中的推送消息。</p></li><li><p>Ambiguity</p></li><li>Paraphrase</li><li>metric</li></ul><h2 id="术语进阶篇"><a href="#术语进阶篇" class="headerlink" title="术语进阶篇"></a>术语进阶篇</h2><h3 id="NLP常用术语"><a href="#NLP常用术语" class="headerlink" title="NLP常用术语"></a>NLP常用术语</h3><h4 id="词级别"><a href="#词级别" class="headerlink" title="词级别"></a>词级别</h4><ul><li>分词（Seg）</li><li>词性标注（POS）</li><li>命名实体识别（NER）</li><li>未登录词识别</li><li>词向量（word2vec）</li><li>词义消歧</li></ul><h4 id="句子级别"><a href="#句子级别" class="headerlink" title="句子级别"></a>句子级别</h4><ul><li>情感分析</li><li>关系提取</li><li>意图识别</li><li>依存句法分析（parser）</li><li>角色标注，</li><li>浅层语义分析，</li><li>指代消解</li></ul><h4 id="篇章级别"><a href="#篇章级别" class="headerlink" title="篇章级别"></a>篇章级别</h4><ul><li>信息抽取：</li><li>本体提取：</li><li>事件抽取：</li><li>主题提取：</li><li>文档聚类：</li><li>舆情分析：</li><li>篇章理解：</li><li>自动文摘：</li></ul><h4 id="常用基础算法："><a href="#常用基础算法：" class="headerlink" title="常用基础算法："></a>常用基础算法：</h4><ol><li><p>机器学习：</p><ul><li>隐马尔科夫（HMM）</li><li>条件随机场（CRF）</li><li>支持向量机（SVM）</li><li>语言模型</li><li>主题模型（LDA）</li><li>TF-IDF</li><li>互信息（PMI）</li><li>贝叶斯模型</li><li>概率图模型   </li></ul></li><li><p>深度学习:</p></li></ol><h3 id="Qustion-Answering-QA"><a href="#Qustion-Answering-QA" class="headerlink" title="Qustion Answering(QA)"></a>Qustion Answering(QA)</h3><h3 id="Reinfoecement-Learning-强化学习-RL"><a href="#Reinfoecement-Learning-强化学习-RL" class="headerlink" title="Reinfoecement Learning(强化学习/RL)"></a>Reinfoecement Learning(强化学习/RL)</h3><h3 id="Markov-Decision-Process-马尔科夫决策过程-MDP"><a href="#Markov-Decision-Process-马尔科夫决策过程-MDP" class="headerlink" title="Markov Decision Process(马尔科夫决策过程/MDP)"></a>Markov Decision Process(马尔科夫决策过程/MDP)</h3><h3 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP"></a>POMDP</h3><h3 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h3><h3 id="Phonology"><a href="#Phonology" class="headerlink" title="Phonology"></a>Phonology</h3><h3 id="分词（Segment）"><a href="#分词（Segment）" class="headerlink" title="分词（Segment）"></a>分词（Segment）</h3><p>中英文都存在分词的问题，不过相对来说，英文单词与单词之间本来就有空格进行分割，所以处理起来相对方便。但是中文书写是没有分隔符的，所以分词的问题就比较突出。分词常用的手段可以是基于字典的最长串匹配，据说可以解决85%的问题，但是歧义分词很难。另外就是当下主流的统计机器学习的办法。</p><h3 id="词性标注（Label）"><a href="#词性标注（Label）" class="headerlink" title="词性标注（Label）"></a>词性标注（Label）</h3><p>基于机器学习的方法里，往往需要对词的词性进行标注。标注的目的是用来表示，词的一种隐状态，隐藏状态构成的转移就构成了状态转移序列。例如：苏宁易购/n 投资/v 了/u 国际米兰/n。其中，n代表名词，v代表动词，n,v都是标注。以此类推。</p><h3 id="命名实体识别（Named-Entity-Recognition）"><a href="#命名实体识别（Named-Entity-Recognition）" class="headerlink" title="命名实体识别（Named Entity Recognition）"></a>命名实体识别（Named Entity Recognition）</h3><p>本质上还是标注问题的一种。只不过把标注细化了。比如，苏宁/cmp_s 易购/cmp_e 是/v B2C/n 电商/n。我们把苏宁易购 标注成cmp_s和cmp_e,分别表征公司名的起始和结束。这样，当遇上苏宁/云商/易购这种场景时，也可以完整得识别出它是一个公司名称。如果，按照传统的标注方式，苏宁/cmp 易购/cmp这样笼统地标注可能会有问题。</p><h3 id="句法分析（Syntax-Parsing）"><a href="#句法分析（Syntax-Parsing）" class="headerlink" title="句法分析（Syntax Parsing）"></a>句法分析（Syntax Parsing）</h3><p>句法分析往往是一种基于规则的专家系统。当然也不是说它不能用统计学的方法进行构建，不过最初的时候，还是利用语言学专家的知识来构建的。句法分析的目的是解析句子的中各个成分的依赖关系。所以，往往最终生成的结果，是一棵句法分析树。句法分析可以解决传统词袋模型不考虑上下文的问题。比如，张三是李四的领导；李四是张三的领导。这两句话，用词袋模型是完全相同的，但是句法分析可以分析出其中的主从关系，真正理清句子的关系。</p><h3 id="指代消解-Anaphora-Resolution"><a href="#指代消解-Anaphora-Resolution" class="headerlink" title="指代消解(Anaphora Resolution)"></a>指代消解(Anaphora Resolution)</h3><p>中文中代词出现的频率很高，它的作用的是用来表征前文出现过的人名、地名等词。例如，苏宁易购坐落在南京，这家公司目前位于中国B2C市场前三。在这句话中，其实“苏宁易购”这个词出现了2次，“这家公司”指代的就是苏宁易购。但是出于中文的习惯，我们不会把“苏宁易购”再重复一遍。</p><h2 id="AI模型篇"><a href="#AI模型篇" class="headerlink" title="AI模型篇"></a>AI模型篇</h2><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h3 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h3><h3 id="Machine-Reading-Comprehension-MRC"><a href="#Machine-Reading-Comprehension-MRC" class="headerlink" title="Machine Reading Comprehension(MRC)"></a>Machine Reading Comprehension(MRC)</h3><h3 id="Knowledge-Base-QA-KBQA"><a href="#Knowledge-Base-QA-KBQA" class="headerlink" title="Knowledge Base-QA(KBQA)"></a>Knowledge Base-QA(KBQA)</h3><ul><li>WordNet(1998)</li><li>Freebase(2008)</li><li>Yago(2007)</li></ul><h3 id="Knowledge-base-completion-KBC"><a href="#Knowledge-base-completion-KBC" class="headerlink" title="Knowledge base completion(KBC)"></a>Knowledge base completion(KBC)</h3><h2 id="chatbot领域学习地图："><a href="#chatbot领域学习地图：" class="headerlink" title="chatbot领域学习地图："></a>chatbot领域学习地图：</h2><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fue50ug6o9j217m88pb2c.jpg" alt=""></p><blockquote><p>参考与引用</p><ol><li><a href="https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/</a></li><li><a href="https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4" target="_blank" rel="noopener">https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4</a></li><li><a href="https://blog.ubisend.com/discover-chatbots/chatbot-glossary" target="_blank" rel="noopener">https://blog.ubisend.com/discover-chatbots/chatbot-glossary</a></li><li><a href="https://blog.csdn.net/wangongxi/article/details/52662177" target="_blank" rel="noopener">https://blog.csdn.net/wangongxi/article/details/52662177</a></li><li><a href="https://www.jianshu.com/p/d7ec29abbcb8" target="_blank" rel="noopener">https://www.jianshu.com/p/d7ec29abbcb8</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;chatbot基本篇&quot;&gt;&lt;a href=&quot;#chatbot基本篇&quot; class=&quot;headerlink&quot; title=&quot;chatbot基本篇&quot;&gt;&lt;/a&gt;chatbo
      
    
    </summary>
    
      <category term="AI" scheme="https://824zzy.github.io/categories/AI/"/>
    
    
      <category term="chatbot" scheme="https://824zzy.github.io/tags/chatbot/"/>
    
      <category term="conversationalAI" scheme="https://824zzy.github.io/tags/conversationalAI/"/>
    
      <category term="nlp" scheme="https://824zzy.github.io/tags/nlp/"/>
    
  </entry>
  
  <entry>
    <title>深度学习手写笔记</title>
    <link href="https://824zzy.github.io/2018/08/03/Deeplearning-note/"/>
    <id>https://824zzy.github.io/2018/08/03/Deeplearning-note/</id>
    <published>2018-08-03T06:36:43.000Z</published>
    <updated>2018-08-03T06:43:03.756Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><div class="row"><iframe src="https://drive.google.com/file/d/14hBEl8WUtbBdDHcIE4uAMledytupRDzP/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;

	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/14hBEl8WUtbBdDHcIE4uAM
      
    
    </summary>
    
      <category term="HandWriting" scheme="https://824zzy.github.io/categories/HandWriting/"/>
    
    
      <category term="deepLearning" scheme="https://824zzy.github.io/tags/deepLearning/"/>
    
  </entry>
  
  <entry>
    <title>博客主题配置</title>
    <link href="https://824zzy.github.io/2018/07/26/blog-config/"/>
    <id>https://824zzy.github.io/2018/07/26/blog-config/</id>
    <published>2018-07-25T16:00:00.000Z</published>
    <updated>2018-08-18T06:23:28.142Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="hexo基本使用"><a href="#hexo基本使用" class="headerlink" title="hexo基本使用"></a>hexo基本使用</h2><h3 id="创建新页面"><a href="#创建新页面" class="headerlink" title="创建新页面"></a>创建新页面</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo new page your_page_name</span><br></pre></td></tr></table></figure><p>执行命令后会生成<code>/source/your_page_name/index.md</code>。</p><p>接着在<code>theme/next/_condig.yml</code>找到<code>menu</code>属性设置路由即可。</p><p>如有必要，需要在<code>theme/next/languages</code>找到<code>menu</code>进行设置。</p><h3 id="创建新博客文章"><a href="#创建新博客文章" class="headerlink" title="创建新博客文章"></a>创建新博客文章</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 创建新的文章</span><br><span class="line">hexo new post your_post_name</span><br><span class="line"><span class="meta">#</span> 创建新的草稿</span><br><span class="line">hexo new draft your_draft_name</span><br></pre></td></tr></table></figure><h2 id="博客主题的基本配置"><a href="#博客主题的基本配置" class="headerlink" title="博客主题的基本配置"></a>博客主题的基本配置</h2><p>博客基本信息修改位置为：<code>/_config.yml</code></p><h3 id="博客logo修改位置为："><a href="#博客logo修改位置为：" class="headerlink" title="博客logo修改位置为："></a>博客logo修改位置为：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/themes/next/source/images/apple-touch-icon-next.png;/themes/next/source/images/favicon-16*16-next.png;/themes/next/source/images/favicon-32*32-next.png;</span><br></pre></td></tr></table></figure><p>三个文件需要修改，缩放图片建议使用百度搜索的<strong>改图宝</strong>。</p><h3 id="博客大背景图片修改位置为："><a href="#博客大背景图片修改位置为：" class="headerlink" title="博客大背景图片修改位置为："></a>博客大背景图片修改位置为：</h3><p><code>/theme/next/source/css/_custom/custom.styl</code></p><h3 id="在右上角实现fork-me-on-github"><a href="#在右上角实现fork-me-on-github" class="headerlink" title="在右上角实现fork me on github:"></a>在右上角实现fork me on github:</h3><p>从<a href="https://github.com/blog/273-github-ribbons" target="_blank" rel="noopener">这里</a>复制代码到<code>themes/next/layout/_layout.swig</code>文件中的<code>&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</code>一句下面并修改<code>href</code>。</p><h3 id="点击动画特效："><a href="#点击动画特效：" class="headerlink" title="点击动画特效："></a>点击动画特效：</h3><p>修改位置为<code>themes/next/source/js/src/click-effect.js</code>，动画特效可以自己DIY,默认设置的特效为社会主义核心价值观。</p><h3 id="修改文章底部的那个带-号的标签为更漂亮的样式："><a href="#修改文章底部的那个带-号的标签为更漂亮的样式：" class="headerlink" title="修改文章底部的那个带#号的标签为更漂亮的样式："></a>修改文章底部的那个带#号的标签为更漂亮的样式：</h3><p>修改模板<code>/themes/next/layout/_macro/post.swig</code>，搜索<code>rel=&quot;tag&quot;&gt;#</code>，将<code>#</code>换成<code>&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code></p><h3 id="修改作者头像："><a href="#修改作者头像：" class="headerlink" title="修改作者头像："></a>修改作者头像：</h3><p><code>/themes/next/source/images/avater.jpg</code></p><h3 id="语言设置bug"><a href="#语言设置bug" class="headerlink" title="语言设置bug:"></a>语言设置bug:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.在hexo 文件夹里主题 next文件夹里的language 文件夹 找到 zh-Hans.yml 重命名 zh-CN.yml</span><br><span class="line">2.在hexo 文件夹里的_config.yml 修改 language: zh-CN</span><br></pre></td></tr></table></figure><h3 id="文章加密访问："><a href="#文章加密访问：" class="headerlink" title="文章加密访问："></a>文章加密访问：</h3><p>打开<code>themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig</code>文件，在<code>rel=&quot;stylesheet&quot;</code>的下一行添加如下代码：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">    (<span class="function"><span class="keyword">function</span> (<span class="params"></span>) </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">'&#123;&#123; page.password &#125;&#125;'</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (prompt(<span class="string">'请输入文章密码'</span>) !== <span class="string">'&#123;&#123; page.password &#125;&#125;'</span>) &#123;</span><br><span class="line">                alert(<span class="string">'密码错误！'</span>);</span><br><span class="line">                <span class="keyword">if</span> (history.length === <span class="number">1</span>) &#123;</span><br><span class="line">                    location.replace(<span class="string">"http://xxxxxxx.xxx"</span>); <span class="comment">// 这里替换成你的首页</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    history.back();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;)();</span><br><span class="line">&lt;<span class="regexp">/script&gt;</span></span><br></pre></td></tr></table></figure></p><p>使用方法如下：<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1ftorxsujudj20k00c6dgz.jpg" alt=""></p><h3 id="友情链接设置：在-themes-next-config-yml的Blog-rolls中这只链接即可"><a href="#友情链接设置：在-themes-next-config-yml的Blog-rolls中这只链接即可" class="headerlink" title="友情链接设置：在/themes/next/_config.yml的Blog rolls中这只链接即可"></a>友情链接设置：在<code>/themes/next/_config.yml</code>的Blog rolls中这只链接即可</h3><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># Blog rolls</span><br><span class="line">links_icon: link</span><br><span class="line">links_title: 友情链接</span><br><span class="line"># links_layout: block</span><br><span class="line">links_layout: inline</span><br><span class="line">links:</span><br><span class="line">  your links</span><br></pre></td></tr></table></figure><h3 id="自定义鼠标样式："><a href="#自定义鼠标样式：" class="headerlink" title="自定义鼠标样式："></a>自定义鼠标样式：</h3><p>在<code>/themes/next/source/css/_custom/custom.styl</code>中添加如下代码</p><p>鼠标样式的<code>ico</code>文件有需要的话可以<a href="http://www.rw-designer.com/cursor-library" target="_blank" rel="noopener">来这里</a>自己DIY。</p><h3 id="博客添加打赏功能："><a href="#博客添加打赏功能：" class="headerlink" title="博客添加打赏功能："></a>博客添加打赏功能：</h3><p>在<code>/themes/next/_config.yml</code>中搜索reward并对收款码进行修改。</p><h2 id="第三方服务配置"><a href="#第三方服务配置" class="headerlink" title="第三方服务配置"></a>第三方服务配置</h2><h3 id="添加RSS"><a href="#添加RSS" class="headerlink" title="添加RSS:"></a>添加RSS:</h3><p>配置位置分别为<code>/_config.yml</code>与<code>/themes/next/_config.yml</code></p><h3 id="访客统计："><a href="#访客统计：" class="headerlink" title="访客统计："></a>访客统计：</h3><p>根据<a href="https://blog.csdn.net/ganzhilin520/article/details/79048021" target="_blank" rel="noopener">教程</a>，在leancloud注册并新建应用，获取id和key后填写到<code>_config.yml</code>里<code>leancloud_visitors</code>的属性中。</p><h3 id="为博客添加宠物："><a href="#为博客添加宠物：" class="headerlink" title="为博客添加宠物："></a>为博客添加宠物：</h3><p>在终端输入<code>npm install -save hexo-helper-live2d</code>在<code>/themes/next/_config.yml</code>中添加代码,详情请见<a href="https://github.com/EYHN/hexo-helper-live2d/blob/61b581634a916cf4ce035c1685174cb2755264f3/README.zh-CN.md" target="_blank" rel="noopener">这里</a></p><h3 id="博客在线显示pdf功能"><a href="#博客在线显示pdf功能" class="headerlink" title="博客在线显示pdf功能"></a>博客在线显示pdf功能</h3><p>首先安装插件<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install --save hexo-pdf</span><br></pre></td></tr></table></figure></p><p>使用方法为<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#123;% pdf http://your_pdf_link.pdf %&#125;</span><br><span class="line">&#123;% pdf ./your_pdf_**relative**_path %&#125;</span><br></pre></td></tr></table></figure></p><h3 id="修改博客的搜索功能："><a href="#修改博客的搜索功能：" class="headerlink" title="修改博客的搜索功能："></a>修改博客的搜索功能：</h3><p>建议使用algolia,因为swiftype已收费。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-algolia --save</span><br><span class="line">```    </span><br><span class="line">在`/themes/next/_config.yml`中搜索algolia,添加代码：</span><br><span class="line">``` js</span><br><span class="line">algolia:</span><br><span class="line">  applicationID: your_algolia_ud</span><br><span class="line">  apiKey: your_apiKey</span><br><span class="line">  indexName: your_index</span><br></pre></td></tr></table></figure></p><h3 id="文章置顶功能"><a href="#文章置顶功能" class="headerlink" title="文章置顶功能"></a>文章置顶功能</h3><p>安装第三方插件<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm uninstall hexo-generator-index --save</span><br></pre></td></tr></table></figure></p><p>对需要置顶的文章添加属性即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: hexo+GitHub博客搭建实战</span><br><span class="line">date: 2017-09-08 12:00:25</span><br><span class="line">categories: 博客搭建系列</span><br><span class="line">**top: true**</span><br><span class="line">---</span><br></pre></td></tr></table></figure></p><blockquote><p>参考与引用</p><ol><li><a href="https://blog.csdn.net/qq_33232071/article/details/51108062" target="_blank" rel="noopener">https://blog.csdn.net/qq_33232071/article/details/51108062</a></li><li><a href="https://hexo.io/zh-cn/docs/setup.html" target="_blank" rel="noopener">https://hexo.io/zh-cn/docs/setup.html</a></li><li><a href="http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html" target="_blank" rel="noopener">http://mashirosorata.vicp.io/HEXO-NEXT%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE.html</a></li><li><a href="https://segmentfault.com/a/1190000009544924#articleHeader21" target="_blank" rel="noopener">https://segmentfault.com/a/1190000009544924#articleHeader21</a></li><li><a href="https://github.com/shenzekun/shenzekun.github.io/blob/hexo/themes/next/layout/_layout.swig" target="_blank" rel="noopener">https://github.com/shenzekun/shenzekun.github.io/blob/hexo/themes/next/layout/_layout.swig</a></li><li><a href="https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E4%B8%BB%E4%B9%89%E6%A0%B8%E5%BF%83%E4%BB%B7%E5%80%BC%E8%A7%82/3271832?fr=aladdin" target="_blank" rel="noopener">https://baike.baidu.com/item/%E7%A4%BE%E4%BC%9A%E4%B8%BB%E4%B9%89%E6%A0%B8%E5%BF%83%E4%BB%B7%E5%80%BC%E8%A7%82/3271832?fr=aladdin</a></li><li><a href="https://blog.csdn.net/ganzhilin520/article/details/79048021" target="_blank" rel="noopener">https://blog.csdn.net/ganzhilin520/article/details/79048021</a></li><li><a href="https://www.zhihu.com/question/41625825" target="_blank" rel="noopener">https://www.zhihu.com/question/41625825</a></li><li><a href="https://www.jianshu.com/p/f5c184047e72" target="_blank" rel="noopener">https://www.jianshu.com/p/f5c184047e72</a></li><li><a href="https://github.com/xiaweizi/BackupBlog/commit/b97173da33837604a31f2e5f78b17ba819306f74" target="_blank" rel="noopener">https://github.com/xiaweizi/BackupBlog/commit/b97173da33837604a31f2e5f78b17ba819306f74</a></li><li><a href="https://blog.csdn.net/luzheqi/article/details/52798557" target="_blank" rel="noopener">https://blog.csdn.net/luzheqi/article/details/52798557</a></li><li><a href="https://blog.csdn.net/qwerty200696/article/details/79010629" target="_blank" rel="noopener">https://blog.csdn.net/qwerty200696/article/details/79010629</a></li><li><a href="https://blog.csdn.net/pop1586082213/article/details/54576131" target="_blank" rel="noopener">https://blog.csdn.net/pop1586082213/article/details/54576131</a></li><li><a href="https://github.com/nodejs/node-v0.x-archive/issues/3911" target="_blank" rel="noopener">https://github.com/nodejs/node-v0.x-archive/issues/3911</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;hexo基本使用&quot;&gt;&lt;a href=&quot;#hexo基本使用&quot; class=&quot;headerlink&quot; title=&quot;hexo基本使用&quot;&gt;&lt;/a&gt;hexo基本使用&lt;/h2
      
    
    </summary>
    
      <category term="Blog" scheme="https://824zzy.github.io/categories/Blog/"/>
    
    
      <category term="Hexo-next" scheme="https://824zzy.github.io/tags/Hexo-next/"/>
    
  </entry>
  
  <entry>
    <title>信息科学原理手写笔记</title>
    <link href="https://824zzy.github.io/2018/07/18/infomation-science-handwriting/"/>
    <id>https://824zzy.github.io/2018/07/18/infomation-science-handwriting/</id>
    <published>2018-07-17T16:00:00.000Z</published>
    <updated>2018-08-01T09:47:29.880Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="课堂笔记"><a href="#课堂笔记" class="headerlink" title="课堂笔记"></a>课堂笔记</h2><div class="row"><iframe src="https://drive.google.com/file/d/1lli8ZJgdkfyIBUT6-CmVPeujpqpfpJGu/preview" style="width:100%; height:550px"></iframe></div><h2 id="题目参考"><a href="#题目参考" class="headerlink" title="题目参考"></a>题目参考</h2><div class="row"><iframe src="https://drive.google.com/file/d/1Gsc5yuhNsulK-0hRGNEEZ_0QumcebPQJ/preview" style="width:100%; height:550px"></iframe></div><h2 id="题目索引"><a href="#题目索引" class="headerlink" title="题目索引"></a>题目索引</h2><div class="row"><iframe src="https://drive.google.com/file/d/1HaiyMuEi_VjEyKDH3KEchJMT1TEusPio/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;课堂笔记&quot;&gt;&lt;a href=&quot;#课堂笔记&quot; class=&quot;headerlink&quot; title=&quot;课堂笔记&quot;&gt;&lt;/a&gt;课堂笔记&lt;/h2&gt;

	&lt;div class=&quot;
      
    
    </summary>
    
      <category term="HandWriting" scheme="https://824zzy.github.io/categories/HandWriting/"/>
    
    
      <category term="informationScience" scheme="https://824zzy.github.io/tags/informationScience/"/>
    
  </entry>
  
  <entry>
    <title>模式识别与机器学习手写笔记</title>
    <link href="https://824zzy.github.io/2018/07/10/PRML-handwriting/"/>
    <id>https://824zzy.github.io/2018/07/10/PRML-handwriting/</id>
    <published>2018-07-09T16:00:00.000Z</published>
    <updated>2018-08-01T09:49:45.284Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="课堂笔记"><a href="#课堂笔记" class="headerlink" title="课堂笔记"></a>课堂笔记</h2><div class="row"><iframe src="https://drive.google.com/file/d/145ag3TfrL6bY222mopcvCnCedipimPdu/preview" style="width:100%; height:550px"></iframe></div><p>##考试大抄<br><div class="row"><iframe src="https://drive.google.com/file/d/1N8rNwzZp8jq2IvkrDh4LjS0E8S_dpCdM/preview" style="width:100%; height:550px"></iframe></div></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;课堂笔记&quot;&gt;&lt;a href=&quot;#课堂笔记&quot; class=&quot;headerlink&quot; title=&quot;课堂笔记&quot;&gt;&lt;/a&gt;课堂笔记&lt;/h2&gt;

	&lt;div class=&quot;
      
    
    </summary>
    
      <category term="HandWriting" scheme="https://824zzy.github.io/categories/HandWriting/"/>
    
    
      <category term="prml" scheme="https://824zzy.github.io/tags/prml/"/>
    
  </entry>
  
  <entry>
    <title>强化学习-DavidSilver(Lecture1 to Lecture3)</title>
    <link href="https://824zzy.github.io/2018/06/30/RL-DavidSilver-1-3/"/>
    <id>https://824zzy.github.io/2018/06/30/RL-DavidSilver-1-3/</id>
    <published>2018-06-29T16:00:00.000Z</published>
    <updated>2018-07-31T07:37:20.978Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>本科毕业设计的强化学习笔记。许多强化学习的术语使用中文表达容易产生歧义，因此本笔记使用英文。 <a href="https://www.youtube.com/watch?v=2pWv7GOvuf0" target="_blank" rel="noopener">David Silver强化学习课程视频网址</a><br><a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" target="_blank" rel="noopener">David Silver强化学习课程课件</a>。</p></blockquote><h2 id="Lecture-One"><a href="#Lecture-One" class="headerlink" title="Lecture One"></a>Lecture One</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ul><li>all is about decision</li><li>no supervisor,only <strong>reward</strong> signal(not supervisor learning)</li><li>feedback is delayed,not instantaneous</li><li>the key role:<strong>agent</strong>(brain)</li></ul><h3 id="The-process"><a href="#The-process" class="headerlink" title="The process"></a>The process</h3><ul><li>background:environment(earth) input: observation &amp; reward –&gt; output:action</li><li>history and state:<br>History:  $$H_t=A_1,O_1,A_2,O_2…A_t,O_t,R_t$$<br>State of agent :    $$S_t^a=f(H_t)$$<br>State of environment:    $$S_t=f(H_t)$$</li></ul><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg5bizsrj20xg0ictf8.jpg" alt=""></p><h3 id="keys-of-fundamental-assumptions"><a href="#keys-of-fundamental-assumptions" class="headerlink" title="keys of fundamental assumptions"></a>keys of fundamental assumptions</h3><ol><li>Markov state</li><li>agent may conclude</li></ol><ul><li>policy:to decide agent’s function towards current state</li><li>value:predictive reward of agent’s action</li><li>model:a metaphysical regulation of “world”(<strong>state</strong>&amp;<strong>reward</strong>)</li></ul><ol start="3"><li>exploitation(choose old) and exploration(choose new)</li></ol><h3 id="The-classification-of-agent"><a href="#The-classification-of-agent" class="headerlink" title="The classification of agent"></a>The classification of agent</h3><ul><li>Value Based: only need $max(V)$</li><li>Policy Based: get action directly by state</li><li>AC(Actor Critic):act(i.e. policy), critic(i.e. value function)</li></ul><h3 id="let-us-review-immediately"><a href="#let-us-review-immediately" class="headerlink" title="let us review immediately"></a>let us review immediately</h3><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg3rvl2wj21yu2kz7wh.jpg" alt=""></p><hr><h2 id="Lecture-Two"><a href="#Lecture-Two" class="headerlink" title="Lecture Two"></a>Lecture Two</h2><h3 id="introduction-to-MDP-markov-decision-process"><a href="#introduction-to-MDP-markov-decision-process" class="headerlink" title="introduction to MDP(markov decision process)"></a>introduction to MDP(markov decision process)</h3><blockquote><p>almost all RL problems can be formalised as MDPs</p></blockquote><h3 id="Markov-Property-and-Markov-Process"><a href="#Markov-Property-and-Markov-Process" class="headerlink" title="Markov Property and Markov Process"></a>Markov Property and Markov Process</h3><blockquote><p>the future is independent of the past given the present</p></blockquote><h4 id="Markov-Property"><a href="#Markov-Property" class="headerlink" title="Markov Property"></a>Markov Property</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg8lkc95j20x607mq3j.jpg" alt=""></p><h4 id="Markov-Process"><a href="#Markov-Process" class="headerlink" title="Markov Process"></a>Markov Process</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstg9h4fybj20ww08gjst.jpg" alt=""></p><h3 id="State-Transition-Matrix"><a href="#State-Transition-Matrix" class="headerlink" title="State Transition Matrix"></a>State Transition Matrix</h3><blockquote><p>the state transition probability for a Markov state and successor state</p></blockquote><h3 id="Markov-Reward-Process"><a href="#Markov-Reward-Process" class="headerlink" title="Markov Reward Process"></a>Markov Reward Process</h3><blockquote><p>A Markov reward process is a Markov chain with values.(State,Probability,Reward,Discount factor-gamma)</p></blockquote><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fse949pfxej21410f1di6.jpg" alt=""></p><h4 id="return-G"><a href="#return-G" class="headerlink" title="return(G)"></a>return(<strong>G</strong>)</h4><blockquote><p>the return G is the total discounted reward from time-step t. </p></blockquote><p>$$G_t = R_{t+1}+{\gamma}R_{t+2}+ {\gamma} ^2R_{t+3}…+{\gamma}^kR_{t+k+1}$$<br>　we could figure out from equation above if discount factor closes to 0 the return will be “myopic”, if discount factor nevertheless closes to 1 then the return will be “far-sighted”</p><h4 id="Value-Function-Expectation"><a href="#Value-Function-Expectation" class="headerlink" title="Value Function:Expectation"></a>Value Function:<strong>Expectation</strong></h4><blockquote><p>the value function v(s) gives the long-term value of state s.</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgan5dxdj20xa08qjsh.jpg" alt=""></p><p>then we could deduce MRP Bellman Equation below:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgbhlcxoj211s0a4t9x.jpg" alt=""></p><p>Reward only relates to state,therefore Bellman Equation can be decomposition said by:<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgc2frlqj211i0hc3zu.jpg" alt=""></p><h4 id="Bellman-Equation-for-MRPs-in-matrix"><a href="#Bellman-Equation-for-MRPs-in-matrix" class="headerlink" title="Bellman Equation for MRPs in matrix:"></a>Bellman Equation for MRPs in matrix:</h4><p>The bellman equation can be expressed concisely using matrics:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgoq6yy1j211k0j0wg3.jpg" alt=""></p><p>The bellman equation is a kind of linear equation so we could solve it directly:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgfys2wej212w0aimxx.jpg" alt=""></p><p>But time complexity is close to $O(n^3)$,we could solve it by iteration methods:</p><ul><li>Dynamic Programming</li><li>Monto Carlo evaluation</li><li>Temporal-Difference(TD) Learning</li></ul><p>Let us see some other concepts for preparing!</p><h3 id="Markov-Decision-Processes"><a href="#Markov-Decision-Processes" class="headerlink" title="Markov Decision Processes"></a>Markov Decision Processes</h3><blockquote><p>Markov Decison Processes (S,A,P,R,$\gamma$) is a Markov Reward Processed with decisons.It is an environment in which all states are Markov</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgr8o1hsj20q40b6gng.jpg" alt=""></p><h4 id="Policies"><a href="#Policies" class="headerlink" title="Policies"></a>Policies</h4><blockquote><p>A policy $\pi$ is a distribution over actions given states.</p></blockquote><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgruhsrtj20bs028q2u.jpg" alt=""></p><p>for MDP, we must calculate state-value function and action-value function, we have definition below:<br><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgsgz1gaj20pu0esdhw.jpg" alt=""></p><p>just like bellman equation, we could deduce bell expectation equation from state-value function and action-value function:</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fstgtf593bj20r60di0tx.jpg" alt=""></p><p>we finally have different Bellman Expectation Equation for $V^{\pi}$,$Q^{\pi}$ and the Matrix Form is：</p><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsthdw3ihrj20ow0diaav.jpg" alt=""></p><h4 id="Optimal-Value-Functions"><a href="#Optimal-Value-Functions" class="headerlink" title="Optimal Value Functions"></a>Optimal Value Functions</h4><p>Coming question, how could we judge the performance of our policy?</p><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fseb9v3uaxj20rm0dl3zx.jpg" alt=""></p><h4 id="Optimal-Bellman-Equation"><a href="#Optimal-Bellman-Equation" class="headerlink" title="Optimal Bellman Equation"></a>Optimal Bellman Equation</h4><p>we could deduce the Optimal Bellman Eqution from above first:</p><p align="center"><br>    <img with="400px" height="400px" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthiix1lcj20h00dmdgm.jpg"><br></p><p align="center"><br>    <img with="300px" height="300px" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthirugdzj20lo0coq3t.jpg"><br></p><p>we could solve the equation by:</p><ul><li>Value iteration</li><li>Police iteration</li><li>Q-Learning</li><li>Sarsa</li></ul><h3 id="extension-of-MDP"><a href="#extension-of-MDP" class="headerlink" title="extension of MDP"></a>extension of MDP</h3><ul><li>infinite MDPS</li><li>Reductions of POMDP’s</li></ul><h4 id="infinite-MDPs"><a href="#infinite-MDPs" class="headerlink" title="infinite MDPs"></a>infinite MDPs</h4><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsthjqcbhoj20p80gq767.jpg" alt=""></p><h4 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP:"></a>POMDP:</h4><p>It could be seen as a Hidden Markov Process adding actions!</p><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsebmimapgj21180lejux.jpg" alt=""></p><h3 id="Let-us-review-immediately"><a href="#Let-us-review-immediately" class="headerlink" title="Let us review immediately!"></a>Let us review immediately!</h3><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthrducjcj21yu2kz4r0.jpg" alt=""><br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsthqqzx45j21yu2kz1l8.jpg" alt=""></p><hr><h2 id="Lecture-3-Planning-by-Dynamic-Programming"><a href="#Lecture-3-Planning-by-Dynamic-Programming" class="headerlink" title="Lecture 3 : Planning by Dynamic Programming"></a>Lecture 3 : Planning by Dynamic Programming</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul><li><strong>Dynamic</strong> sequential or temporal component to the problem</li><li><strong>Programming</strong> is a optimision of question!<ul><li>optimal substructure</li><li>overlapping subproblems</li></ul></li></ul><p>&emsp;&emsp;There are two applications of DP</p><ol><li><p>for prediction:</p><ul><li>Input：MDP &amp; policy $\pi$</li><li>Output: value function $v_\pi$</li></ul></li><li><p>for control</p><ul><li>Input: MDP</li><li>Output: optimal value function $v_<em>$ &amp; optimal policy $\pi_</em>$</li></ul></li></ol><p><img src="http://ww1.sinaimg.cn/large/ca26ff18ly1fsthz8kmyjj21yu2kzb29.jpg" alt=""></p><h3 id="Iterative-Policy-Evaluation"><a href="#Iterative-Policy-Evaluation" class="headerlink" title="Iterative Policy Evaluation"></a>Iterative Policy Evaluation</h3><p>How to evaluate $\pi$?</p><ul><li>solition:iterative application of bellman expectation backup to get the true value function($V_0-&gt;V_\pi$)</li><li>from end to start by iteration.</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst51czfmaj20pm0ewmy8.jpg" alt=""></p><p>&emsp;&emsp;It is just like a weighted average of every probability of each action.</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst8a8p85fj20om0kutb7.jpg" alt=""></p><p>the detail you could see the manuscript!</p><p><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RL5.jpg" alt=""></p><h3 id="Policy-Iteration"><a href="#Policy-Iteration" class="headerlink" title="Policy Iteration:"></a>Policy Iteration:</h3><ol><li>evaluate the policy $\pi$：fill the maze with number to get $v_\pi$<br>$$V_\pi(s) = E[R_{t+1}+\gamma R_{t+2}+…|S_t = s]$$</li><li>improve the policy by acting greedy with respect to $v_\pi$<br>$$\pi^{‘} = greedy(v_\pi) $$</li></ol><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst59a5cd0j20vr0fn42a.jpg" alt=""></p><ol start="3"><li>Policy improvement:</li></ol><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst9t2rt9bj20vi0kmtc8.jpg" alt=""></p><p>the details you could see the manuscript!<br><img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/RL5.jpg" alt=""></p><h3 id="Value-Iteration"><a href="#Value-Iteration" class="headerlink" title="Value Iteration"></a>Value Iteration</h3><p>The solution v∗(s) can be found by one-step lookahead, and it start with final rewards and work backwards:<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst5i9k9fzj20vr04ljrr.jpg" alt=""></p><p>There is an example:<br><img src="leanote://file/getImage?fileId=5b373da1afc5ce605c000001" alt=""></p><p>the details you could see the manuscript!</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fst5j0ochmj20vo0fcmyf.jpg" alt=""></p><h3 id="Synchronous-Dynamic-Programming-Algorithms"><a href="#Synchronous-Dynamic-Programming-Algorithms" class="headerlink" title="Synchronous Dynamic Programming Algorithms"></a>Synchronous Dynamic Programming Algorithms</h3><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fstbt3m1pkj20wg0aiq4p.jpg" alt=""></p><p>we could see Iterative Policy Evaluation and Policy Iteration as a whole knowledge. The knowledge is all in consideration of policy.They as the same in essence.</p><h3 id="Asynchronous-Dynamic-Programming"><a href="#Asynchronous-Dynamic-Programming" class="headerlink" title="Asynchronous Dynamic Programming"></a>Asynchronous Dynamic Programming</h3><ul><li>In-Place Dynamic Programming</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fstet5a8koj20w60iaacj.jpg" alt=""></p><p>the main difference between two methods above is the number of copy for reducing storage.</p><ul><li>Prioritised sweeping</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fstevcscvuj20w00eowgs.jpg" alt=""></p><ul><li>Real-time dynamic programming</li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fsteyfhrxoj20rm0cswg6.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;blockquote&gt;
&lt;p&gt;本科毕业设计的强化学习笔记。许多强化学习的术语使用中文表达容易产生歧义，因此本笔记使用英文。 &lt;a href=&quot;https://www.youtub
      
    
    </summary>
    
      <category term="MachineLearning" scheme="https://824zzy.github.io/categories/MachineLearning/"/>
    
    
      <category term="reinforcementLearning" scheme="https://824zzy.github.io/tags/reinforcementLearning/"/>
    
  </entry>
  
  <entry>
    <title>卷积神经网络</title>
    <link href="https://824zzy.github.io/2018/06/29/CNN-note/"/>
    <id>https://824zzy.github.io/2018/06/29/CNN-note/</id>
    <published>2018-06-28T16:00:00.000Z</published>
    <updated>2018-07-29T03:54:32.171Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="视觉感知"><a href="#视觉感知" class="headerlink" title="视觉感知"></a>视觉感知</h2><blockquote><p>相同的图片经过不同的视觉系统，会得到适合自己生存环境的感知。</p></blockquote><p>不同的观察角度，决定了图片的识别结果。</p><h2 id="图像表达"><a href="#图像表达" class="headerlink" title="图像表达"></a>图像表达</h2><p>画面识别的输入$x$是形状为（width, height, depth）的三维张量。其中每一个（width，height）的矩阵称为一个channel。</p><blockquote><p>画面不变性：一个物体在channel中的位置不应该影响对该物体的识别结果。</p></blockquote><h2 id="为什么前馈神经网络不能完成任务？"><a href="#为什么前馈神经网络不能完成任务？" class="headerlink" title="为什么前馈神经网络不能完成任务？"></a>为什么前馈神经网络不能完成任务？</h2><p>输入图片是一个三维张量，但是很明显前馈神经网络很难识别不同位置的“相同”样本。<br>也即：应当使前馈神经网络在识别图片中的物体时，即使物体在不同位置也能顺利识别出来。<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsrxt7affrj20k00ce0z1.jpg" alt=""></p><h2 id="卷积神经网络：让权重在不同位置共享的神经网络"><a href="#卷积神经网络：让权重在不同位置共享的神经网络" class="headerlink" title="卷积神经网络：让权重在不同位置共享的神经网络"></a>卷积神经网络：让权重在不同位置共享的神经网络</h2><p>卷积神经网络的最基本的操作：</p><ol><li>卷积</li><li>非线性（ReLu）</li><li>Pooling池化</li><li>分类（全连接层）</li></ol><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><ul><li><p>使用局部区域去扫描整张图片<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fsrzmkrrypj20e90ea43u.jpg" alt=""><br>其中：红框表示<strong>filter</strong>或者<strong>kernel</strong>,隐藏层节点为kernel的线性组合。<br>那么，隐藏层节点$y_0$的表达式即为：<br>$$ y_0=x_0<em>w_1+x_1</em>w_2+x4<em>w_3+x_5</em>w_4+b_0 $$</p></li><li><p>空间共享<br>不同的区域共享同一个“权重矩阵”和偏移量$b_0$。</p></li><li><p>矩阵形式的输出表达：<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fss08p95qjj20e90eawjr.jpg" alt=""><br>经过一次feature detector后的隐藏层就可以看做是“卷积”的特征。</p></li><li><p>处理Depth这一个维度:将三个channel看成三组不同的权重矩阵<br>特别的，针对$$ 2\cdot2\cdot3 $$(RGB)的kernel有：<br><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fss0q4vy7kj207t01ajr8.jpg" alt=""><br>也就是说，<strong>depth维是以被贯穿的方式处理的</strong>。<br>在实践中，Depth的数值与filter的个数相同。</p></li><li><p>步长（Stride）：<br>这个参数决定了filter滑动一次所跨越的像素数量。本文的例子中步长均为1。</p></li><li><p>Zero padding<br>为了保证卷积后的图片尺寸不变，则需要在最外一层填充0，</p></li><li><p>多filters<br>不同的filters对同一个图像抓取到的Feature Maps也会不同。<br>每一个不同的filter代表了每一个不同的操作，下图就展示了filter对用一张图片不同的处理结果。</p></li></ul><p align="center"><br>  <img width="60%" height="60%" src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fss2yuhw9dj20ia0u2485.jpg"><br></p><h3 id="非线性（ReLu）"><a href="#非线性（ReLu）" class="headerlink" title="非线性（ReLu）"></a>非线性（ReLu）</h3><p>回顾一下老朋友ReLU:Rectified Linear Unit<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss3hexqnoj20tr09c3zw.jpg" alt=""><br>这个环节的主要作用就是把一些值为负数的像素点全部设置为0，</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss42edfvbj215k0fkjzp.jpg" alt=""></p><h3 id="Pooling池化"><a href="#Pooling池化" class="headerlink" title="Pooling池化"></a>Pooling池化</h3><ul><li>Max pooling<br>整个图片被不重叠的分割成若干个同样大小的小块（pooling size）。每个小块内只取最大的数字，再舍弃其他节点后，保持原有的平面结构得出output。那么为什么要有这个环节？<blockquote><p>卷积后的Feature Map中有对于识别物体不必要的冗余信息。 </p></blockquote></li></ul><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss45xe26bj20rg0nedlu.jpg" alt=""></p><p>&emsp;&emsp;注：上图的步长设置为1</p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>卷积网络的最后会将末端得到的长方体平摊(flatten)成一个长长的向量，并送入全连接层配合输出层进行分类。</p><h2 id="小结：卷积神经网络的训练过程"><a href="#小结：卷积神经网络的训练过程" class="headerlink" title="小结：卷积神经网络的训练过程"></a>小结：卷积神经网络的训练过程</h2><ol><li>随机初始化所有的filter、参数、权重</li><li>将训练图像作为输入，通过卷积-&gt;ReLu-&gt;池化（pooling）-&gt;全连接层的过程找到每个分类的概率。</li><li>在输出层计算总误差。</li><li>使用梯度下降反向传播更新所有filter、参数、权重的值。其中，权重按它们所占误差的比例更新；</li></ol><hr><h2 id="再用一个例子查漏补缺"><a href="#再用一个例子查漏补缺" class="headerlink" title="再用一个例子查漏补缺"></a>再用一个例子查漏补缺</h2><p><a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" target="_blank" rel="noopener">可视化CNN游戏，强烈建议尝试一下！</a></p><p>游戏截图如下：<br>一副图片由1024（$32*32$）个像素组成。<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss7xncql9j21q0172x6p.jpg" alt=""></p><p>第一个卷积层由6个$5*5$并且步长设置为1的filter生成，我们可以形象的理解为它的depth维度为6。注：下图将ReLu环节与卷积环节合二为一了，请读者心中有数。</p><p align="center"><br>  <img width="200px" height="400px" src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fss7zpo0cxj20go0vmdne.jpg"><br><br></p><p>紧接着针对每一个feature map使用$2*2$并且步长为2的max pooling。可以看到Pooling层的每一个像素对应Conv层的四个像素。</p><p align="center"><br>    <img with="200" height="400px" src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssbu4uyuwj20ek0gwn0t.jpg"><br></p><p>接下来是最难理解的第二次的卷积层和max pooling层的环节：<br>首先，观察第一层max pooling到第二层卷积的个数，为什么8个feature map经过filter的f卷积之后变成了16个feature map？<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssctu1m8lj219y0620yl.jpg" alt=""></p><p>为了寻找答案，我们来观察下第二层feature maps的filter都是长成什么样的：<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssd06wljtj210w0k67fd.jpg" alt=""><br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssd0qrdugj21aq0kek7e.jpg" alt=""></p><p>请大家仔细观察上图：我们会发现，第二层卷积层的filter的形状和所选择的第一层max pooling的feature map息息相关！也就是说，我们在做第二层的卷积时，只考察了第一层的局部特征！</p><p>第二层的max pooling与第一层同理，我就不再赘述了。</p><p>之后是全连接层，全连接层利用了所有的特征：</p><p><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssd8ndkubj21cg02yn25.jpg" alt=""></p><p>全连接层的全景图如下：<br><img src="https://ws1.sinaimg.cn/mw690/ca26ff18ly1fssdbxdtm0j21oq0c2gzj.jpg" alt=""></p><blockquote><p>参考与引用</p><ol><li><a href="https://zhuanlan.zhihu.com/p/27642620" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27642620</a></li><li><a href="https://cs231n.github.io/convolutional-networks/" target="_blank" rel="noopener">https://cs231n.github.io/convolutional-networks/</a></li><li><a href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" target="_blank" rel="noopener">https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/</a></li><li><a href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" target="_blank" rel="noopener">http://scs.ryerson.ca/~aharley/vis/conv/flat.html</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;视觉感知&quot;&gt;&lt;a href=&quot;#视觉感知&quot; class=&quot;headerlink&quot; title=&quot;视觉感知&quot;&gt;&lt;/a&gt;视觉感知&lt;/h2&gt;&lt;blockquote&gt;
&lt;p
      
    
    </summary>
    
      <category term="DeepLearning" scheme="https://824zzy.github.io/categories/DeepLearning/"/>
    
    
      <category term="cnn" scheme="https://824zzy.github.io/tags/cnn/"/>
    
  </entry>
  
  <entry>
    <title>人类简史与未来简史</title>
    <link href="https://824zzy.github.io/2018/06/27/some-great-books-note/"/>
    <id>https://824zzy.github.io/2018/06/27/some-great-books-note/</id>
    <published>2018-06-26T16:00:00.000Z</published>
    <updated>2018-07-29T03:45:10.174Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="人类简史"><a href="#人类简史" class="headerlink" title="人类简史"></a>人类简史</h2><h3 id="以问题为导向阅读"><a href="#以问题为导向阅读" class="headerlink" title="以问题为导向阅读"></a>以问题为导向阅读</h3><h4 id="问题1：人类如何从不相关的物种变成了地球的主宰者？"><a href="#问题1：人类如何从不相关的物种变成了地球的主宰者？" class="headerlink" title="问题1：人类如何从不相关的物种变成了地球的主宰者？"></a>问题1：人类如何从不相关的物种变成了地球的主宰者？</h4><p>&emsp;答案：集体层面上，人类可以<em>灵活</em>地进行<em>大型合作</em>。其中，灵活相对于地球上的其他物种，例如：蚁群可以高效的合作，但是它们不会策划去推翻蚁后的统治。大型合作代表一种在信任机制，即陌生人“绑定”之间的契约。</p><p>&emsp;列举一些只会出现在人类这个物种上的合作机制：</p><ul><li>屠宰场</li><li>监狱</li><li>集中营</li></ul><p>&emsp;启发：人类之所以可以进行灵活地大型合作，我认为一部分要归功于人类的自我意识。而人工意识真的是当前人工智能的发展未来吗？人类进化成为“有意识”的物种花费了数百万年的时间。目前计算机接口并不具备像人类一样与现实世界进行交互，通过自然选择筛选基因的外部条件。因此人工智能也许会跳过意识这一环节，成为无意识的超级智能。再或者，计算机通过其特有的接口“互联网”，直接进化出超级意识。</p><h4 id="问题2：人类为何能建立前所未有的合作机制？"><a href="#问题2：人类为何能建立前所未有的合作机制？" class="headerlink" title="问题2：人类为何能建立前所未有的合作机制？"></a>问题2：人类为何能建立前所未有的合作机制？</h4><p>&emsp;答案：想象力：人类可以创造虚幻或者虚幻的故事。只要人们广泛“相信”/“信任”这些故事，大家便会遵循相同的规定、准则、价值观。</p><ul><li>动物仅仅用语言描述现实世界，而人类使用语言创造新的（虚构的）现实。例如：上帝、人权、国家、民族、公司、货币。</li></ul><p>&emsp;启发：正在飞速发展的AI恰恰会有相同形式机制，比如医疗领域，人类医生有数千万，但是他们参差不齐的水平和文化背景经常会导致误诊。而共享单一医疗网络的AI医生将会共享同一个“准则”，第一时间可以获取到最新具有抗药性的病毒，这无疑对医疗来说是巨大的进步。</p><h3 id="2-按照时间顺序阅读"><a href="#2-按照时间顺序阅读" class="headerlink" title="2. 按照时间顺序阅读"></a>2. 按照时间顺序阅读</h3><ol><li>认知革命：语言沟通进行合作。</li><li>农业革命：驯化地球上的其他物种；使用文字进行记录。</li><li>科学革命：人类发现自己的“无知”，进而不断探索未知的领域。</li><li>？？革命：？？</li></ol><p>&emsp;启发：人类会无意识的进入一个全新的时代。在时代的转换过程中阶层流动将会变得十分迅速，而每次转换都会让资源集中在更少的人手中。越来越多的权力由人类涌向算法，最后十分有可能是一个无意识的智能体控制这个星球。</p><h2 id="未来简史"><a href="#未来简史" class="headerlink" title="未来简史"></a>未来简史</h2><h3 id="观点导向阅读"><a href="#观点导向阅读" class="headerlink" title="观点导向阅读"></a>观点导向阅读</h3><ol><li><p>人类一直在追求“永生”，而计算机（硅基生命）天生“永生”。<br><br>启发：按照进化论的观点，通过不断地“死亡”来筛选适合生存的突变基因，碳基生命完成了进化。相反，硅基生命则不需要通过这种方式完成进化。那么我们需不需要编码一个“原始”的硅基生命体（含有基本代码片的单片机）使其模拟人类进化的过程呢？</p></li><li><p>科技革命产生了人文主义宗教。<br><br>科学，本身成为了一种宗教。“圣经“们打下了有神论宗教的基础。”牛顿与苹果“，”马尔科夫假设“，”神经网络“，成为了计算机乃至科学的基石。我常常恐惧于：如果有一天计算机科学的基石崩塌，这门学科将会向</p></li><li><p>人文主义将会面临彻底的失败。<br><br>人文主义的基本假设是：人是有自我意识的。但是神经科学家告诉我们：人的意识仅仅是神经信号，并不比地球上的其他物种高明多少，也没有21克的”灵魂“存在。未来数据主义十分有可能成为新的主流信仰，即全世界的低级碳基生命伴随着高级硅基生命一起进化，最终变成一个巨大的综合生命体。</p></li></ol><h3 id="章节顺序阅读"><a href="#章节顺序阅读" class="headerlink" title="章节顺序阅读"></a>章节顺序阅读</h3><ul><li>幸福：幸福感的本质是神经元之间传递的电化学反应信号，或许真的有一串代码可以传递一个”幸福矩阵“于神经网络之中呢？</li><li>直觉：生物自有的算法（适者生存）已经保证了，地球上的生物最起码是局部最优的。而人类决策算法中最重要的”直觉“或者说”无意识部分“，需要进行巧妙地编码。</li><li>意识：意识本质上是个体的退化与集体的进化。自由意志本身也只是一个算法。那么首先，如何让冷冰冰的代码具有主观能动性呢？是需要给他们编码一个最基本的生存动机？还是其他方式呢？</li><li>左右脑的启发：当前最为火爆的GAN(对抗神经网络)模型，可以类比人类的左右脑。因为脑科学实验表明，左脑和右脑本来就是两套不同的决策体系，它们通过神经纤维连接了起来，最终作出一致的决策。因此，从神经元到深度神经网络到对抗式神经网络，人类不经意间走着仿生学的”正确“道路。一步一步实现人工智能。（此处可以添加GAN相关论文成果）</li></ul><h3 id="小结："><a href="#小结：" class="headerlink" title="小结："></a>小结：</h3><ul><li>当前世界的时间节点，无论是中国倡导的“经济全球化”，还是美国倡导的“美国优先”，都是在讲一个故事，创造一种幻觉。</li><li>pytorch, tensorflow最终会变成一个超级平台，规范一切关于人工智能的进化过程。C语言就像是现实世界的物理定律，底层硬件就像是现实世界中的实体。</li><li>人类只是简单地算法，人工智能需要一个本领域的”质能方程“。 </li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;人类简史&quot;&gt;&lt;a href=&quot;#人类简史&quot; class=&quot;headerlink&quot; title=&quot;人类简史&quot;&gt;&lt;/a&gt;人类简史&lt;/h2&gt;&lt;h3 id=&quot;以问题为导向阅
      
    
    </summary>
    
      <category term="AI" scheme="https://824zzy.github.io/categories/AI/"/>
    
    
      <category term="aBriefHistoryOfHumankind" scheme="https://824zzy.github.io/tags/aBriefHistoryOfHumankind/"/>
    
      <category term="homoDeus" scheme="https://824zzy.github.io/tags/homoDeus/"/>
    
  </entry>
  
  <entry>
    <title>深度学习设计理念手写笔记</title>
    <link href="https://824zzy.github.io/2018/06/16/YJango-Deep-Learning/"/>
    <id>https://824zzy.github.io/2018/06/16/YJango-Deep-Learning/</id>
    <published>2018-06-15T16:00:00.000Z</published>
    <updated>2018-08-01T09:55:00.174Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><div class="row"><iframe src="https://drive.google.com/file/d/1cski1XD1gfZauuDb-TOw8HqxmGixbkoO/preview" style="width:100%; height:550px"></iframe></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;

	&lt;div class=&quot;row&quot;&gt;
		&lt;iframe src=&quot;https://drive.google.com/file/d/1cski1XD1gfZauuDb-TOw8
      
    
    </summary>
    
      <category term="HandWriting" scheme="https://824zzy.github.io/categories/HandWriting/"/>
    
    
      <category term="deeplearning" scheme="https://824zzy.github.io/tags/deeplearning/"/>
    
  </entry>
  
  <entry>
    <title>超智能体读书笔记</title>
    <link href="https://824zzy.github.io/2018/06/15/super-organism-YJango/"/>
    <id>https://824zzy.github.io/2018/06/15/super-organism-YJango/</id>
    <published>2018-06-14T16:00:00.000Z</published>
    <updated>2018-07-29T03:45:12.098Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><blockquote><p>版权说明：<br>本文仅记录在阅读 于建国（YJango）博士的《超智能体》一书过程中的笔记。本文作者已通过邮件联系作者，获得授权。</p></blockquote><h2 id="智能的本质"><a href="#智能的本质" class="headerlink" title="智能的本质"></a>智能的本质</h2><p>　智能起源于随机性（熵）：随着时间的推移，孤立系统会自发朝向最大熵状态演化[不去刻意整理的宿舍会越来越乱]。</p><blockquote><p>智能：根据环境变化做出相应变化的能力，即熵减的能力[减少“不确定性”]</p></blockquote><p>　想要探究智能，我们必须具备正确描述世界状态和不同时间下的状态变化。线性代数则给了我们答案。</p><h3 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h3><blockquote><p>线性代数：有关任意维度空间下事物<strong>状态</strong>和<strong>变化状态</strong>的规则</p></blockquote><h4 id="矩阵的本质：存储状态（静态）或变化（动态）的信息"><a href="#矩阵的本质：存储状态（静态）或变化（动态）的信息" class="headerlink" title="矩阵的本质：存储状态（静态）或变化（动态）的信息"></a>矩阵的本质：存储状态（静态）<strong>或</strong>变化（动态）的信息</h4><ol><li>矩阵的静态信息：<br>　向量可以描述一个事物的状态，许多具有相同维度的向量的有序排列构成了矩阵。<ul><li>关于张量：多个标量有序排列后形成向量，多个向量有序排列后形成矩阵，多个矩阵有序排列后形成三维张量（3D tensor）。</li></ul></li><li><p>矩阵的动态信息：<br>　此时矩阵可以看做是多个维度相同的权重的有序排列，并且可以对另一个矩阵的静态信息进行批量变化。这便是矩阵乘法的本质。</p><blockquote><p>两个矩阵相乘，一个矩阵提供状态信息，另个矩阵提供变化信息</p></blockquote></li><li><p>向量空间：能够容纳所有线性组合的状态集合。</p><ul><li>向量空间一定在各个维度可以无限延伸（因为实数域无限）</li><li>子空间：子空间内的向量空间<ul><li>最小的子空间：0</li><li>空集不可以是向量空间</li></ul></li></ul></li><li><p>线性变换：<br> 矩阵乘以矩阵可以视作一个矩阵内部向量的批量线性变换（lineartransformation）。方便理解起见可以仅讨论由矩阵乘以向量所形成的一次线性变换。直接上图：<br> <img src="https://raw.githubusercontent.com/824zzy/blogResources/master/picResources/superorganism-1.png" alt=""></p></li><li><p>线性变化：不同维度空间下的向量组的投影。例如$y_{2<em>1}=A_{2</em>3}x_{3*1}$便是将三维向量$x$经过线性变换后变成二维空间的向量$y$。<br>注：神经网络的核心 $$ y=a(Ax+b)$$ </p></li></ol><h4 id="维度的扩展"><a href="#维度的扩展" class="headerlink" title="维度的扩展"></a>维度的扩展</h4><p><strong>思维空间</strong>：人们认为自己拥有自由的意识和思维。然而这种自由也是有限的。它好比线性空间里的张成,能张成多大的意识空间<strong>取决于脑中有多少互不相关的因素</strong>,也就是维度（秩）。</p><p>　维度的作用：</p><ul><li>复数的理解:进一步扩展的数的域。</li><li>傅里叶变换的理解:在x-y坐标系上增加1维时,一切豁然开朗。</li><li><p>弦理论的理解:尝试融合相对论和量子力学的理论,但只有当扩充到10维空间+1维时间时,数学公式才合理。</p></li><li><p><strong>弦理论</strong>：</p><ul><li>1.问题的起源：<ul><li>宇宙也许存在高维度的空间</li><li>构成世界最基础的成分是什么？</li></ul></li><li>2.物质的构成：分子-&gt;原子-&gt;质子、中子-&gt;？？？<br>  可能是不断<strong>跳动</strong>的能量<strong>线条</strong>：宇宙万物的一切皆源于此。</li><li>3.上述理论的数学证明之后在十维空间和一维时间的情况下才成立。那么我们的宇宙的确可能存在高纬度的空间</li><li>4.新的问题：当我们观测一个宇宙的状态时，我们确定了20个数值（粒子的质量，重力场的强度，…），并且如果这20个数中的任何一个数有所变化，我们的宇宙将不复存在。那么这20个数值是因为什么而确定的呢？<br>  也许是更高纬度的空间</li><li><ol start="5"><li>通过实验证明高纬度空间的存在：<br>欧洲大型强子对撞机通过将质子加速对撞，观测：如果对撞后的能量有所损失，则可能是因为对撞的一部分“残骸”进入到了高纬度空间！</li></ol></li></ul></li></ul><p>小结：<strong>当问题无法被理解时，往往是因为找错的地方，不妨尝试扩展维度，增加搜索空间。</strong>然而由于信息量的限制，很多事物无法确定变化后的状态，因此需要概率为我们提供依据。</p><h3 id="概率"><a href="#概率" class="headerlink" title="概率"></a>概率</h3><blockquote><p>概率是用来衡量事物在跨时间后的不同状态的确信度</p></blockquote><h3 id="熵与生命"><a href="#熵与生命" class="headerlink" title="熵与生命"></a>熵与生命</h3><blockquote><p>生命活着就在减熵：利用信息压缩（或者说抽象）后形成的知识，对抗熵增！</p></blockquote><p>　智能的条件</p><ul><li>智能LV1:从环境到行动的关联能力[生存]（植物&amp;微生物）</li><li>智能LV2:利用过去到未来的关联能力[预测]（动物）</li><li>智能的实现：通过存储关联的材料（遗传物质）</li></ul><hr><h2 id="自然智能"><a href="#自然智能" class="headerlink" title="自然智能"></a>自然智能</h2><h3 id="RNA与DNA（智能LV1）"><a href="#RNA与DNA（智能LV1）" class="headerlink" title="RNA与DNA（智能LV1）"></a>RNA与DNA（智能LV1）</h3><ul><li>识别：DNA上的信息：蛋白质合成。</li><li>学习：繁衍，变异，筛选。</li><li>进化：<strong>进化是以种群为单位的被动过程</strong><br>　问题：在<strong>《未来简史》</strong>中，作者描述人类将打破自然选择的进化理论，转而通过基因改造技术“主动”进化。</li><li>永生的缺陷：永生者失去了为种群提供差异性的筛选功能。</li></ul><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><ol><li>神经元的本质行为：<br>$$y=a(Wx+b),其中x是输入信号，y是输出信号$$</li></ol><hr><h2 id="人工智能"><a href="#人工智能" class="headerlink" title="人工智能"></a>人工智能</h2><h3 id="梯度下降的问题"><a href="#梯度下降的问题" class="headerlink" title="梯度下降的问题"></a>梯度下降的问题</h3><ul><li>局部最小值（鞍点）的解决方案：<ul><li>随机梯度下降：每次只更新一个样本所计算的梯度</li><li>小批量梯度下降：每次更新若干样本所计算梯度的平均值</li><li>.etc</li></ul></li></ul><h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><blockquote><p>神经网络不缺少新结构，但缺少一个该领域的$E=mc^2$</p></blockquote><ol><li>为什么神经网络高效：并行的先验知识使得模型可用线性级数量的样本学习指数级数量<br>的变体：</li><li>学习的本质是什么：将变体拆分成因素和知识（Disentangle Factors of Variation）</li><li>为什么深层神经网络比浅层神经网络更高效：</li><li>神经网络在什么问题上不具备优势：<ul><li>非函数问题：需要想办法将问题转化为函数问题</li><li>非迭代：该层的状态不是由上层状态构成的任务</li></ul></li></ol><h3 id="深度学习计算机实现平台：tensorflow"><a href="#深度学习计算机实现平台：tensorflow" class="headerlink" title="深度学习计算机实现平台：tensorflow"></a>深度学习计算机实现平台：tensorflow</h3><p>Tensorflow基本用法</p><ol><li>准备阶段：组装计算图<ul><li>计算图<code>想象成一个管道</code>：需要组装的结构，由许多操作组成</li><li>操作<code>想象成不通管道分支的连接处</code>：对零个或多个数据进行输入与输出</li><li>数据类型：1.张量（tensor）2.变量（variable）3.常量（constant）<ul><li>张量<code>想象成管道中的液体</code>：多维度array或者list<br>  tener_name = tf.placeholder(type, shape, name)</li><li>变量：在同一时刻对图中所有其他操作都保持静态的数据（管道中的阀门）<br>  name_variable = tf.Variable(value, name)</li><li>常量：无需初始化的变量<br>  name_constant = tf.constant(value)</li></ul></li></ul></li><li>执行阶段：使用计算图<ul><li>执行语句: sess.run(op)</li><li>送值（feed）: 输入操作的输入值（输入液体）<br>  sess.run([output], feed_dict={input1:value1, input2:value2})</li><li>取值（fetch）: 获取操作的输出值（得到液体）<br>  sess.run(one op)<br>  sess.run([a list of op])</li></ul></li></ol><h3 id="DEMO部分："><a href="#DEMO部分：" class="headerlink" title="DEMO部分："></a>DEMO部分：</h3><p>YJango博士的部分demo由于tensorflow版本问题可能无法运行，我将部分代码已经“修正”并已上传至github，本地环境测试均可通过，请大家放心使用。<br><a href="https://github.com/824zzy/TutorialTensorflow" target="_blank" rel="noopener">代码部分的笔记</a></p><blockquote><p>参考与引用: 1. 《超智能体》 于建国（Yjango）博士</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;blockquote&gt;
&lt;p&gt;版权说明：&lt;br&gt;本文仅记录在阅读 于建国（YJango）博士的《超智能体》一书过程中的笔记。本文作者已通过邮件联系作者，获得授权。&lt;/p&gt;
&lt;/b
      
    
    </summary>
    
      <category term="AI" scheme="https://824zzy.github.io/categories/AI/"/>
    
    
      <category term="readingNote" scheme="https://824zzy.github.io/tags/readingNote/"/>
    
      <category term="mathematics" scheme="https://824zzy.github.io/tags/mathematics/"/>
    
  </entry>
  
  <entry>
    <title>GRE填空逻辑方法总结</title>
    <link href="https://824zzy.github.io/2018/06/10/GRE-verbal-method/"/>
    <id>https://824zzy.github.io/2018/06/10/GRE-verbal-method/</id>
    <published>2018-06-09T16:00:00.000Z</published>
    <updated>2018-07-29T03:06:31.508Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="同意重复"><a href="#同意重复" class="headerlink" title="同意重复"></a>同意重复</h2><blockquote><p>同意重复定义：句中通过一些明显的指示代词和指代性的名词对前文或者后文的内容进行重复的题目考点</p></blockquote><ol><li>同意重复常见标志代词：<code>this,that,such,this very（正是这个）,the,the same,the former/later</code>等</li><li>同意重复扩展标志词：<code>necessarily, surely, definitely, equally, parallel</code></li></ol><p>广义同/反义词</p><blockquote><p>在评价正负性方向相同/相反的词汇和短语（善良、勇敢 VS 无知 吝啬）</p></blockquote><p>补充知识点：if的用法</p><ol><li>如果：</li><li>是否：</li><li>即使：if not all（即使不是全部），“大部分”的意思</li><li>其他短语：<ul><li>If any:即便有</li><li>If ever:如果真有</li><li>If at all:即使某事真的 发生</li></ul></li></ol><hr><h2 id="因果关系"><a href="#因果关系" class="headerlink" title="因果关系"></a>因果关系</h2><h3 id="因果关系逻辑词"><a href="#因果关系逻辑词" class="headerlink" title="因果关系逻辑词"></a>因果关系逻辑词</h3><ul><li><p>表原因：because, since, for, in that(GRE常用！), now that（既然）,  as, because of, due to, given（GRE常用！）, on the ground that, on ground of, as long as </p><h4 id="例句："><a href="#例句：" class="headerlink" title="例句："></a>例句：</h4><ul><li>Dramatic literature often recapitulates the history of a culture in that <strong>it takes as its subject matter the important event</strong> that have shaped and guided the culture.</li><li>=Dramatic literature often recapitalates the history of a culture in that it takes the important events that have shaped and guided the culture as its subject matter.<br>补充知识点：宾语后置<blockquote><p>宾语后置：在“主语+谓语+宾语+状语”的句型中。有时候宾语如果有修饰成分，则可以把宾语后置 </p></blockquote></li></ul></li><li><p>表结果：therefore, thereby, thus, so, whereby, as a result, consequently, so(such)…that…, so(such)…as to, too…to…等</p></li><li>其他因果逻辑词：result in(左边导致右边), result from(右边导致左边), lead to, give rise to, bring about</li></ul><h3 id="解题要点"><a href="#解题要点" class="headerlink" title="解题要点"></a>解题要点</h3><p>根据已知的因果关系判断空格语义，再选取同义或者广义同义。</p><p>补充知识点：as long as用法</p><pre><code>- 和...一样长：This stick is as long as that one- 只要...,如果：We can do this directly as long as we have certain types of information- 既然，因为：As long as you have been here, you could wait for a moment.</code></pre><hr><h2 id="目的手段"><a href="#目的手段" class="headerlink" title="目的手段"></a>目的手段</h2><h3 id="表示目的的词或者短语："><a href="#表示目的的词或者短语：" class="headerlink" title="表示目的的词或者短语："></a>表示目的的词或者短语：</h3><p>to do, for doing, in order to, so that, for fear that, lest, in case, for 等</p><h3 id="表示手段的词或者短语："><a href="#表示手段的词或者短语：" class="headerlink" title="表示手段的词或者短语："></a>表示手段的词或者短语：</h3><p>by doing, whereby, by means of, be way of, depend on, rely on, by virtur of 等</p><h3 id="目的手段题目解题要点"><a href="#目的手段题目解题要点" class="headerlink" title="目的手段题目解题要点"></a>目的手段题目解题要点</h3><p>根据目的反推手段或者方法，或者根据手段推导目的或者结果</p><hr><h2 id="解释说明"><a href="#解释说明" class="headerlink" title="解释说明"></a>解释说明</h2><h3 id="解释说明标志词："><a href="#解释说明标志词：" class="headerlink" title="解释说明标志词："></a>解释说明标志词：</h3><p>冒号（：），破折号（-），定语从句，分词短语做状语，同位语，形容词短语，主系表结构等 </p><h3 id="解题要点-1"><a href="#解题要点-1" class="headerlink" title="解题要点"></a>解题要点</h3><p>对解释说明的信息进行同义改写</p><hr><h2 id="类比关系"><a href="#类比关系" class="headerlink" title="类比关系"></a>类比关系</h2><h3 id="类比关系标志词"><a href="#类比关系标志词" class="headerlink" title="类比关系标志词"></a>类比关系标志词</h3><p><code>just as, like, as...as, as if/as though, resemble, similarly, in the same way, like wise 等</code></p><h3 id="解题要点-2"><a href="#解题要点-2" class="headerlink" title="解题要点"></a>解题要点</h3><p>找类比关系进行同义改写</p><hr><h2 id="并列关系"><a href="#并列关系" class="headerlink" title="并列关系"></a>并列关系</h2><h3 id="并列关系标志词"><a href="#并列关系标志词" class="headerlink" title="并列关系标志词"></a>并列关系标志词</h3><p><code>and, or, not only...but alse, not just...but also, as well as, at once...and等</code></p><h3 id="并列分为顺承并列和转折并列"><a href="#并列分为顺承并列和转折并列" class="headerlink" title="并列分为顺承并列和转折并列"></a>并列分为顺承并列和转折并列</h3><ul><li>我欣赏她的美丽和善良</li><li>我既喜欢这本书又介意它的一些细节</li></ul><h3 id="解题要点-3"><a href="#解题要点-3" class="headerlink" title="解题要点"></a>解题要点</h3><p>　找同义广义词（很少找直接同义词）</p><hr><h2 id="递进关系"><a href="#递进关系" class="headerlink" title="递进关系"></a>递进关系</h2><h3 id="递进关系逻辑词"><a href="#递进关系逻辑词" class="headerlink" title="递进关系逻辑词"></a>递进关系逻辑词</h3><p><code>even, not only ... but also, indeed, especially, particularly, in addition, moreover, futher more, all the more</code></p><h3 id="注意even的停发"><a href="#注意even的停发" class="headerlink" title="注意even的停发"></a>注意even的停发</h3><ul><li>even表示让步转折：多放在句首，<strong>即使</strong></li><li>even表示递进关系：多放在句中，<strong>更加</strong></li></ul><h3 id="解题要点-4"><a href="#解题要点-4" class="headerlink" title="解题要点"></a>解题要点</h3><p>　加强递进/减弱递进</p><hr><h2 id="让步转折"><a href="#让步转折" class="headerlink" title="让步转折"></a>让步转折</h2><h3 id="让步转折逻辑词"><a href="#让步转折逻辑词" class="headerlink" title="让步转折逻辑词"></a>让步转折逻辑词</h3><p><code>even, although, though, despite, however, nevertheless, but, in spite of, for all=despite, even as, even when, as</code></p><h3 id="解题要点-5"><a href="#解题要点-5" class="headerlink" title="解题要点"></a>解题要点</h3><p>　取反义或广义反义</p><h2 id=""><a href="#" class="headerlink" title="　"></a>　</h2><h2 id="对比关系"><a href="#对比关系" class="headerlink" title="对比关系"></a>对比关系</h2><h3 id="对比关系逻辑词"><a href="#对比关系逻辑词" class="headerlink" title="对比关系逻辑词"></a>对比关系逻辑词</h3><ul><li>连接性关系词：<code>rather than, far from, on the contratary, in contrast to, compare with, unlike, different from, not but</code></li><li>对比关系的其他逻辑词：<code>ironic, surprising, stunning, strange, mask, belie, veil, seem, appear, paradox, contradiction, dichtomy</code></li></ul><h3 id="解题要点-6"><a href="#解题要点-6" class="headerlink" title="解题要点"></a>解题要点</h3><p>　取反义或广义反义词</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;同意重复&quot;&gt;&lt;a href=&quot;#同意重复&quot; class=&quot;headerlink&quot; title=&quot;同意重复&quot;&gt;&lt;/a&gt;同意重复&lt;/h2&gt;&lt;blockquote&gt;
&lt;p
      
    
    </summary>
    
      <category term="GRE" scheme="https://824zzy.github.io/categories/GRE/"/>
    
    
      <category term="verbal" scheme="https://824zzy.github.io/tags/verbal/"/>
    
  </entry>
  
  <entry>
    <title>GRE阅读导学</title>
    <link href="https://824zzy.github.io/2018/06/10/GRE-reasoning-overall/"/>
    <id>https://824zzy.github.io/2018/06/10/GRE-reasoning-overall/</id>
    <published>2018-06-09T16:00:00.000Z</published>
    <updated>2018-07-29T03:03:48.019Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="语言-amp-题目"><a href="#语言-amp-题目" class="headerlink" title="语言&amp;题目"></a>语言&amp;题目</h2><ul><li>Specify your problems</li><li>Simplify your solutions</li></ul><h2 id="GRE-General-Test"><a href="#GRE-General-Test" class="headerlink" title="GRE General Test"></a>GRE General Test</h2><ul><li>Analytical Writing</li><li>Verbal Reasoning</li><li>Quantitative Reasoning</li></ul><h3 id="Analytical-Writing-2-tasks"><a href="#Analytical-Writing-2-tasks" class="headerlink" title="Analytical Writing(2 tasks)"></a><strong>Analytical Writing</strong>(2 tasks)</h3><h3 id="Verbal-Reasoning-2-sections"><a href="#Verbal-Reasoning-2-sections" class="headerlink" title="Verbal Reasoning(2 sections)"></a><strong>Verbal Reasoning</strong>(2 sections)</h3><p>30 min &amp; 20 proplems</p><h3 id="Quantitative-Reasoning-2-sections"><a href="#Quantitative-Reasoning-2-sections" class="headerlink" title="Quantitative Reasoning(2 sections)"></a><strong>Quantitative Reasoning</strong>(2 sections)</h3><h3 id="Unscored-positon-varies"><a href="#Unscored-positon-varies" class="headerlink" title="Unscored(positon varies)"></a>Unscored(positon varies)</h3><h3 id="score-standard"><a href="#score-standard" class="headerlink" title="score standard"></a>score standard</h3><p>section-level(根据第一部分的分数决定第二部分的难度)</p><hr><h2 id="GRE-Verbal-Reasoning"><a href="#GRE-Verbal-Reasoning" class="headerlink" title="GRE Verbal Reasoning"></a>GRE Verbal Reasoning</h2><ul><li>Reading Comprehension(20 min)</li><li>Text Completion</li><li>Sentence Equivalence</li></ul><h3 id="Reading-Comprehension"><a href="#Reading-Comprehension" class="headerlink" title="Reading Comprehension"></a>Reading Comprehension</h3><ul><li>长文章 4</li><li>短文章 2</li><li>逻辑单题 1</li></ul><h3 id="文章初体验"><a href="#文章初体验" class="headerlink" title="文章初体验"></a>文章初体验</h3><ul><li>plant <strong>communities</strong>:群落</li><li>more <strong>susceptible</strong> than:易受影响的</li><li><strong>inconsistent</strong> theroy:前后不一致的</li><li>resource-release <strong>mechanisms</strong>:方式方法</li><li><strong>ecological</strong> correlates: 生态学的</li><li>no <strong>necessary</strong> relationship:必然的</li><li>this may <strong>arise from</strong> sth:由于</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;语言-amp-题目&quot;&gt;&lt;a href=&quot;#语言-amp-题目&quot; class=&quot;headerlink&quot; title=&quot;语言&amp;amp;题目&quot;&gt;&lt;/a&gt;语言&amp;amp;题目
      
    
    </summary>
    
      <category term="GRE" scheme="https://824zzy.github.io/categories/GRE/"/>
    
    
      <category term="reasoning" scheme="https://824zzy.github.io/tags/reasoning/"/>
    
  </entry>
  
  <entry>
    <title>GRE填空逻辑方法总结</title>
    <link href="https://824zzy.github.io/2018/06/10/GRE-verbal-overall/"/>
    <id>https://824zzy.github.io/2018/06/10/GRE-verbal-overall/</id>
    <published>2018-06-09T16:00:00.000Z</published>
    <updated>2018-07-29T03:11:34.398Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="GRE填空简介"><a href="#GRE填空简介" class="headerlink" title="GRE填空简介"></a>GRE填空简介</h2><ol><li>题目数量：每个section10个题目，一共两个section共20题</li><li>题目类型：</li></ol><ul><li>单空题：五选一</li><li>双空题：三选一</li><li>三空题：三选一</li><li>句子等价：六选二（选同义词）</li></ul><hr><h2 id="如何取得高分？"><a href="#如何取得高分？" class="headerlink" title="如何取得高分？"></a>如何取得高分？</h2><ol><li><p>词汇：不能低于12000，最好在15000以上</p><blockquote><p>五遍以下纯裸考，十遍以下比基尼考</p></blockquote><ul><li>relying on the <strong>well-to-do</strong> for <strong>commissions</strong>：有钱人&amp;佣金</li><li>hypocrite：虚伪</li><li>egotist：以自我为中心这</li><li>sycophant：奉承者</li><li>adulator：奉承者</li><li>braggart：自夸者</li><li>coward：懦夫</li><li>if sth at all：即使真的发生某事</li></ul></li><li>句子结构（主要是语法问题）<ul><li>后置定语（四种）：<ul><li>The boy <strong>who is reading a book</strong>：定语从句做后置定语</li><li>The boy <strong>reading a book</strong>：分词短语做后置定语</li><li>The boy <strong>in a red sweater</strong>:介词短语做后置定语</li><li>The boy angry at his teacher:形容词短语做后置定语</li><li>真题例句：The writer so <strong>wary of extravagance</strong> was <strong>profligate</strong> with paper：对奢侈浪费十分谨慎;浪荡 行为不检点</li></ul></li><li>倒装句<ul><li>1.部分倒装：Only by ignoring decades of mismanagement and inefficiency could investors conclude that a fresh <strong>infusion of cash</strong> of cash would provide anything other than a <strong>fleeting solution</strong> to the company’s <strong>financial woes</strong>.：注入现金；短暂的方案；金融危机<ul><li>主句正常结构是：Investors could conclude that … only by ignoring decades of …</li><li>部分倒装（助动词，Be动词，情态动词提前）<ul><li>only + 状语提前句子部分倒装</li><li>否定副词提前句子部分倒装</li></ul></li></ul></li><li>2.完全倒装：Burke is often on slippery ground when it comes to her primary sources;<strong>especially duious is the mode</strong> by which she gathered her oral evidence<ul><li>正常语序：Burke is often on slippery ground when it comes to her primary sources;<strong>the mode is especially duious</strong> by which she gathered her oral evidence</li><li>完全倒装知识讲解：<ul><li>1.“主谓句+地点状语/时间状语”中状语可以提前</li><li>2.“主语+be动词+表语（形容词短语，介词短语，分词短语）”</li></ul></li></ul></li></ul></li><li>插入语：<ul><li>常见插入语例子：To be frank；The teacher,along with the headmaster,is doing sth</li><li>如何处理插入语：先看插入语之外的句子结构，再带入插入语进行完整的理解。</li></ul></li><li>That引导主语从句（that的从句用作主语）</li><li>As引导的让步状语从句<ul><li>1.作为：As a student, I must study hard</li><li>2.当：It was raining as I came back to my car</li><li>3.因为：As he is a child, we should not blame him</li><li>4.如此：I am as tall as my father</li><li>5.与…比起来：I am as tall as my father</li><li>6.尽管：<ul><li>Child as he is, he know everything = Although he is a child, he knows everything</li><li>Object as you may, I will go = Although you may object, I will go</li><li>Much as you like it, I will not buy it. = Although you like it, I will not buy it for you.</li></ul></li></ul></li><li>语法补充知识点（自学）<ul><li>六大从句</li><li>强调句</li><li>虚拟语气</li><li>非谓语动词</li></ul></li></ul></li></ol><ol start="3"><li><p>逻辑推理</p><ul><li>逻辑要收敛：任何推理都要基于题目本身！<ul><li>erudite：博学的</li><li>insular：与世隔绝的</li><li>cosmopolitan：四海为家的</li><li>imperturbable：泰然自若的</li></ul></li><li>很多时候我们只需要掌握句子的逻辑主线，不必过于纠结于汉语的翻译。<ul><li>savor：品尝 欣赏</li><li>rejoice:庆祝</li><li>prevarication：搪塞</li><li>flattery：奉承</li><li>affectat：感动</li><li>narcissism：自恋；水仙花</li><li>indolence：懒散</li><li>fecundit：肥沃富饶</li><li>economy：节约；理财</li></ul></li></ul></li><li><p>对应技巧</p><ul><li>填空核心方法总结<strong>：读懂句意-简化句意-梳理核心逻辑-找到空格对应点-选出答案</strong></li><li>练习：<ul><li>disdain：蔑视</li><li>egalitarian：平等主义</li><li>maverick：特立独行</li><li>dilettante：一知半解者</li><li>iconoclast：偶像破坏者</li><li>purveyor：承办商</li><li>prose:散文</li><li>general：将军</li><li>belligerence:好战的</li><li>indigence：贫穷</li><li>perfidy：背信弃义</li><li>betrayal：揭露</li><li>haughty：高傲的</li></ul></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;GRE填空简介&quot;&gt;&lt;a href=&quot;#GRE填空简介&quot; class=&quot;headerlink&quot; title=&quot;GRE填空简介&quot;&gt;&lt;/a&gt;GRE填空简介&lt;/h2&gt;&lt;ol
      
    
    </summary>
    
      <category term="GRE" scheme="https://824zzy.github.io/categories/GRE/"/>
    
    
      <category term="verbal" scheme="https://824zzy.github.io/tags/verbal/"/>
    
  </entry>
  
  <entry>
    <title>GRE阅读方法总结</title>
    <link href="https://824zzy.github.io/2018/06/10/GRE-reasoning-method/"/>
    <id>https://824zzy.github.io/2018/06/10/GRE-reasoning-method/</id>
    <published>2018-06-09T16:00:00.000Z</published>
    <updated>2018-07-29T03:02:37.320Z</updated>
    
    <content type="html"><![CDATA[<script src="/assets/js/APlayer.min.js"> </script><h2 id="Reading的正确打开方式"><a href="#Reading的正确打开方式" class="headerlink" title="Reading的正确打开方式"></a>Reading的正确打开方式</h2><blockquote><p>Reading is <strong>not</strong> translation! 方向错了，就算再努力，也会在错误的方向越走越远</p></blockquote><ol><li><p>先读文章：<br> Key words =&gt; Important information =&gt; Function of sentences</p></li><li><p>答题原则</p></li></ol><ul><li>忠于文本</li><li>区分题型</li><li>读懂选项</li></ul><hr><h2 id="短文章题目类型（前四类）"><a href="#短文章题目类型（前四类）" class="headerlink" title="短文章题目类型（前四类）"></a>短文章题目类型（前四类）</h2><ul><li>although/though/even tho ugh/even if：表示让步（句内逻辑）</li><li>任何英语句子：1.表示thing 2.表示state</li></ul><h3 id="全文主旨题："><a href="#全文主旨题：" class="headerlink" title="全文主旨题："></a><strong>全文主旨题</strong>：</h3><ul><li>The passage is <strong>primarily concerned</strong> with</li><li>Which of the following best states <strong>the central idea</strong> of the passage</li><li>The <strong>primary purpose</strong> of the passage is to<br>  思路：文章结构+文章开头</li></ul><h3 id="推理题（基于原文）："><a href="#推理题（基于原文）：" class="headerlink" title="推理题（基于原文）："></a><strong>推理题</strong>（基于原文）：</h3><ul><li>标志词：<code>inferred</code>/<code>suggest</code>/<code>implies</code></li><li>It can be inferred from the passage that …?</li><li>The author suggests/implies which of the following about …?<br>  思路：<ol><li>定位（scanning 问啥找啥 找第一次）</li><li>读定位词所在句（OR 其前后1-2句）</li><li>匹配选项（定位词所在句OR 其前后1-2句 的同意替换）</li></ol></li></ul><h3 id="作者意图题"><a href="#作者意图题" class="headerlink" title="作者意图题"></a><strong>作者意图题</strong></h3><ul><li>标志词：The author of the passage mentions … primarily <code>in order to</code><br>  思路：<ol><li>定位…所在句</li><li>句内/句间 逻辑</li></ol></li></ul><h3 id="事实内容题"><a href="#事实内容题" class="headerlink" title="事实内容题"></a><strong>事实内容题</strong></h3><ul><li>标志词：<code>which of the following is true of sth</code><br>  思路：<ol><li>定位包含信息点的句子：</li><li>直接看选项找同意替换的选项</li><li>如果没有答案，就接着看下一句</li></ol></li></ul><hr><h2 id="其他题型"><a href="#其他题型" class="headerlink" title="其他题型"></a>其他题型</h2><h3 id="不定项选择题"><a href="#不定项选择题" class="headerlink" title="不定项选择题"></a><strong>不定项选择题</strong></h3><p>依题目要求作答</p><h3 id="观点论证题"><a href="#观点论证题" class="headerlink" title="观点论证题"></a><strong>观点论证题</strong></h3><p>观点标志词</p><ul><li><code>notion</code>/<code>belief</code>/<code>view</code>/<code>point</code>/<code>perception</code>…</li><li>…<code>argue</code>…：认为 </li></ul><h3 id="补充知识点-qualify"><a href="#补充知识点-qualify" class="headerlink" title="补充知识点: qualify"></a>补充知识点: qualify</h3><blockquote><p>If you qualify a statement, you make it less strong or less general by adding a detail or explanation to it.</p></blockquote><h3 id="高亮句作用题"><a href="#高亮句作用题" class="headerlink" title="高亮句作用题"></a><strong>高亮句作用题</strong></h3><ul><li>读懂<code>高亮句</code></li><li>读懂<code>前后句</code></li><li>理解<code>句间关系</code></li></ul><h3 id="补充知识点：句间关系"><a href="#补充知识点：句间关系" class="headerlink" title="补充知识点：句间关系"></a>补充知识点：句间关系</h3><blockquote><p>英文常用顶真方式连接文章逻辑。<code>上句末尾，本句开头</code></p></blockquote><h3 id="文学评论"><a href="#文学评论" class="headerlink" title="文学评论"></a><strong>文学评论</strong></h3><h4 id="补充知识点：wry"><a href="#补充知识点：wry" class="headerlink" title="补充知识点：wry"></a>补充知识点：wry</h4><blockquote><p>a wry expression or wry humor shows that you know a situation is bad, but you alse think it is slightly amusing</p></blockquote><hr><h2 id="精读速度训练"><a href="#精读速度训练" class="headerlink" title="精读速度训练"></a>精读速度训练</h2><h3 id="反应速度训练"><a href="#反应速度训练" class="headerlink" title="反应速度训练"></a>反应速度训练</h3><ol><li>中文（sentence by sentence） 每天2-3篇 练5天；卡壳就查/录音查漏补缺</li><li>英文（sentence by sentence） 每天2-3篇 练5天；卡壳就查/录音查漏补缺</li><li>英文（不出声 停顿两秒想这句话的意思<code>keyword and meaning</code>） 每天2-3篇 练5天</li></ol><h3 id="专注度"><a href="#专注度" class="headerlink" title="专注度"></a>专注度</h3><h3 id="记忆力"><a href="#记忆力" class="headerlink" title="记忆力"></a>记忆力</h3><hr><h2 id="意群划分"><a href="#意群划分" class="headerlink" title="意群划分"></a>意群划分</h2><ol><li>介词短语：prepositional phrase(prep)<ul><li>of individual folktales</li><li>in the place</li></ul></li><li>分词短语：participial phrase（part）<ul><li>concerning the exact point</li><li>told by aliens</li></ul></li><li>形容词短语：adjective pharse(adj)<ul><li>full of books</li><li>useful for me</li></ul></li><li>不定式：infinitive phrase(inf)<ul><li>to do</li></ul></li><li>从句：subordinate clause(sub)<ul><li>that/which/whose</li></ul></li></ol><h2 id="长文章"><a href="#长文章" class="headerlink" title="长文章"></a>长文章</h2><h3 id="类型-思路"><a href="#类型-思路" class="headerlink" title="类型/思路"></a>类型/思路</h3><ol><li>详略结合<br>详读<br>（主题句 + 段末总结 + 逻辑关系）<br>略读<br>（举例 + 展开描述）</li><li>分清题型</li></ol><h3 id="段内关系"><a href="#段内关系" class="headerlink" title="段内关系"></a>段内关系</h3><h3 id="段间关系"><a href="#段间关系" class="headerlink" title="段间关系"></a>段间关系</h3><hr><h2 id="逻辑单题的类型-思路-解题步骤"><a href="#逻辑单题的类型-思路-解题步骤" class="headerlink" title="逻辑单题的类型/思路/解题步骤"></a>逻辑单题的类型/思路/解题步骤</h2><h3 id="逻辑单题的类型"><a href="#逻辑单题的类型" class="headerlink" title="逻辑单题的类型"></a>逻辑单题的类型</h3><ul><li>假设<ol><li>提问方式<ul><li>Which of the following is an <strong>assumption</strong> on which the argument depends?</li><li>Which of the following is an <strong>assumption</strong> on which the argument relies?</li></ul></li><li>检查选项的逻辑成立的条件</li></ol></li><li>推理<ol><li>提问方式<ul><li>The information given, if accurate,most strongly supports which of the following <strong>hypotheses</strong>? </li><li>Which of the following <strong>conclusions</strong> is the best supported by the information? </li></ul></li></ol></li><li>加强<ol><li>提问方式<ul><li>Which of the following,if true,<strong>most strengthens</strong> the argument given?</li><li>Which is the following provide <strong>the most support</strong> for the argument</li></ul></li><li>选项提高结论的可信度</li></ol></li><li>句子功能<ol><li>提问方式<ul><li>In the argument given, the <strong>two highlighted portions</strong> play which of the following roles?</li></ul></li></ol></li><li>削弱<ol><li>提问方式<ul><li>Which of the following,if true,<strong>most weakens</strong> the argument given?</li><li>Which of the following,if true,<strong>most seriously undermines</strong>…?</li></ul></li></ol></li><li>填空<ol><li>提问方式<ul><li>Which of the following,if true,most logically complete the argument?</li></ul></li></ol></li></ul><h3 id="逻辑单题的解题步骤"><a href="#逻辑单题的解题步骤" class="headerlink" title="逻辑单题的解题步骤"></a>逻辑单题的解题步骤</h3><ol><li><p>看题目（确定类型）{5秒钟}</p></li><li><p>看文章（读懂逻辑）{45秒钟}</p></li><li>想原理（预设提问）[用中文想]{20秒钟}</li><li>看选项（排除错选）{60秒钟}</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;Reading的正确打开方式&quot;&gt;&lt;a href=&quot;#Reading的正确打开方式&quot; class=&quot;headerlink&quot; title=&quot;Reading的正确打开方式
      
    
    </summary>
    
      <category term="GRE" scheme="https://824zzy.github.io/categories/GRE/"/>
    
    
      <category term="reasoning" scheme="https://824zzy.github.io/tags/reasoning/"/>
    
  </entry>
  
</feed>

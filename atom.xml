<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Awesome Chatbot</title>
  
  <subtitle>Blog by Handsome Geeks</subtitle>
  <link href="/awesome-chatbot/atom.xml" rel="self"/>
  
  <link href="https://bupt.github.io/awesome-chatbot/"/>
  <updated>2018-08-14T07:12:52.078Z</updated>
  <id>https://bupt.github.io/awesome-chatbot/</id>
  
  <author>
    <name>BUPTer</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>对话AI的论文列表</title>
    <link href="https://bupt.github.io/awesome-chatbot/2018/08/09/convAI-paper-list/"/>
    <id>https://bupt.github.io/awesome-chatbot/2018/08/09/convAI-paper-list/</id>
    <published>2018-08-09T04:31:31.000Z</published>
    <updated>2018-08-14T07:12:52.078Z</updated>
    
    <content type="html"><![CDATA[<script src="/awesome-chatbot/assets/js/APlayer.min.js"> </script><blockquote><p>论文列表格式<br>&emsp;论文发表年份： 论文题目&amp;论文链接：第一作者（第一作者所属学校/机构），代码链接</p></blockquote><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><h3 id="Existing-Models-of-Dialog-System"><a href="#Existing-Models-of-Dialog-System" class="headerlink" title="Existing Models of Dialog System"></a>Existing Models of Dialog System</h3><h4 id="Task-Oriented-Dialog"><a href="#Task-Oriented-Dialog" class="headerlink" title="Task-Oriented Dialog"></a>Task-Oriented Dialog</h4><ul><li>13: <a href="https://ieeexplore.ieee.org/document/6407655/" target="_blank" rel="noopener"><strong>POMDP-Based Statistical Spoken Dialog Systems: A Review</strong></a>: Steve Young(Cambridge University)</li><li>11: <a href="https://www.wiley.com/en-us/Spoken+Language+Understanding:+Systems+for+Extracting+Semantic+Information+from+Speech-p-9780470688243" target="_blank" rel="noopener"><strong>Spoken Language Understanding: Systems for Extracting Semantic Information from Speech</strong></a>: Book!</li><li>11:<a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener"><strong>Data-Driven Response Generation in Social Media</strong></a>: Alan Ritter(University of Washington Seattle)</li><li><p>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener"><strong>A Neural Network Approach to Context-Sensitive Generation of Conversational Responses</strong></a>: Alessandro Sordoni(Universite de Montreal)</p></li><li><p>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener"><strong>A Neural Conversational Model</strong></a>: Oriol Vinyals(Google), <a href="https://github.com/Conchylicultor/DeepQA" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</p></li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener"><strong>Neural Responding Machine for Short-Text Conversation</strong></a>: Lifeng Shang(Noah’s Ark Lab), <a href="https://github.com/stamdlee/DeepLearningFramework" target="_blank" rel="noopener"><strong>code</strong></a> via theano and tensorflow</li></ul><h3 id="Traditional-NLP-component-stack"><a href="#Traditional-NLP-component-stack" class="headerlink" title="Traditional NLP component stack"></a>Traditional NLP component stack</h3><h4 id="Challenge-of-NLP"><a href="#Challenge-of-NLP" class="headerlink" title="Challenge of NLP"></a>Challenge of NLP</h4><ul><li>09: <a href="https://www.cs.colorado.edu/~martin/slp.html" target="_blank" rel="noopener"><strong>SPEECH and LANGUAGE PROCESSING An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Second Edition</strong></a>: book </li></ul><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h4 id="application-scenarios"><a href="#application-scenarios" class="headerlink" title="application scenarios"></a>application scenarios</h4><ol><li>Web search<ul><li>13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), <a href="https://github.com/wangtianqi1993/DL-WebSearch" target="_blank" rel="noopener"><strong>code</strong></a> via tensorflow</li><li>14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li></ul></li><li>Entity linking<ul><li>14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Image captioning<ul><li>15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul></li><li>Machine Translation<ul><li><a href="http://aclweb.org/anthology/P/P14/P14-1066.pdf" target="_blank" rel="noopener"><strong>Learning Continuous Phrase Representations for Translation Modeling</strong></a>: Jianfeng Gao(Microsoft Research)</li></ul></li><li>Online recommendation<ul><li>[<strong>duplicate</strong>] 14: <a href="http://anthology.aclweb.org/D/D14/D14-1002.pdf" target="_blank" rel="noopener"><strong>Modeling Interestingness with Deep Neural Networks</strong></a>: Jianfneg Gao(Microsoft Research)</li></ul></li></ol><h4 id="Framework-of-Model"><a href="#Framework-of-Model" class="headerlink" title="Framework of Model"></a>Framework of Model</h4><ul><li>[<strong>duplicate</strong>] 13: <a href="http://dl.acm.org/citation.cfm?id=2505665" target="_blank" rel="noopener"><strong>Learning deep structured semantic models for web search using clickthrough data</strong></a>: Po-Sen Huang(University of Illinois at Urbana-Champaign), [<strong>code</strong>]<ul><li>[<strong>duplicate</strong>] 14: <a href="http://dl.acm.org/citation.cfm?doid=2661829.2661935" target="_blank" rel="noopener"><strong>A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</strong></a>: Yelong Shen(Microsoft Research)</li></ul></li><li>16: <a href="https://arxiv.org/abs/1502.06922" target="_blank" rel="noopener"><strong>Deep Sentence Embedding Using Long Short-Term Memory Networks: Analysis and Application to Information Retrieval</strong></a>: Hamid Palangi, <a href="https://github.com/zhaosm/dssm-lstm" target="_blank" rel="noopener"><strong>code</strong></a></li><li><a href="http://aka.ms/sent2vec" target="_blank" rel="noopener">Sent2Vec</a>: software by microsoft</li></ul><h4 id="Go-beyound-DSSM"><a href="#Go-beyound-DSSM" class="headerlink" title="Go beyound DSSM"></a>Go beyound DSSM</h4><ul><li>[<strong>duplicate</strong>] 15: <a href="https://arxiv.org/abs/1411.4952" target="_blank" rel="noopener"><strong>From Captions to Visual Concepts and Back</strong></a>: Hao Fang&amp;Li Deng(Microsoft Research)</li></ul><hr><h2 id="Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC"><a href="#Question-answeriing-QA-and-Machine-Readiing-Comprehension-MRC" class="headerlink" title="Question answeriing(QA) and Machine Readiing Comprehension(MRC)"></a>Question answeriing(QA) and Machine Readiing Comprehension(MRC)</h2><h3 id="Open-Domain-Question-Answering"><a href="#Open-Domain-Question-Answering" class="headerlink" title="Open-Domain Question Answering"></a>Open-Domain Question Answering</h3><h4 id="Knowledge-Base-QA"><a href="#Knowledge-Base-QA" class="headerlink" title="Knowledge Base-QA"></a>Knowledge Base-QA</h4><ol><li>Symbolic approach via Large-scale knowledge graphs<ul><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>: Stephen D.Richardson(Microsoft Research)</li><li>13: <a href="http://www.aclweb.org/anthology/D13-1160" target="_blank" rel="noopener">Semantic Parsing on Freebase from Question-Answer Pairs</a>: Jonathan Berant(Stanford University)</li><li>15: <a href="https://arxiv.org/pdf/1510.08565.pdf" target="_blank" rel="noopener">Attention with Intention for a Neural Network Conversation Model</a>: Kaisheng Yao(Microsoft Research)</li><li>14: <a href="http://www.aclweb.org/anthology/P14-1091" target="_blank" rel="noopener">Knowledge-Based Question Answering as Machine Translation</a>: Junwei Bao(Harbin Institute of Technology)</li><li>15: <a href="http://aclweb.org/anthology/P15-1128" target="_blank" rel="noopener">Semantic Parsing via Staged Query Graph Generation: Question Answering with Knowledge Base</a>:Wen-tau Yih(Microsoft Research)</li></ul></li><li><p><strong>ReasoNet</strong> with Shared Memory</p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Search Controller in <strong>ReasoNet</strong> </p><ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li></ul></li><li><strong>ReasoNet</strong> in symbolic vs neural space<ul><li>Symbolic is comprehensible but not robust<ul><li>11: <a href="http://www.cs.cmu.edu/~tom/pubs/lao-emnlp11.pdf" target="_blank" rel="noopener">Random Walk Inference and Learning in A Large Scale Knowledge Base</a>:Ni Lao(Carnegie Mellon University)</li><li>98: <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/COLING-98-richardson-dolan-vanderwende.pdf" target="_blank" rel="noopener">MindNet: acquiring and structuring semantic information from text</a>:Stephen D.Richardson(Microsoft Research)</li></ul></li><li>Neural is robust but not comprehensible<ul><li>[<strong>duplicate</strong>] 16: <a href="https://arxiv.org/pdf/1611.04642.pdf?" target="_blank" rel="noopener">Link Prediction using Embedded Knowledge Graphs</a>: Yulong Shen（Microsoft&amp;Google Research）</li><li>15: <a href="https://arxiv.org/abs/1412.6575" target="_blank" rel="noopener">EMBEDDING ENTITIES AND RELATIONS FOR LEARNING AND INFERENCE IN KNOWLEDGE BASES</a>:Bishan Yang(Cornell University)</li></ul></li><li>Hybrid is robust and  comprehensible<ul><li>18: <a href="https://arxiv.org/pdf/1802.04394.pdf" target="_blank" rel="noopener">M-Walk: Learning to Walk in Graph with Monte Carlo Tree Search</a>:Yelong Shen(Microsoft Research&amp;Tecent AI Lab)</li><li>18: <a href="https://arxiv.org/abs/1707.06690" target="_blank" rel="noopener">DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning</a>:Wenhan Xiong(University of California,Santa Barbara), <a href="https://github.com/xwhan/DeepPath" target="_blank" rel="noopener">code1</a> <a href="https://github.com/arunarn2/DeepPathwithTensorforce" target="_blank" rel="noopener">code2</a></li><li>18: <a href="https://arxiv.org/abs/1711.05851" target="_blank" rel="noopener">GO FOR A WALK AND ARRIVE AT THE ANSWER: REASONING OVER PATHS IN KNOWLEDGE BASES USING REINFORCEMENT LEARNING</a>:Rajarshi Das(University of Massachusetts,Amherst), </li></ul></li></ul></li><li>Multi-turn KB-QA<ul><li>Programmed Dialogue policy<ul><li>15: <a href="https://arxiv.org/pdf/1504.07182.pdf" target="_blank" rel="noopener">A Probabilistic Framework for Representing Dialog Systems and Entropy-Based Dialog Management through Dynamic Stochastic State Evolution</a>:Ji Wu(IEEE)</li></ul></li><li>Trained via RL Dialogue policy<ul><li>16: <a href="https://arxiv.org/abs/1604.04562" target="_blank" rel="noopener">A Network-based End-to-End Trainable Task-oriented Dialogue System</a>:Tsung-Hsien Wen(Cambridge University)</li><li>17: <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access</a>:Bhuwan Dhingra(Carnegie Mellon University)</li></ul></li></ul></li></ol><h4 id="Text-QA"><a href="#Text-QA" class="headerlink" title="Text-QA"></a>Text-QA</h4><ol><li>MS MARCO<ul><li>16: <a href="https://arxiv.org/abs/1611.09268" target="_blank" rel="noopener">MS MARCO: A Human Generated MAchine Reading COmprehension Dataset</a>:Tri Nguyan(Microsoft AI&amp;Research)</li></ul></li><li>SQuAD<ul><li>16: <a href="https://nlp.stanford.edu/pubs/rajpurkar2016squad.pdf" target="_blank" rel="noopener">SQuAD: 100,000+ Questions for Machine Comprehension of Text</a>:Pranav Rajpurkar(Stanford University)</li></ul></li></ol><h3 id="Neural-MRC-Models"><a href="#Neural-MRC-Models" class="headerlink" title="Neural MRC Models"></a>Neural MRC Models</h3><h4 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h4><ul><li>16: <a href="https://arxiv.org/pdf/1611.01603.pdf" target="_blank" rel="noopener">BI-DIRECTIONAL ATTENTION FLOW FOR MACHINE COMPREHENSION</a>:Minjoon Seo(University of Washington)<ul><li><a href="https://github.com/imraviagrawal/ReadingComprehension" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/bentrevett/bidaf" target="_blank" rel="noopener">code2</a> </li><li><a href="https://github.com/akhil-vader/MachineComprehension_SQuAD" target="_blank" rel="noopener">code3</a> </li><li><a href="https://github.com/RamkishanPanthena/Machine-Comprehension-using-SQuAD-Dataset" target="_blank" rel="noopener">code4</a></li></ul></li></ul><h4 id="SAN"><a href="#SAN" class="headerlink" title="SAN"></a>SAN</h4><ul><li>18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul><h4 id="Neural-MRC-Models-on-SQuAD"><a href="#Neural-MRC-Models-on-SQuAD" class="headerlink" title="Neural MRC Models on SQuAD"></a><strong>Neural MRC Models on SQuAD</strong></h4><ol><li><p>Encoding: map each text span to a semantic vector</p><ul><li>Word Embedding<ul><li>14: <a href="https://nlp.stanford.edu/pubs/glove.pdf" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a>:Jeffrey Pennington(Stanford University)<ul><li><a href="https://github.com/brangerbriz/midi-glove" target="_blank" rel="noopener">code:midi-glove</a></li><li><a href="https://github.com/fdurant/wiki_glove" target="_blank" rel="noopener">code:wiki-glove</a></li></ul></li><li>13: <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases and their Compositionality</a>:Tomas Mikolov(Google Inc.)<ul><li><a href="https://github.com/brijml/mikolov_word2vec" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/shuuchen/keras_word2vec" target="_blank" rel="noopener">code2</a><ul><li>Context Embedding</li></ul></li></ul></li></ul></li></ul><ol><li>capture context info for each word<ul><li>16: <a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li><li>18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li><li>Context Embedding via BiLSTM/ELmo<ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/abs/1802.05365" target="_blank" rel="noopener">Deep contextualized word representations</a>:Matthew E.Peters(Allen Institute for Artificial Intelligence), <a href="https://github.com/zqhZY/ner_elmo" target="_blank" rel="noopener">code</a></li><li>17: <a href="https://arxiv.org/abs/1708.00107" target="_blank" rel="noopener">Learned in Translation: Contextualized Word Vectors</a>:Bryan McCann(SalesForce)</li><li>16: [duplicate]<a href="http://aclweb.org/anthology/K16-1006" target="_blank" rel="noopener">context2vec: Learning Generic Context Embedding with Bidirectional LSTM</a>:Oren Melamud(Bar-Ilan University)</li></ul></li><li>Context Embedding<ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1804.09541.pdf" target="_blank" rel="noopener">QANET: COMBINING LOCAL CONVOLUTION WITH GLOBAL SELF-ATTENTION FOR READING COMPREHENSION</a>:Adams Wei Yu(CMU&amp;Google Brain)<ul><li><a href="https://github.com/ni9elf/QANet" target="_blank" rel="noopener">code1</a></li><li><a href="https://github.com/BangLiu/QANet-PyTorch" target="_blank" rel="noopener">code2</a></li></ul></li></ul></li></ol><ul><li>Query-context/Content-query attention</li></ul></li><li><p>Reasoning: rank and re-rank semantic vectors</p><ul><li><p>Multi-step reasoning for Text-QA</p><ul><li>[<strong>duplicate</strong>] 17: <a href="https://arxiv.org/pdf/1609.05284.pdf" target="_blank" rel="noopener">ReasoNet: Learning to Stop Reading in Machine Comprehension</a>:Yelong Shen(Microsoft Research)</li></ul></li><li><p>Stochastic Answer Net</p><ul><li>[<strong>duplicate</strong>] 18: <a href="https://arxiv.org/pdf/1712.03556.pdf" target="_blank" rel="noopener">Stochastic Answer Networks for Machine Reading Comprehension</a>: Xiaodong Liu(Microsoft Research,Redmond), <a href="https://github.com/kevinduh/san_mrc" target="_blank" rel="noopener">code</a></li></ul></li></ul></li></ol><hr><h2 id="Task-oriented-dialogues"><a href="#Task-oriented-dialogues" class="headerlink" title="Task-oriented dialogues"></a>Task-oriented dialogues</h2><h3 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h3><h4 id="A-Example-Dialogue-with-Movie-Bot"><a href="#A-Example-Dialogue-with-Movie-Bot" class="headerlink" title="A Example Dialogue with Movie-Bot"></a>A Example Dialogue with Movie-Bot</h4><ul><li><a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">source code</a><h4 id="Conversation-as-Reinforcement-Learning"><a href="#Conversation-as-Reinforcement-Learning" class="headerlink" title="Conversation as Reinforcement Learning"></a>Conversation as Reinforcement Learning</h4></li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">A Stochastic Model of Human-Machine Interaction for Learning Dialog Strategies</a>: Esther Levin(IEEE)</li><li>02: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf</a></li><li>04: <a href="https://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0ahUKEwjqp6P6-ojcAhVkGTQIHRZLA0sQFggoMAA&amp;url=http://www.i6doc.com/en/resources/download.cfm?GCOI%3D28001100696760%26thefile%3D70221_fpms_frameworkv2_1002221.pdf&amp;usg=AOvVaw0H74e3nVBG62oeUXXJeubo&amp;gws_rd=cr" target="_blank" rel="noopener">https://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0ahUKEwjqp6P6-ojcAhVkGTQIHRZLA0sQFggoMAA&amp;url=http://www.i6doc.com/en/resources/download.cfm?GCOI%3D28001100696760%26thefile%3D70221_fpms_frameworkv2_1002221.pdf&amp;usg=AOvVaw0H74e3nVBG62oeUXXJeubo&amp;gws_rd=cr</a></li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf</a><h4 id="Dialogue-System-Evaluation-Simulated-Users"><a href="#Dialogue-System-Evaluation-Simulated-Users" class="headerlink" title="Dialogue System Evaluation(Simulated Users)"></a>Dialogue System Evaluation(Simulated Users)</h4></li></ul><ol><li>Agenda based<ul><li>09: <a href="https://ieeexplore.ieee.org/document/4806280/" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/4806280/</a></li><li>source code: <a href="https://github.com/MiuLab/TC-Bot" target="_blank" rel="noopener">https://github.com/MiuLab/TC-Bot</a></li></ul></li><li>Model based<ul><li>16: <a href="https://arxiv.org/abs/1607.00070" target="_blank" rel="noopener">https://arxiv.org/abs/1607.00070</a></li><li>17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.01008.pdf</a></li></ul></li></ol><h3 id="traditional-approache"><a href="#traditional-approache" class="headerlink" title="traditional approache"></a>traditional approache</h3><h4 id="Decison-theoretic-View-of-Dialogue-Management"><a href="#Decison-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decison-theoretic View of Dialogue Management"></a>Decison-theoretic View of Dialogue Management</h4><ul><li>00: <a href="https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf" target="_blank" rel="noopener">https://web.eecs.umich.edu/~baveja/Papers/RLDSjair.pdf</a></li><li>00: <a href="http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf" target="_blank" rel="noopener">http://www.thepieraccinis.com/publications/2000/IEEE_TSAP_00.pdf</a></li><li>00: <a href="http://www.aclweb.org/anthology/P98-2219" target="_blank" rel="noopener">http://www.aclweb.org/anthology/P98-2219</a></li><li>02: <a href="https://dl.acm.org/citation.cfm?id=1289246" target="_blank" rel="noopener">https://dl.acm.org/citation.cfm?id=1289246</a></li></ul><h4 id="Language-Understanding-Uncertainty-POMDP-as-a-principled-framework"><a href="#Language-Understanding-Uncertainty-POMDP-as-a-principled-framework" class="headerlink" title="Language Understanding Uncertainty: POMDP as a principled framework"></a>Language Understanding Uncertainty: POMDP as a principled framework</h4><ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">http://www.mit.edu/~nickroy/papers/acl00.pdf</a></li><li>01: <a href="http://www.wytsg.org:88/reslib/400/180/110/020/010/130/L000000000233767.pdf" target="_blank" rel="noopener">http://www.wytsg.org:88/reslib/400/180/110/020/010/130/L000000000233767.pdf</a></li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf</a></li></ul><h4 id="scaling-up-Dialogue-Optimization"><a href="#scaling-up-Dialogue-Optimization" class="headerlink" title="scaling up Dialogue Optimization"></a>scaling up Dialogue Optimization</h4><ol><li>Use approxmiate POMDP algorithms leveraging problem-specific structure<ul><li>00: <a href="http://www.mit.edu/~nickroy/papers/acl00.pdf" target="_blank" rel="noopener">http://www.mit.edu/~nickroy/papers/acl00.pdf</a></li><li>07: <a href="http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf" target="_blank" rel="noopener">http://svr-www.eng.cam.ac.uk/~sjy/papers/wiyo07-j.pdf</a></li></ul></li><li>Use Reinforcement Learning algorithms with function approximation<ul><li>08: <a href="http://www.aclweb.org/anthology/J08-4002" target="_blank" rel="noopener">http://www.aclweb.org/anthology/J08-4002</a></li><li>09: <a href="https://pdfs.semanticscholar.org/a950/d7836e101e7d649791714d8383a804a6f671.pdf" target="_blank" rel="noopener">https://pdfs.semanticscholar.org/a950/d7836e101e7d649791714d8383a804a6f671.pdf</a></li><li>14: <a href="http://mi.eng.cam.ac.uk/~sjy/papers/gktb14.pdf" target="_blank" rel="noopener">http://mi.eng.cam.ac.uk/~sjy/papers/gktb14.pdf</a></li></ul></li></ol><h3 id="Natural-language-understanding-and-dialogue-state-tracking"><a href="#Natural-language-understanding-and-dialogue-state-tracking" class="headerlink" title="Natural language understanding and dialogue state tracking"></a>Natural language understanding and dialogue state tracking</h3><h4 id="Language-Understanding"><a href="#Language-Understanding" class="headerlink" title="Language Understanding"></a>Language Understanding</h4><ol><li><p>DNN for Domain/Intent Classification</p><ul><li>15:  <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RNNLM_addressee.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/RNNLM_addressee.pdf</a></li></ul></li><li><p>Slot filling</p><ul><li>16: <a href="https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_MultiJoint.pdf" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~yvchen/doc/IS16_MultiJoint.pdf</a></li></ul></li><li><p>Further details on NLU</p><ul><li>ppt: <a href="https://www.csie.ntu.edu.tw/~yvchen/doc/OpenDialogue_Tutorial_IJCNLP.pdf" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~yvchen/doc/OpenDialogue_Tutorial_IJCNLP.pdf</a></li><li>E2E MemNN for Contectual LU:<a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/IS16_ContextualSLU.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/wp-content/uploads/2016/06/IS16_ContextualSLU.pdf</a></li><li>LU Importance: 17: <a href="https://arxiv.org/abs/1703.01008" target="_blank" rel="noopener">https://arxiv.org/abs/1703.01008</a></li></ul></li></ol><h4 id="Dialogue-State-Tracking-DST"><a href="#Dialogue-State-Tracking-DST" class="headerlink" title="Dialogue State Tracking(DST)"></a>Dialogue State Tracking(DST)</h4><ol><li>DSTC(Dialog State Tracking Challenge)<ul><li><a href="https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/</a></li><li><a href="http://camdial.org/~mh521/dstc/" target="_blank" rel="noopener">http://camdial.org/~mh521/dstc/</a></li><li><a href="http://www.colips.org/workshop/dstc4/" target="_blank" rel="noopener">http://www.colips.org/workshop/dstc4/</a></li><li><a href="http://workshop.colips.org/dstc5/" target="_blank" rel="noopener">http://workshop.colips.org/dstc5/</a></li></ul></li><li><p>Neural Belief Tracker</p><ul><li>16:  <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">https://arxiv.org/abs/1606.03777</a></li></ul></li><li><p>NN-Based DST</p><ul><li>13: <a href="http://www.anthology.aclweb.org/W/W13/W13-4073.pdf" target="_blank" rel="noopener">http://www.anthology.aclweb.org/W/W13/W13-4073.pdf</a></li><li>15: <a href="https://arxiv.org/abs/1506.07190" target="_blank" rel="noopener">https://arxiv.org/abs/1506.07190</a></li><li>16: <a href="https://arxiv.org/abs/1606.03777" target="_blank" rel="noopener">https://arxiv.org/abs/1606.03777</a></li></ul></li></ol><h3 id="Deep-RL-for-dialogue-policy-learning"><a href="#Deep-RL-for-dialogue-policy-learning" class="headerlink" title="Deep RL for dialogue policy learning"></a>Deep RL for dialogue policy learning</h3><h4 id="Two-main-classed-of-RL-algorithms"><a href="#Two-main-classed-of-RL-algorithms" class="headerlink" title="Two main classed of RL algorithms"></a>Two main classed of RL algorithms</h4><ol><li>Value function based:<ul><li>15:<a href="https://www.nature.com/articles/nature14236" target="_blank" rel="noopener">https://www.nature.com/articles/nature14236</a></li><li>16: <a href="https://arxiv.org/pdf/1606.02560.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.02560.pdf</a></li></ul></li><li>Policy based:<ul><li>1992: <a href="https://doi.org/10.1007/BF00992696" target="_blank" rel="noopener">https://doi.org/10.1007/BF00992696</a></li><li>17: <a href="http://www.aclweb.org/anthology/P/P16/P16-1230.pdf" target="_blank" rel="noopener">http://www.aclweb.org/anthology/P/P16/P16-1230.pdf</a><h4 id="Domain-Extension-and-Exploration-BBQ-network"><a href="#Domain-Extension-and-Exploration-BBQ-network" class="headerlink" title="Domain Extension and Exploration(BBQ network)"></a>Domain Extension and Exploration(BBQ network)</h4></li></ul></li></ol><ul><li>18: <a href="https://arxiv.org/pdf/1608.05081.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1608.05081.pdf</a></li></ul><h4 id="Composite-task-Dialogues"><a href="#Composite-task-Dialogues" class="headerlink" title="Composite-task Dialogues"></a>Composite-task Dialogues</h4><ol><li>A Hierarchical Policy Learner<ul><li>98: <a href="http://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines.pdf" target="_blank" rel="noopener">http://papers.nips.cc/paper/1384-reinforcement-learning-with-hierarchies-of-machines.pdf</a></li><li>17:  <a href="https://arxiv.org/abs/1704.03084" target="_blank" rel="noopener">https://arxiv.org/abs/1704.03084</a></li></ul></li><li>Integrating Planning for Dialogue Policy Learning<ul><li>18: <a href="https://arxiv.org/abs/1801.06176" target="_blank" rel="noopener">https://arxiv.org/abs/1801.06176</a></li></ul></li></ol><h3 id="Decision-theoretic-View-of-Dialogue-Management"><a href="#Decision-theoretic-View-of-Dialogue-Management" class="headerlink" title="Decision-theoretic View of Dialogue Management"></a>Decision-theoretic View of Dialogue Management</h3><h4 id="Hybrid-Code-Networks"><a href="#Hybrid-Code-Networks" class="headerlink" title="Hybrid Code Networks"></a>Hybrid Code Networks</h4><ul><li>17: <a href="https://arxiv.org/abs/1702.03274" target="_blank" rel="noopener">https://arxiv.org/abs/1702.03274</a><h4 id="Differentiating-KB-Accesses"><a href="#Differentiating-KB-Accesses" class="headerlink" title="Differentiating KB Accesses"></a>Differentiating KB Accesses</h4></li><li>17:  <a href="https://arxiv.org/abs/1609.00777" target="_blank" rel="noopener">https://arxiv.org/abs/1609.00777</a><h4 id="An-E2E-Neural-Dialogue-System"><a href="#An-E2E-Neural-Dialogue-System" class="headerlink" title="An E2E Neural Dialogue System"></a>An E2E Neural Dialogue System</h4></li><li>17: <a href="https://arxiv.org/pdf/1703.01008.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1703.01008.pdf</a></li></ul><hr><h2 id="Fully-data-driven-conversation-models-and-chatbots"><a href="#Fully-data-driven-conversation-models-and-chatbots" class="headerlink" title="Fully data-driven conversation models and chatbots"></a>Fully data-driven conversation models and chatbots</h2><h3 id="Historical-overview"><a href="#Historical-overview" class="headerlink" title="Historical overview"></a>Historical overview</h3><h4 id="Response-retrival-system"><a href="#Response-retrival-system" class="headerlink" title="Response retrival system"></a>Response retrival system</h4><ul><li>10:  <a href="https://aritter.github.io/chat.pdf" target="_blank" rel="noopener">https://aritter.github.io/chat.pdf</a></li></ul><h4 id="Response-generation-using-Statistical-Machine-Translation"><a href="#Response-generation-using-Statistical-Machine-Translation" class="headerlink" title="Response generation using Statistical Machine Translation"></a>Response generation using Statistical Machine Translation</h4><ul><li>11:  <a href="http://www.aclweb.org/anthology/D11-1054" target="_blank" rel="noopener">http://www.aclweb.org/anthology/D11-1054</a></li></ul><h4 id="First-neural-response-generation-systems"><a href="#First-neural-response-generation-systems" class="headerlink" title="First neural response generation systems"></a>First neural response generation systems</h4><ol><li>Neural Models for Response Generation<ul><li>15: <a href="https://www.aclweb.org/anthology/N/N15/N15-1020.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/N/N15/N15-1020.pdf</a></li><li>15: <a href="https://arxiv.org/pdf/1506.05869.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1506.05869.pdf</a></li><li>15: <a href="https://www.aclweb.org/anthology/P15-1152" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P15-1152</a></li></ul></li><li>Neural conversation engine: <ul><li>15: <a href="http://research.microsoft.com/apps/pubs/?id=241719" target="_blank" rel="noopener">http://research.microsoft.com/apps/pubs/?id=241719</a></li><li>16: <a href="http://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">http://arxiv.org/abs/1510.03055</a></li></ul></li></ol><h3 id="challenges-and-remedies"><a href="#challenges-and-remedies" class="headerlink" title="challenges and remedies"></a>challenges and remedies</h3><h4 id="Challenge-The-blandness-problem"><a href="#Challenge-The-blandness-problem" class="headerlink" title="Challenge: The blandness problem"></a>Challenge: The blandness problem</h4><ul><li>16: <a href="https://arxiv.org/abs/1510.03055" target="_blank" rel="noopener">https://arxiv.org/abs/1510.03055</a><h4 id="Challenge-The-consistency-problem"><a href="#Challenge-The-consistency-problem" class="headerlink" title="Challenge: The consistency problem"></a>Challenge: The consistency problem</h4></li></ul><ol><li>Solution: Personalized Response Generation<ul><li>16: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">https://arxiv.org/abs/1603.06155</a></li></ul></li><li>Personal modeling as multi-task learning<ul><li>17: <a href="https://arxiv.org/abs/1710.07388" target="_blank" rel="noopener">https://arxiv.org/abs/1710.07388</a></li></ul></li><li>Improving personalization with multiple losses<ul><li>16:  <a href="https://arxiv.org/pdf/1606.00372.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1606.00372.pdf</a><h4 id="Challenge-Long-conversational-context"><a href="#Challenge-Long-conversational-context" class="headerlink" title="Challenge: Long conversational context"></a>Challenge: Long conversational context</h4></li></ul></li><li>It can be challenging for LSTM/GRU to encode very long context<ul><li>18: <a href="https://arxiv.org/abs/1805.04623" target="_blank" rel="noopener">https://arxiv.org/abs/1805.04623</a></li></ul></li><li>Hierarchical Encoder-Decoder(HRED)<ul><li>16: <a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160" target="_blank" rel="noopener">https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/11957/12160</a></li></ul></li><li>Hierarchical Latent Variable Encoder-Decoder(VHRED)<ul><li>17: <a href="http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf" target="_blank" rel="noopener">http://www.cs.toronto.edu/~lcharlin/papers/vhred_aaai17.pdf</a></li></ul></li></ol><h3 id="Grounded-conversation-models"><a href="#Grounded-conversation-models" class="headerlink" title="Grounded conversation models"></a>Grounded conversation models</h3><h4 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a>A Knowledge-Grounded Neural Conversation Model</h4><ul><li>15: <a href="https://arxiv.org/pdf/1503.08895.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1503.08895.pdf</a></li><li>17: <a href="https://arxiv.org/abs/1702.01932" target="_blank" rel="noopener">https://arxiv.org/abs/1702.01932</a><h4 id="Grounded-E2E-Dialogue-Systems"><a href="#Grounded-E2E-Dialogue-Systems" class="headerlink" title="Grounded E2E Dialogue Systems"></a>Grounded E2E Dialogue Systems</h4></li><li>16: <a href="https://arxiv.org/abs/1611.08669" target="_blank" rel="noopener">https://arxiv.org/abs/1611.08669</a></li><li>17: <a href="https://arxiv.org/abs/1701.08251" target="_blank" rel="noopener">https://arxiv.org/abs/1701.08251</a></li><li>18: <a href="https://www.microsoft.com/en-us/research/uploads/prod/2018/04/huber2018chi.small_.pdf" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/uploads/prod/2018/04/huber2018chi.small_.pdf</a></li></ul><h3 id="Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue"><a href="#Beyond-supervised-learning-Deep-Reinforcement-Learning-for-E2E-Dialogue" class="headerlink" title="Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)"></a>Beyond supervised learning(Deep Reinforcement Learning for E2E Dialogue)</h3><pre><code>- 16: https://arxiv.org/abs/1606.01541</code></pre><h3 id="Data-and-evaluation"><a href="#Data-and-evaluation" class="headerlink" title="Data and evaluation"></a>Data and evaluation</h3><h4 id="Conversational-datasets-for-social-bots-E2E-dialogue-research"><a href="#Conversational-datasets-for-social-bots-E2E-dialogue-research" class="headerlink" title="Conversational datasets(for social bots, E2E dialogue research)"></a>Conversational datasets(for social bots, E2E dialogue research)</h4><ul><li>15: <a href="https://arxiv.org/abs/1512.05742" target="_blank" rel="noopener">https://arxiv.org/abs/1512.05742</a><h4 id="Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation"><a href="#Evaluating-E2E-Dialogue-Systems-via-Autumatic-evaluation" class="headerlink" title="Evaluating E2E Dialogue Systems via Autumatic evaluation"></a>Evaluating E2E Dialogue Systems via Autumatic evaluation</h4></li></ul><ol><li>Machine-Translation-Based Metric<ul><li>02: <a href="https://www.aclweb.org/anthology/P02-1040.pdf" target="_blank" rel="noopener">https://www.aclweb.org/anthology/P02-1040.pdf</a></li><li>02: <a href="http://www.mt-archive.info/HLT-2002-Doddington.pdf" target="_blank" rel="noopener">http://www.mt-archive.info/HLT-2002-Doddington.pdf</a></li></ul></li><li>Sentence-level correlation of MT metrics:<ul><li>16: <a href="https://aclweb.org/anthology/D16-1230" target="_blank" rel="noopener">https://aclweb.org/anthology/D16-1230</a></li><li>15: <a href="http://www.aclweb.org/anthology/N15-1124" target="_blank" rel="noopener">http://www.aclweb.org/anthology/N15-1124</a></li></ul></li></ol><h4 id="The-importance-of-sample-size"><a href="#The-importance-of-sample-size" class="headerlink" title="The importance of sample size"></a>The importance of sample size</h4><pre><code>- 02: https://www.aclweb.org/anthology/P02-1040.pdf- 06: http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf</code></pre><h4 id="Corpus-level-Correlation"><a href="#Corpus-level-Correlation" class="headerlink" title="Corpus-level Correlation"></a>Corpus-level Correlation</h4><pre><code>- 02: https://www.aclweb.org/anthology/P02-1040.pdf- 06: http://homepages.inf.ed.ac.uk/pkoehn/publications/bootstrap2004.pdf</code></pre><h3 id="Chatbot-in-public"><a href="#Chatbot-in-public" class="headerlink" title="Chatbot in public"></a>Chatbot in public</h3><h4 id="Social-Bots-commercial-systems"><a href="#Social-Bots-commercial-systems" class="headerlink" title="Social Bots: commercial systems"></a>Social Bots: commercial systems</h4><ol><li>For end users<ul><li>Replika.ai system description: <a href="https://github.com/lukalabs/replika-research/blob/master/scai2017/replika_ai.pdf" target="_blank" rel="noopener">replika_ai</a>: Slides</li><li>XiaoIce:<br>15:<a href="https://www.nytimes.com/interactive/2015/07/27/science/chatting-with-xiaoice.html" target="_blank" rel="noopener">Chatting With Xiaoice</a>: News</li></ul></li><li>For bot developers<ul><li>Microsoft Personality chat:speaker embedding LSTM: <a href="https://arxiv.org/abs/1603.06155" target="_blank" rel="noopener">A Persona-Based Neural Conversation Model</a>: Jiwei Li(Stanford University), <a href="https://github.com/fionn-mac/A-Persona-Based-Neural-Conversation-Model" target="_blank" rel="noopener">code</a> via Pytorch</li><li>Microsoft Personality chat’s API: <a href="https://labs.cognitive.microsoft.com/en-us/project-personality-chat" target="_blank" rel="noopener">Project Personality Chat’s url</a> </li></ul></li></ol><h4 id="Open-Benchmarks"><a href="#Open-Benchmarks" class="headerlink" title="Open Benchmarks"></a>Open Benchmarks</h4><ol><li><p>Alexa Challenge</p><ul><li>website: <a href="https://developer.amazon.com/alexaprize/proceedings" target="_blank" rel="noopener">Alexa Prize Proceedings</a></li></ul></li><li><p>Dialogue System Technology Challenge(DSTC)</p><ul><li><a href="http://workshop.colips.org/dstc7" target="_blank" rel="noopener">DSTC7</a></li><li>Visual-Scene: <a href="https://github.com/hudaAlamri/DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge" target="_blank" rel="noopener">DSTC7-Audio-Visual-Scene-Aware-Dialog-AVSD-Challenge 2018</a></li><li>background article:<br><a href="https://github.com/DSTC-MSR-NLP/DSTC7-End-to-End-Conversation-Modeling" target="_blank" rel="noopener">DSTC7-End-to-End-Conversation-Modeling 2018</a></li><li>Registration Link:<br><a href="http://workshop.colips.org/dstc7/call.html" target="_blank" rel="noopener">DSTC7 Registration</a></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/awesome-chatbot/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;blockquote&gt;
&lt;p&gt;论文列表格式&lt;br&gt;&amp;emsp;论文发表年份： 论文题目&amp;amp;论文链接：第一作者（第一作者所属学校/机构），代码
      
    
    </summary>
    
      <category term="AI" scheme="https://bupt.github.io/awesome-chatbot/categories/AI/"/>
    
    
      <category term="chatbot" scheme="https://bupt.github.io/awesome-chatbot/tags/chatbot/"/>
    
      <category term="conversationalAI" scheme="https://bupt.github.io/awesome-chatbot/tags/conversationalAI/"/>
    
      <category term="nlp" scheme="https://bupt.github.io/awesome-chatbot/tags/nlp/"/>
    
      <category term="paper" scheme="https://bupt.github.io/awesome-chatbot/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>对话AI的术语和学习地图</title>
    <link href="https://bupt.github.io/awesome-chatbot/2018/08/08/convAI-map-and-term/"/>
    <id>https://bupt.github.io/awesome-chatbot/2018/08/08/convAI-map-and-term/</id>
    <published>2018-08-08T15:25:39.000Z</published>
    <updated>2018-08-14T07:12:52.077Z</updated>
    
    <content type="html"><![CDATA[<script src="/awesome-chatbot/assets/js/APlayer.min.js"> </script><h2 id="术语基本篇"><a href="#术语基本篇" class="headerlink" title="术语基本篇"></a>术语基本篇</h2><h3 id="Natural-language-processing-自然语言处理-NLP"><a href="#Natural-language-processing-自然语言处理-NLP" class="headerlink" title="Natural language processing(自然语言处理/NLP)"></a>Natural language processing(自然语言处理/NLP)</h3><p>自然语言处理是人工智能的一个子集领域。自然语言处理是一项包罗万象且相当复杂的技术，它包含许多子集，如自然语言理解。</p><p>NLP指的是机器理解人类输入的所有东西。为此，NLP引擎将使用许多工具，如NLU，总结算法，情绪分析，标记化等等。</p><h3 id="Natural-language-understanding-自然语言理解-NLU"><a href="#Natural-language-understanding-自然语言理解-NLU" class="headerlink" title="Natural language understanding (自然语言理解/NLU)"></a>Natural language understanding (自然语言理解/NLU)</h3><p>自然语言理解是自然语言处理的一个子集。NLU和NLP经常被混淆，因为它们的意思非常接近。</p><p>NLU是NLP引擎中非常具体的部分，它检查话语并提取其实体和意图。用更通俗的话说，NLU允许机器理解用户在说什么。</p><p>说到聊天机器人，可以把NLU想象成阅读人类语言并识别文本不同部分的过程，把它分解成正确的意图和实体</p><h3 id="Chatbot-聊天机器人"><a href="#Chatbot-聊天机器人" class="headerlink" title="Chatbot(聊天机器人)"></a>Chatbot(聊天机器人)</h3><p><code>chatbot</code>是一个可对话的计算机程序。但是<strong>对话agent</strong>可能是形容这个程序更好的词汇。</p><h3 id="Utterance-表达"><a href="#Utterance-表达" class="headerlink" title="Utterance(表达)"></a>Utterance(表达)</h3><p>用户对chatbot说的任何话，也可以看做是用户输入。例如，如果用户输入“给我看昨天的财经新闻”，整个句子就是<code>Utterance</code>。</p><h3 id="Intent-意图"><a href="#Intent-意图" class="headerlink" title="Intent(意图))"></a>Intent(意图))</h3><p><code>Intent</code>代表了用户<code>Utterance</code>的意义。Chatbot将会根据用户一系列的<code>Intent</code>和对<code>Intent</code>的理解来回应用户。例如，如果用户输入“show me yesterday’s financial news”，用户的意图是检索金融标题列表。<code>Intent</code>通常是一个动词和一个名词，如“showNews”。</p><h3 id="Entity-实体"><a href="#Entity-实体" class="headerlink" title="Entity(实体)"></a>Entity(实体)</h3><p><code>Entity</code>通常修饰<code>Intent</code>。例如，如果用户输入“show me yesterday’s financial news”，那么<code>Entity</code>是“yesterday”和“financial”。<code>Entity</code>会被赋予一个名称，例如“dateTime”和“newsType”。<code>Entity</code>有时也被称为<code>Slots</code>。</p><p><img src="http://ww1.sinaimg.cn/mw690/ca26ff18ly1fu2otnnx3oj21r60x246f.jpg" alt=""></p><h3 id="Broadcast-广播"><a href="#Broadcast-广播" class="headerlink" title="Broadcast(广播)"></a>Broadcast(广播)</h3><p><code>Broadcast</code>是预先发送给用户的消息。它不是对用户输入的响应。<code>Broadcast</code>也被称为“订阅消息”，它相当于聊天机器人中的移动应用程序中的推送消息。</p><h3 id="Ambiguity"><a href="#Ambiguity" class="headerlink" title="Ambiguity"></a>Ambiguity</h3><h3 id="Paraphrase"><a href="#Paraphrase" class="headerlink" title="Paraphrase"></a>Paraphrase</h3><h3 id="metric"><a href="#metric" class="headerlink" title="metric"></a>metric</h3><h2 id="术语进阶篇"><a href="#术语进阶篇" class="headerlink" title="术语进阶篇"></a>术语进阶篇</h2><h3 id="Qustion-Answering-QA"><a href="#Qustion-Answering-QA" class="headerlink" title="Qustion Answering(QA)"></a>Qustion Answering(QA)</h3><h3 id="Reinfoecement-Learning-强化学习-RL"><a href="#Reinfoecement-Learning-强化学习-RL" class="headerlink" title="Reinfoecement Learning(强化学习/RL)"></a>Reinfoecement Learning(强化学习/RL)</h3><h3 id="Markov-Decision-Process-马尔科夫决策过程-MDP"><a href="#Markov-Decision-Process-马尔科夫决策过程-MDP" class="headerlink" title="Markov Decision Process(马尔科夫决策过程/MDP)"></a>Markov Decision Process(马尔科夫决策过程/MDP)</h3><h3 id="POMDP"><a href="#POMDP" class="headerlink" title="POMDP"></a>POMDP</h3><h3 id="Image-captioning"><a href="#Image-captioning" class="headerlink" title="Image captioning"></a>Image captioning</h3><h3 id="Phonology"><a href="#Phonology" class="headerlink" title="Phonology"></a>Phonology</h3><h3 id="分词（Segment）"><a href="#分词（Segment）" class="headerlink" title="分词（Segment）"></a>分词（Segment）</h3><p>中英文都存在分词的问题，不过相对来说，英文单词与单词之间本来就有空格进行分割，所以处理起来相对方便。但是中文书写是没有分隔符的，所以分词的问题就比较突出。分词常用的手段可以是基于字典的最长串匹配，据说可以解决85%的问题，但是歧义分词很难。另外就是当下主流的统计机器学习的办法。</p><h3 id="词性标注（Label）"><a href="#词性标注（Label）" class="headerlink" title="词性标注（Label）"></a>词性标注（Label）</h3><p>基于机器学习的方法里，往往需要对词的词性进行标注。标注的目的是用来表示，词的一种隐状态，隐藏状态构成的转移就构成了状态转移序列。例如：苏宁易购/n 投资/v 了/u 国际米兰/n。其中，n代表名词，v代表动词，n,v都是标注。以此类推。</p><h3 id="命名实体识别（Named-Entity-Recognition）"><a href="#命名实体识别（Named-Entity-Recognition）" class="headerlink" title="命名实体识别（Named Entity Recognition）"></a>命名实体识别（Named Entity Recognition）</h3><p>本质上还是标注问题的一种。只不过把标注细化了。比如，苏宁/cmp_s 易购/cmp_e 是/v B2C/n 电商/n。我们把苏宁易购 标注成cmp_s和cmp_e,分别表征公司名的起始和结束。这样，当遇上苏宁/云商/易购这种场景时，也可以完整得识别出它是一个公司名称。如果，按照传统的标注方式，苏宁/cmp 易购/cmp这样笼统地标注可能会有问题。</p><h3 id="句法分析（Syntax-Parsing）"><a href="#句法分析（Syntax-Parsing）" class="headerlink" title="句法分析（Syntax Parsing）"></a>句法分析（Syntax Parsing）</h3><p>句法分析往往是一种基于规则的专家系统。当然也不是说它不能用统计学的方法进行构建，不过最初的时候，还是利用语言学专家的知识来构建的。句法分析的目的是解析句子的中各个成分的依赖关系。所以，往往最终生成的结果，是一棵句法分析树。句法分析可以解决传统词袋模型不考虑上下文的问题。比如，张三是李四的领导；李四是张三的领导。这两句话，用词袋模型是完全相同的，但是句法分析可以分析出其中的主从关系，真正理清句子的关系。</p><h3 id="指代消解-Anaphora-Resolution"><a href="#指代消解-Anaphora-Resolution" class="headerlink" title="指代消解(Anaphora Resolution)"></a>指代消解(Anaphora Resolution)</h3><p>中文中代词出现的频率很高，它的作用的是用来表征前文出现过的人名、地名等词。例如，苏宁易购坐落在南京，这家公司目前位于中国B2C市场前三。在这句话中，其实“苏宁易购”这个词出现了2次，“这家公司”指代的就是苏宁易购。但是出于中文的习惯，我们不会把“苏宁易购”再重复一遍。</p><p>###</p><h2 id="术语终极篇"><a href="#术语终极篇" class="headerlink" title="术语终极篇"></a>术语终极篇</h2><h3 id="Deep-Semantic-Similarity-Model-DSSM"><a href="#Deep-Semantic-Similarity-Model-DSSM" class="headerlink" title="Deep Semantic Similarity Model(DSSM)"></a>Deep Semantic Similarity Model(DSSM)</h3><h3 id="Triplet-loss"><a href="#Triplet-loss" class="headerlink" title="Triplet loss"></a>Triplet loss</h3><h3 id="Machine-Reading-Comprehension-MRC"><a href="#Machine-Reading-Comprehension-MRC" class="headerlink" title="Machine Reading Comprehension(MRC)"></a>Machine Reading Comprehension(MRC)</h3><h3 id="Knowledge-Base-QA-KBQA"><a href="#Knowledge-Base-QA-KBQA" class="headerlink" title="Knowledge Base-QA(KBQA)"></a>Knowledge Base-QA(KBQA)</h3><blockquote><p>参考与引用</p><ol><li><a href="https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/" target="_blank" rel="noopener">https://www.microsoft.com/en-us/research/publication/neural-approaches-to-conversational-ai/</a></li><li><a href="https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4" target="_blank" rel="noopener">https://chatbotsmagazine.com/chatbot-vocabulary-10-chatbot-terms-you-need-to-know-3911b1ef31b4</a></li><li><a href="https://blog.ubisend.com/discover-chatbots/chatbot-glossary" target="_blank" rel="noopener">https://blog.ubisend.com/discover-chatbots/chatbot-glossary</a></li><li><a href="https://blog.csdn.net/wangongxi/article/details/52662177" target="_blank" rel="noopener">https://blog.csdn.net/wangongxi/article/details/52662177</a></li></ol></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=&quot;/awesome-chatbot/assets/js/APlayer.min.js&quot;&gt; &lt;/script&gt;&lt;h2 id=&quot;术语基本篇&quot;&gt;&lt;a href=&quot;#术语基本篇&quot; class=&quot;headerlink&quot; title=&quot;术语基本篇&quot;&gt;&lt;/a&gt;术语基本篇
      
    
    </summary>
    
      <category term="AI" scheme="https://bupt.github.io/awesome-chatbot/categories/AI/"/>
    
    
      <category term="chatbot" scheme="https://bupt.github.io/awesome-chatbot/tags/chatbot/"/>
    
      <category term="conversationalAI" scheme="https://bupt.github.io/awesome-chatbot/tags/conversationalAI/"/>
    
      <category term="nlp" scheme="https://bupt.github.io/awesome-chatbot/tags/nlp/"/>
    
  </entry>
  
</feed>
